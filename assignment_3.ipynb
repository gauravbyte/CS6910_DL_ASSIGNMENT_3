{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "is_executing": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from tqdm.auto import tqdm\n",
    "from datetime import time\n",
    "import pandas as pd  # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data import Dataset\n",
    "import sys\n",
    "\n",
    "print(sys.path)\n",
    "import random\n",
    "import os\n",
    "\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        os.path.join(dirname, filename)\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "is_executing": true
   },
   "outputs": [],
   "source": [
    "os.environ()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "\u001B[34m\u001B[1mwandb\u001B[0m: Currently logged in as: \u001B[33mcs22m045\u001B[0m. Use \u001B[1m`wandb login --relogin`\u001B[0m to force relogin\n",
      "\u001B[34m\u001B[1mwandb\u001B[0m: \u001B[33mWARNING\u001B[0m If you're specifying your api key in code, ensure this code is not shared publicly.\n",
      "\u001B[34m\u001B[1mwandb\u001B[0m: \u001B[33mWARNING\u001B[0m Consider setting the WANDB_API_KEY environment variable, or running `wandb login` from the command line.\n",
      "\u001B[34m\u001B[1mwandb\u001B[0m: Appending key for api.wandb.ai to your netrc file: C:\\Users\\gaura/.netrc\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.15.3 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.14.0"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>c:\\Users\\gaura\\PycharmProjects\\scientificProject\\wandb\\run-20230518_104437-ot5olg4p</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/cs22m045/DL_ASSIGNMENT_3/runs/ot5olg4p' target=\"_blank\">dark-firefly-28</a></strong> to <a href='https://wandb.ai/cs22m045/DL_ASSIGNMENT_3' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/cs22m045/DL_ASSIGNMENT_3' target=\"_blank\">https://wandb.ai/cs22m045/DL_ASSIGNMENT_3</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/cs22m045/DL_ASSIGNMENT_3/runs/ot5olg4p' target=\"_blank\">https://wandb.ai/cs22m045/DL_ASSIGNMENT_3/runs/ot5olg4p</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<button onClick=\"this.nextSibling.style.display='block';this.style.display='none';\">Display W&B run</button><iframe src='https://wandb.ai/cs22m045/DL_ASSIGNMENT_3/runs/ot5olg4p?jupyter=true' style='border:none;width:100%;height:420px;display:none;'></iframe>"
      ],
      "text/plain": [
       "<wandb.sdk.wandb_run.Run at 0x192404c4dd0>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# !pip install wandb\n",
    "import wandb\n",
    "wandb.login(key = \"d4c2dc0cbf8caf1ee8dc1563f3d5c10594df22b5\")\n",
    "wandb.init(project=\"DL_ASSIGNMENT_3\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %env WANDB_SILENT=true\n",
    "# wandb.init(timeout=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Executing on cuda:0\n",
      "Running on Kaggle\n",
      "(51199, 2)\n",
      "(4095, 2)\n",
      "(4095, 2)\n",
      "{'_': 0, '|': 1, '$': 2, 'a': 3, 'b': 4, 'c': 5, 'd': 6, 'e': 7, 'f': 8, 'g': 9, 'h': 10, 'i': 11, 'j': 12, 'k': 13, 'l': 14, 'm': 15, 'n': 16, 'o': 17, 'p': 18, 'q': 19, 'r': 20, 's': 21, 't': 22, 'u': 23, 'v': 24, 'w': 25, 'x': 26, 'y': 27, 'z': 28}\n",
      "ouput char set  {'भ', 'ढ', 'र', 'ं', 'ॉ', 'ऊ', 'ऑ', 'द', 'ः', 'अ', 'ट', 'ौ', 'ज', 'ॅ', 'ँ', 'ड', 'ष', 'ग', 'ू', 'ण', 'छ', 'श', 'ऱ', 'ा', 'ध', 'स', 'फ', 'ळ', 'ो', 'ई', 'ी', 'े', 'प', 'च', 'ठ', '़', 'ु', 'इ', 'औ', 'ञ', 'व', 'म', 'ह', 'आ', 'ए', 'थ', 'ब', 'ख', 'घ', 'ऐ', 'झ', 'ि', 'ओ', 'ृ', '्', 'उ', 'ै', 'न', 'त', 'ऋ', 'ऍ', 'क', 'य', 'ल'}\n",
      "ouput char set size 64\n",
      "max input length 28\n",
      "max output length 20\n",
      "max_length 28\n",
      "Input Character max 29\n",
      "output Character size 67\n",
      "Input Character max 29\n",
      "output Character size 67\n",
      "tensor([ 4, 10, 23, 14, 22, 10,  3, 18,  3, 16,  3])\n",
      "व्हायकी\n",
      "{'_': 0, '|': 1, '$': 2, 'a': 3, 'b': 4, 'c': 5, 'd': 6, 'e': 7, 'f': 8, 'g': 9, 'h': 10, 'i': 11, 'j': 12, 'k': 13, 'l': 14, 'm': 15, 'n': 16, 'o': 17, 'p': 18, 'q': 19, 'r': 20, 's': 21, 't': 22, 'u': 23, 'v': 24, 'w': 25, 'x': 26, 'y': 27, 'z': 28}\n",
      "tensor([10,  7, 14, 14, 17])\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Executing on \" + (\"cuda:0\" if torch.cuda.is_available() else \"cpu\"))\n",
    "\n",
    "print('Running on Kaggle')\n",
    "\n",
    "\n",
    "print(df_train.shape)\n",
    "print(df_test.shape)\n",
    "print(df_valid.shape)\n",
    "\n",
    "PAD_CHAR = '_'  # padding character\n",
    "EOW_CHAR = '|'  # end of word character\n",
    "SOW_CHAR = '$'  # start of word character\n",
    "BATCH_SIZE = 32\n",
    "ENGLISH_ALPHA = [chr(alpha) for alpha in range(ord('a'), ord('z') + 1)]\n",
    "INPUT_CHAR_INDX = {PAD_CHAR: 0, EOW_CHAR: 1, SOW_CHAR: 2}\n",
    "for index, alpha in enumerate(ENGLISH_ALPHA):\n",
    "    INPUT_CHAR_INDX[alpha] = index + 3\n",
    "\n",
    "INPUT_INDX_CHAR = {v: k for k, v in INPUT_CHAR_INDX.items()}\n",
    "\n",
    "df_train = df_train.set_axis(['X', 'Y'], axis=1)\n",
    "df_valid = df_valid.set_axis(['X', 'Y'], axis=1)\n",
    "df_test = df_test.set_axis(['X', 'Y'], axis=1)\n",
    "\n",
    "print(INPUT_CHAR_INDX)\n",
    "\n",
    "ouput_words = df_train['Y'].tolist() + df_test['Y'].tolist() + df_valid['Y'].tolist()\n",
    "output_char_set = set()\n",
    "for word in ouput_words:\n",
    "    for char in word:\n",
    "        output_char_set.add(char)\n",
    "OUT_ALPHA = list(output_char_set)\n",
    "# OUT_ALPHA = [chr(alpha) for alpha in range(2304, 2432)]\n",
    "OUT_ALPHA_SIZE = len(OUT_ALPHA)\n",
    "OUTPUT_CHAR_INDEX = {PAD_CHAR: 0, EOW_CHAR: 1, SOW_CHAR: 2}\n",
    "for index, alpha in enumerate(OUT_ALPHA):\n",
    "    OUTPUT_CHAR_INDEX[alpha] = index + 3\n",
    "# %%\n",
    "\n",
    "OUTPUT_INDEX_CHAR = {v: k for k, v in OUTPUT_CHAR_INDEX.items()}\n",
    "\n",
    "print(\"ouput char set \",output_char_set)\n",
    "print(\"ouput char set size\",len(output_char_set))\n",
    "\n",
    "OUTPUT_INDEX_CHAR = {v: k for k, v in OUTPUT_CHAR_INDEX.items()}\n",
    "\n",
    "# print(OUTPUT_CHAR_INDEX)\n",
    "# print(len(OUTPUT_CHAR_INDEX))\n",
    "\n",
    "df_train = df_train.set_axis(['X', 'Y'], axis=1)\n",
    "df_valid = df_valid.set_axis(['X', 'Y'], axis=1)\n",
    "df_test = df_test.set_axis(['X', 'Y'], axis=1)\n",
    "\n",
    "max_input_length = max(df_train.iloc[:, 0].apply(lambda x: len(x)).max(),\n",
    "                       df_test.iloc[:, 0].apply(lambda x: len(x)).max(),\n",
    "                       df_valid.iloc[:, 0].apply(lambda x: len(x)).max())\n",
    "\n",
    "max_output_length = max(df_train.iloc[:, 1].apply(lambda x: len(x)).max(),\n",
    "                        df_test.iloc[:, 1].apply(lambda x: len(x)).max(),\n",
    "                        df_valid.iloc[:, 1].apply(lambda x: len(x)).max())\n",
    "\n",
    "print(\"max input length\", max_input_length)\n",
    "print(\"max output length\", max_output_length)\n",
    "MAX_LENGTH = max(max_input_length, max_output_length)\n",
    "print(\"max_length\", MAX_LENGTH)\n",
    "# %%\n",
    "input_vocab_size = len(INPUT_CHAR_INDX)\n",
    "output_vocab_size = len(OUTPUT_CHAR_INDEX)\n",
    "print(\"Input Character max\", input_vocab_size)\n",
    "print(\"output Character size\", output_vocab_size)\n",
    "\n",
    "train_list = df_train.values.tolist()\n",
    "valid_list = df_valid.values.tolist()\n",
    "test_list = df_test.values.tolist()\n",
    "\n",
    "# %%\n",
    "input_vocab_size = len(INPUT_CHAR_INDX)\n",
    "output_vocab_size = len(OUTPUT_CHAR_INDEX)\n",
    "print(\"Input Character max\", input_vocab_size)\n",
    "print(\"output Character size\", output_vocab_size)\n",
    "\n",
    "train_list = df_train.values.tolist()\n",
    "valid_list = df_valid.values.tolist()\n",
    "test_list = df_test.values.tolist()\n",
    "\n",
    "\n",
    "# %% md\n",
    "class Transliterate(Dataset):\n",
    "    def __init__(self, df_data, in_dict, out_dict):\n",
    "        super().__init__()\n",
    "        self.df_data_word = df_data.copy()\n",
    "        self.in_dict = in_dict\n",
    "        self.out_dict = out_dict\n",
    "        self.df_data = df_data.iloc[:, ].apply(lambda x: SOW_CHAR + x + EOW_CHAR)\n",
    "\n",
    "\n",
    "    def __get_random_word__(self):\n",
    "        idx = random.randint(0, len(self.df_data))\n",
    "        input_word = self.df_data_word.iloc[idx][0]\n",
    "        output_word = self.df_data_word.iloc[idx][1]\n",
    "        return input_word, output_word\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df_data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        input_word = self.df_data.iloc[idx][0]\n",
    "        output_word = self.df_data.iloc[idx][1]\n",
    "        input_tensor = inputToTensor(input_word)\n",
    "        output_tensor = outToTensor(output_word)\n",
    "        return input_tensor, output_tensor\n",
    "\n",
    "    def __getrandom__(self):\n",
    "        idx = random.randint(0,len(self.data_list))\n",
    "        input_word = self.df_data[idx][0]\n",
    "        output_word = self.df_data[idx][1]\n",
    "        input_tensor = inputToTensor(input_word)\n",
    "        output_tensor = outToTensor(output_word)\n",
    "        return input_tensor, output_tensor\n",
    "\n",
    "    def preprocess(self, word):\n",
    "        return SOW_CHAR + word + EOW_CHAR\n",
    "\n",
    "\n",
    "train_data = Transliterate(df_train, INPUT_CHAR_INDX, OUTPUT_CHAR_INDEX)\n",
    "valid_data = Transliterate(df_valid, INPUT_CHAR_INDX, OUTPUT_CHAR_INDEX)\n",
    "test_data = Transliterate(df_test, INPUT_CHAR_INDX, OUTPUT_CHAR_INDEX)\n",
    "# %%\n",
    "def inputToTensor(line):\n",
    "    tensor = torch.tensor(data=([INPUT_CHAR_INDX[x] for x in line]), dtype=torch.long)\n",
    "    return tensor\n",
    "\n",
    "\n",
    "def charToTensor(char, dic=INPUT_CHAR_INDX):\n",
    "    tensor = torch.zeros(len(dic))\n",
    "    tensor[dic[char]] = 1\n",
    "    return tensor\n",
    "\n",
    "\n",
    "def outToTensor(word):\n",
    "    tensor = torch.tensor([OUTPUT_CHAR_INDEX[x] for x in word])\n",
    "    return tensor\n",
    "\n",
    "\n",
    "# %%\n",
    "print(inputToTensor(train_list[0][0]))\n",
    "# %%\n",
    "print(train_list[1][1])\n",
    "\n",
    "# %%\n",
    "inputToTensor(\"$bindhya|\")\n",
    "# %%\n",
    "print(INPUT_CHAR_INDX)\n",
    "# %%\n",
    "print(inputToTensor(\"hello\"))\n",
    "\n",
    "\n",
    "# %%\n",
    "def generate_batch(data_batch):\n",
    "    train_batch = [x[0] for x in data_batch]\n",
    "    target_batch = [x[1] for x in data_batch]\n",
    "    train_pad = torch.nn.utils.rnn.pad_sequence(train_batch, batch_first=True, padding_value=0)\n",
    "    train_pad = train_pad[:, :MAX_LENGTH]\n",
    "    train_pad = torch.nn.functional.pad(train_pad, (0, MAX_LENGTH - train_pad.size(1)), value=0)\n",
    "    target_pad = torch.nn.utils.rnn.pad_sequence(target_batch, batch_first=True, padding_value=0)\n",
    "    target_pad = target_pad[:, :MAX_LENGTH]\n",
    "    target_pad = torch.nn.functional.pad(target_pad, (0, MAX_LENGTH - target_pad.size(1)), value=0)\n",
    "    padded_input_batch = train_pad.T.to(device)\n",
    "    padded_output_batch = target_pad.T.to(device)\n",
    "    return padded_input_batch, padded_output_batch\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# for data, target in train_dataloader:\n",
    "#     print(data.shape)\n",
    "#     print(target.shape)\n",
    "#     if True:\n",
    "#         break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(nn.Module):\n",
    "    def __init__(self, input_size, embedding_size, hidden_size, num_layers, dropout, cell_type, bidirectional=False):\n",
    "        super().__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_layers = num_layers\n",
    "        self.embedding = nn.Embedding(input_size, embedding_size)\n",
    "        self.cell_type = cell_type\n",
    "        self.bidirectional = bidirectional\n",
    "        if cell_type == 'RNN':\n",
    "            self.rnn = nn.RNN(embedding_size,hidden_size,num_layers,dropout=dropout,bidirectional=bidirectional)\n",
    "        elif cell_type == 'LSTM':\n",
    "            self.rnn = nn.LSTM(embedding_size,hidden_size,num_layers,dropout=dropout,bidirectional=bidirectional)\n",
    "        elif cell_type == 'GRU':\n",
    "            self.rnn = nn.GRU(embedding_size,hidden_size,num_layers,dropout=dropout,bidirectional=bidirectional)\n",
    "        # self.rnn = nn.LSTM(embedding_size, hidden_size, n_layers, dropout=dropout)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self, src):\n",
    "        embedded = self.dropout(self.embedding(src))\n",
    "        if self.cell_type == 'LSTM':\n",
    "            outputs, (hidden, cell) = self.rnn(embedded)\n",
    "        else:\n",
    "            outputs, hidden = self.rnn(embedded)\n",
    "        if(self.bidirectional == True):\n",
    "            hidden = hidden[self.num_layers - 1] + hidden[self.num_layers - 1]\n",
    "            hidden = hidden.repeat(self.num_layers,1,1)\n",
    "            if(self.cell_type == \"LSTM\"):\n",
    "                cell = cell[self.num_layers - 1] + cell[self.num_layers - 1]\n",
    "                cell = cell.repeat(self.num_layers,1,1)\n",
    "                return hidden, cell \n",
    "        if(self.cell_type == \"LSTM\"):\n",
    "            return hidden, cell\n",
    "        else:\n",
    "            return outputs,hidden\n",
    "        \n",
    "    def initHidden(self):\n",
    "        if self.bidirectional:\n",
    "            return torch.zeros(2 * self.num_layers, BATCH_SIZE, self.hidden_size, device=device)\n",
    "        else:\n",
    "            return torch.zeros(self.num_layers, BATCH_SIZE, self.hidden_size, device=device)\n",
    "\n",
    "class Decoder(nn.Module):\n",
    "    def __init__(self, output_dim, emb_dim, hidden_size, num_layers, dropout, cell_type='LSTM'):\n",
    "        super().__init__()\n",
    "        self.output_dim = output_dim\n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_layers = num_layers\n",
    "        self.embedding = nn.Embedding(output_dim, emb_dim)\n",
    "        self.cell_type = cell_type\n",
    "        if cell_type == 'RNN':\n",
    "            self.rnn = nn.RNN(emb_dim, hidden_size, num_layers, dropout=dropout)\n",
    "        elif cell_type == 'LSTM':\n",
    "            self.rnn = nn.LSTM(emb_dim, hidden_size, num_layers, dropout=dropout)\n",
    "        elif cell_type == 'GRU':\n",
    "            self.rnn = nn.GRU(emb_dim, hidden_size, num_layers, dropout=dropout)\n",
    "        else:\n",
    "            raise ValueError(\"Invalid RNN type specified!\")\n",
    "        self.fc_out = nn.Linear(hidden_size, output_dim)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self, input, hidden, cell=None):\n",
    "        input = input.unsqueeze(0)\n",
    "        embedded = self.dropout(self.embedding(input))\n",
    "        if self.cell_type == 'LSTM':\n",
    "            output, (hidden, cell) = self.rnn(embedded,( hidden, cell))\n",
    "            prediction = self.fc_out(output).squeeze(0)\n",
    "            return prediction, hidden, cell\n",
    "        else:\n",
    "            output, hidden = self.rnn(embedded, hidden)\n",
    "            prediction = self.fc_out(output).squeeze(0)\n",
    "            return prediction, hidden\n",
    "\n",
    "\n",
    "\n",
    "class Seq2Seq(nn.Module):\n",
    "    def __init__(self, encoder, decoder, device,teacher_forcing_ratio=0.5):\n",
    "        super().__init__()\n",
    "        self.encoder = encoder\n",
    "        self.decoder = decoder\n",
    "        self.device = device\n",
    "        self.teacher_forcing_ratio = teacher_forcing_ratio\n",
    "        assert encoder.hidden_size == decoder.hidden_size, \\\n",
    "            \"Hidden dimensions of encoder and decoder must be equal!\"\n",
    "        assert encoder.num_layers == decoder.num_layers, \\\n",
    "            \"Encoder and decoder must have equal number of layers!\"\n",
    "\n",
    "    def forward(self, src, trg):\n",
    "        batch_size = trg.shape[1]\n",
    "        trg_len = trg.shape[0]\n",
    "        trg_vocab_size = self.decoder.output_dim\n",
    "        outputs = torch.zeros(trg_len, batch_size, trg_vocab_size).to(self.device)\n",
    "        if self.encoder.cell_type == 'LSTM':\n",
    "            encoder_hidden, encoder_cell = self.encoder(src)\n",
    "            hidden = encoder_hidden\n",
    "            cell = encoder_cell\n",
    "        else:\n",
    "            output, hidden = self.encoder(src)\n",
    "        input_decoder = trg[0, :]\n",
    "        for t in range(1, trg_len):\n",
    "            if self.decoder.cell_type == 'LSTM':\n",
    "                dec_output, hidden, cell = self.decoder(input_decoder, hidden, cell)\n",
    "            else:\n",
    "                dec_output, hidden = self.decoder(input_decoder, hidden)\n",
    "            outputs[t] = dec_output\n",
    "            teacher_force = random.random() < self.teacher_forcing_ratio\n",
    "            top1 = dec_output.argmax(1)\n",
    "            input_decoder = trg[t] if teacher_force else top1\n",
    "        return outputs\n",
    "\n",
    "\n",
    "def get_accuracy(preds, target):\n",
    "    \"\"\"\n",
    "    Returns accuracy per batch, i.e. if you get 8/10 right, this returns 0.8, NOT 8\n",
    "    \"\"\"\n",
    "    preds = preds.argmax(dim=2)\n",
    "    preds = preds[1:]\n",
    "    target = target[1:]\n",
    "    matches = torch.eq(preds, target)\n",
    "    columns_matches = torch.sum(matches, dim=0)\n",
    "    num_matching_columns = torch.sum(columns_matches == target.shape[0])\n",
    "    acc = num_matching_columns / target.shape[1]\n",
    "    return acc.item()\n",
    "\n",
    "\n",
    "def train(model, iterator, optimizer, criterion, clip):\n",
    "    model.train()\n",
    "    epoch_loss = 0\n",
    "    epoch_acc = 0\n",
    "    pbar = tqdm(iterator, desc=\"Training\",position=0, leave=True)\n",
    "    for i, (data, target) in enumerate(pbar):\n",
    "        src = data.to(device)\n",
    "        trg = target.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        output = model(src, trg)\n",
    "        output_dim = output.shape[-1]\n",
    "        output_reshaped = output[1:].reshape(-1, output_dim)\n",
    "        trg_reshaped = trg[1:].reshape(-1)\n",
    "        loss = criterion(output_reshaped, trg_reshaped)\n",
    "        loss.backward()\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), clip)\n",
    "        optimizer.step()\n",
    "        acc = get_accuracy(output, trg)\n",
    "        epoch_acc += acc\n",
    "        epoch_loss += loss.item()\n",
    "        pbar.set_postfix(train_loss=epoch_loss / (i + 1), train_acc=epoch_acc / (i + 1))\n",
    "    return epoch_loss / len(iterator), epoch_acc / len(iterator)\n",
    "\n",
    "def evaluate(model, iterator, criterion):\n",
    "    model.eval()\n",
    "    epoch_loss = 0\n",
    "    epoch_acc = 0\n",
    "    # with torch.no_grad():\n",
    "    for i, (data, target) in enumerate(iterator):\n",
    "        src = data.to(device)\n",
    "        trg = target.to(device)\n",
    "        output = model(src, trg)\n",
    "        output_dim = output.shape[-1]\n",
    "        output_reshaped = output[1:].reshape(-1, output_dim)\n",
    "        trg_reshaped = trg[1:].reshape(-1)\n",
    "        loss = criterion(output_reshaped, trg_reshaped)\n",
    "        acc = get_accuracy(output,trg)\n",
    "        epoch_acc += acc\n",
    "        epoch_loss += loss.item()\n",
    "    return epoch_loss / len(iterator), epoch_acc / len(iterator)\n",
    "\n",
    "\n",
    "def predict(model,input_word,actual_output):\n",
    "    data_pred = [[input_word,actual_output]]\n",
    "    data_batch = DataLoader(data_pred, batch_size=BATCH_SIZE, shuffle=False, collate_fn=generate_batch)\n",
    "    iterator = data_batch\n",
    "    with torch.no_grad():\n",
    "        for i, (data, target) in enumerate(iterator):\n",
    "            src = data\n",
    "            trg = target\n",
    "            output = model(src, trg, 0)\n",
    "            output_dim = output.shape[-1]\n",
    "            output_reshaped = output[1:].reshape(-1, output_dim)\n",
    "            trg_reshaped = trg[1:].reshape(-1)\n",
    "            preds = output.argmax(dim=2)\n",
    "            print(\"input word\",input_word)\n",
    "            print(\"actual word\",actual_output)\n",
    "            predicted_word = \"\"\n",
    "            for i in preds:\n",
    "                if i.item() in [0,1,2]:\n",
    "                    continue\n",
    "                predicted_word += predicted_word + OUTPUT_INDEX_CHAR[i.item()]\n",
    "            print(\"predicted word\",predicted_word)\n",
    "    return preds\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sweep_config = {\n",
    "  \"name\": \"CS6910 Assignment 3\",\n",
    "  \"metric\": {\n",
    "      \"name\":\"validation_accuracy\",\n",
    "      \"goal\": \"maximize\"\n",
    "  },\n",
    "  \"method\": \"bayes\",\n",
    "  \"parameters\": {\n",
    "        \n",
    "        \"cell_type\": {\n",
    "            \"values\": [\"LSTM\",\"GRU\"]\n",
    "        },\n",
    "        \"bidirectional\": {\n",
    "            \"values\": [True, False]\n",
    "        },\n",
    "        \"num_epochs\": {\n",
    "            \"values\": [20,25]\n",
    "        },\n",
    "        \"num_layers\": {\n",
    "            \"values\": [1, 2, 3]\n",
    "        },\n",
    "        \"batch_size\": {\n",
    "            \"values\": [32,64,128]\n",
    "        },\n",
    "        \"embedding_size\": {\n",
    "            \"values\": [128, 256, 512]\n",
    "        },\n",
    "        \"hidden_size\": {\n",
    "            \"values\": [128, 256, 512]\n",
    "        },\n",
    "        \"learning_rate\": {\n",
    "            \"values\": [0.001,0.0001]\n",
    "        },\n",
    "        \"enc_dropout\": {\n",
    "            \"values\": [0.2,0.3,0.5]\n",
    "        },\n",
    "        \"dec_dropout\": {\n",
    "            \"values\": [0.2,0.3,0.5]\n",
    "        }\n",
    "    }\n",
    "}\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_train(INPUT_DIM, OUTPUT_DIM, EMBEDDING_SIZE, HIDDEN_SIZE, NUM_LAYERS, ENC_DROPOUT, DEC_DROPOUT,  BIDIRECTIONAL, CELL_TYPE, LEARNING_RATE, N_EPOCHS, CLIP,BATCH_SIZE):\n",
    "    train_dataloader = DataLoader(train_data, batch_size=BATCH_SIZE, shuffle=True, collate_fn=generate_batch)\n",
    "    valid_dataloader = DataLoader(valid_data, batch_size=BATCH_SIZE, shuffle=True, collate_fn=generate_batch)\n",
    "    encoder = Encoder(input_size=INPUT_DIM, embedding_size=EMBEDDING_SIZE, hidden_size=HIDDEN_SIZE, num_layers=NUM_LAYERS, dropout=ENC_DROPOUT, bidirectional=BIDIRECTIONAL, cell_type=CELL_TYPE)\n",
    "    decoder = Decoder(output_dim=OUTPUT_DIM, emb_dim=EMBEDDING_SIZE, hidden_size=HIDDEN_SIZE, num_layers=NUM_LAYERS, dropout=DEC_DROPOUT, cell_type=CELL_TYPE)\n",
    "    model = Seq2Seq(encoder, decoder, device).to(device)\n",
    "    optimizer = optim.Adam(model.parameters(), lr=LEARNING_RATE)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    # pbar = tqdm(range(N_EPOCHS), desc=\"Epochs\",position=0, leave=True)\n",
    "    gbar = tqdm(range(1, N_EPOCHS + 1),position=1,leave=True, desc='Epochs', total=N_EPOCHS)\n",
    "#     gbar = N_EPOCHS\n",
    "    for epoch in gbar:\n",
    "\n",
    "        train_loss, train_acc = train(model, train_dataloader, optimizer, criterion, clip=CLIP)\n",
    "        # print(run_name)\n",
    "        valid_loss, valid_acc = evaluate(model,valid_dataloader, criterion)\n",
    "        print(\"Epoch: \",epoch)\n",
    "        print(f'\\tTrain Loss: {train_loss:.3f} | Train Acc: {train_acc * 100:.2f}%')\n",
    "        print(f'\\t Val. Loss: {valid_loss:.3f} |  Val. Acc: {valid_acc * 100:.2f}%')\n",
    "        wandb.log({\"train_loss\": train_loss, \"train_acc\": train_acc, \"valid_loss\": valid_loss, \"valid_acc\": valid_acc})\n",
    "        gbar.set_postfix(train_loss=train_loss, train_acc=train_acc, valid_loss=valid_loss, valid_acc=valid_acc)\n",
    "    return valid_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_wandb():\n",
    "    wandb.init()\n",
    "    config = wandb.config\n",
    "    LEARNING_RATE = config.learning_rate\n",
    "    BATCH_SIZE = config.batch_size\n",
    "    EMBEDDING_SIZE = config.embedding_size\n",
    "    HIDDEN_SIZE = config.hidden_size\n",
    "    ENC_DROPOUT = config.enc_dropout\n",
    "    DEC_DROPOUT = config.dec_dropout\n",
    "    NUM_LAYERS = config.num_layers\n",
    "    BIDIRECTIONAL = config.bidirectional\n",
    "    CELL_TYPE = config.cell_type\n",
    "    N_EPOCHS = config.num_epochs\n",
    "    CLIP = 1\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    INPUT_DIM = len(INPUT_CHAR_INDX)\n",
    "    OUTPUT_DIM = len(OUTPUT_CHAR_INDEX)\n",
    "    model_train(INPUT_DIM=INPUT_DIM, OUTPUT_DIM=OUTPUT_DIM, EMBEDDING_SIZE=EMBEDDING_SIZE, HIDDEN_SIZE=HIDDEN_SIZE, NUM_LAYERS=NUM_LAYERS, ENC_DROPOUT=ENC_DROPOUT,DEC_DROPOUT=DEC_DROPOUT, BIDIRECTIONAL=BIDIRECTIONAL, CELL_TYPE=CELL_TYPE, LEARNING_RATE=LEARNING_RATE, N_EPOCHS=N_EPOCHS, CLIP=CLIP,BATCH_SIZE=BATCH_SIZE)\n",
    "    # best_valid_loss = float('inf')\n",
    "    print(\"cell_type\",CELL_TYPE,\"bidirectional\",BIDIRECTIONAL,\"num_layers\",NUM_LAYERS,\"batch_size\",BATCH_SIZE,\"embedding_size\",EMBEDDING_SIZE,\"hidden_size\",HIDDEN_SIZE,\"enc_dropout\",ENC_DROPOUT,\"dec_dropout\",DEC_DROPOUT,\"num_epochs\",N_EPOCHS)\n",
    "    run_name = \"ct_{}_bi_{}_nl_{}_bs_{}_es_{}_hs_{}_endo_{}_decdo_{}_ne_{}\".format(CELL_TYPE,BIDIRECTIONAL,NUM_LAYERS,BATCH_SIZE,EMBEDDING_SIZE,HIDDEN_SIZE,ENC_DROPOUT,DEC_DROPOUT,N_EPOCHS)\n",
    "    print(run_name)\n",
    "    wandb.run.name = run_name\n",
    "    wandb.run.save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # wandb.init()\n",
    "# config=wandb.config\n",
    "# LEARNING_RATE = 0.001\n",
    "# BATCH_SIZE = 32\n",
    "# EMBEDDING_SIZE = 128\n",
    "# HIDDEN_SIZE = 512\n",
    "# ENC_DROPOUT = 0.2\n",
    "# DEC_DROPOUT = 0.2\n",
    "# NUM_LAYERS = 2\n",
    "# BIDIRECTIONAL = True\n",
    "# CELL_TYPE = 'LSTM'\n",
    "# N_EPOCHS = 1\n",
    "# CLIP = 1\n",
    "# device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "# train_dataloader = DataLoader(train_data, batch_size=BATCH_SIZE, shuffle=True, collate_fn=generate_batch)\n",
    "# valid_dataloader = DataLoader(valid_data, batch_size=BATCH_SIZE, shuffle=False,     collate_fn=generate_batch)\n",
    "# INPUT_DIM = len(INPUT_CHAR_INDX)\n",
    "# OUTPUT_DIM = len(OUTPUT_CHAR_INDEX)\n",
    "# model_train(INPUT_DIM=INPUT_DIM, OUTPUT_DIM=OUTPUT_DIM, EMBEDDING_SIZE=EMBEDDING_SIZE, HIDDEN_SIZE=HIDDEN_SIZE, NUM_LAYERS=NUM_LAYERS, ENC_DROPOUT=ENC_DROPOUT,DEC_DROPOUT=DEC_DROPOUT, BIDIRECTIONAL=BIDIRECTIONAL, CELL_TYPE=CELL_TYPE, LEARNING_RATE=LEARNING_RATE, N_EPOCHS=N_EPOCHS, CLIP=CLIP,BATCH_SIZE=BATCH_SIZE)\n",
    "# # best_valid_loss = float('inf')\n",
    "# # run_name = \"ct_{}_bi_{}_nl_{}_bs_{}_es_{}_hs_{}_do_{}_ne{}\".format(CELL_TYPE,BIDIRECTIONAL,NUM_LAYERS,BATCH_SIZE,EMBEDDING_SIZE,HIDDEN_SIZE,DROPOUT,N_EPOCHS)\n",
    "# # print(run_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[34m\u001B[1mwandb\u001B[0m: \u001B[33mWARNING\u001B[0m Calling wandb.login() after wandb.init() has no effect.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Create sweep with ID: x2ojhehe\n",
      "Sweep URL: https://wandb.ai/cs22m045/DL_ASSIGNMENT_3/sweeps/x2ojhehe\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "wandb: Waiting for W&B process to finish... (success).\n",
      "wandb: 🚀 View run graceful-meadow-11 at: https://wandb.ai/cs22m045/DL_ASSIGNMENT_3/runs/n92g2j3z\n",
      "wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\n",
      "wandb: Find logs at: ./wandb/run-20230516_071553-n92g2j3z/logs\n",
      "\u001B[34m\u001B[1mwandb\u001B[0m: Agent Starting Run: as4hm8y3 with config:\n",
      "\u001B[34m\u001B[1mwandb\u001B[0m: \tbatch_size: 64\n",
      "\u001B[34m\u001B[1mwandb\u001B[0m: \tbidirectional: False\n",
      "\u001B[34m\u001B[1mwandb\u001B[0m: \tcell_type: LSTM\n",
      "\u001B[34m\u001B[1mwandb\u001B[0m: \tdec_dropout: 0.5\n",
      "\u001B[34m\u001B[1mwandb\u001B[0m: \tembedding_size: 128\n",
      "\u001B[34m\u001B[1mwandb\u001B[0m: \tenc_dropout: 0.5\n",
      "\u001B[34m\u001B[1mwandb\u001B[0m: \thidden_size: 128\n",
      "\u001B[34m\u001B[1mwandb\u001B[0m: \tlearning_rate: 0.001\n",
      "\u001B[34m\u001B[1mwandb\u001B[0m: \tnum_epochs: 15\n",
      "\u001B[34m\u001B[1mwandb\u001B[0m: \tnum_layers: 1\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.15.2 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.15.0"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/kaggle/working/wandb/run-20230516_071700-as4hm8y3</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/cs22m045/DL_ASSIGNMENT_3/runs/as4hm8y3' target=\"_blank\">ancient-sweep-1</a></strong> to <a href='https://wandb.ai/cs22m045/DL_ASSIGNMENT_3' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/cs22m045/DL_ASSIGNMENT_3/sweeps/x2ojhehe' target=\"_blank\">https://wandb.ai/cs22m045/DL_ASSIGNMENT_3/sweeps/x2ojhehe</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/cs22m045/DL_ASSIGNMENT_3' target=\"_blank\">https://wandb.ai/cs22m045/DL_ASSIGNMENT_3</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/cs22m045/DL_ASSIGNMENT_3/sweeps/x2ojhehe' target=\"_blank\">https://wandb.ai/cs22m045/DL_ASSIGNMENT_3/sweeps/x2ojhehe</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/cs22m045/DL_ASSIGNMENT_3/runs/as4hm8y3' target=\"_blank\">https://wandb.ai/cs22m045/DL_ASSIGNMENT_3/runs/as4hm8y3</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/torch/nn/modules/rnn.py:71: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.5 and num_layers=1\n",
      "  warnings.warn(\"dropout option adds dropout after all but last \"\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b6a1fbe9a205471389e359110fd20e24",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epochs:   0%|          | 0/15 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d96f4a7a3f624af8a825d2e9c6153c55",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training:   0%|          | 0/800 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tTrain Loss: 1.267 | Train Acc: 0.00%\n",
      "\t Val. Loss: 0.873 |  Val. Acc: 0.02%\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ca39fbafe6e74335b53a23abcc5d3cf8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training:   0%|          | 0/800 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tTrain Loss: 1.013 | Train Acc: 0.03%\n",
      "\t Val. Loss: 0.723 |  Val. Acc: 0.59%\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d3ab165077704e11a38edd04295b835b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training:   0%|          | 0/800 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tTrain Loss: 0.849 | Train Acc: 0.22%\n",
      "\t Val. Loss: 0.576 |  Val. Acc: 1.98%\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "562c24c7b15249448a6fd0aa18ba4289",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training:   0%|          | 0/800 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tTrain Loss: 0.715 | Train Acc: 1.16%\n",
      "\t Val. Loss: 0.475 |  Val. Acc: 5.27%\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "505ea329bb524997a908ae0dcc0c8028",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training:   0%|          | 0/800 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tTrain Loss: 0.613 | Train Acc: 2.88%\n",
      "\t Val. Loss: 0.412 |  Val. Acc: 8.96%\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4a56d067e7d84ad9ada21e788644e3b9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training:   0%|          | 0/800 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tTrain Loss: 0.550 | Train Acc: 4.52%\n",
      "\t Val. Loss: 0.381 |  Val. Acc: 11.43%\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "67c2613fc7e5498e8783ad34f1f0b1d4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training:   0%|          | 0/800 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tTrain Loss: 0.503 | Train Acc: 6.20%\n",
      "\t Val. Loss: 0.361 |  Val. Acc: 14.29%\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0c39ed978a05414787bd6bccfbcfa19d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training:   0%|          | 0/800 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tTrain Loss: 0.470 | Train Acc: 7.91%\n",
      "\t Val. Loss: 0.349 |  Val. Acc: 15.04%\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "93b0c550caf244febf98c24a15e85ec7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training:   0%|          | 0/800 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tTrain Loss: 0.445 | Train Acc: 9.28%\n",
      "\t Val. Loss: 0.328 |  Val. Acc: 17.04%\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5f8b84438c8e464a8befdae8b9befe85",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training:   0%|          | 0/800 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tTrain Loss: 0.424 | Train Acc: 10.36%\n",
      "\t Val. Loss: 0.314 |  Val. Acc: 17.68%\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "500ba7fd891d4a99ae35f81662540603",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training:   0%|          | 0/800 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tTrain Loss: 0.406 | Train Acc: 11.70%\n",
      "\t Val. Loss: 0.306 |  Val. Acc: 18.61%\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e2ce3ad49b0d493abfd468609722c0d8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training:   0%|          | 0/800 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tTrain Loss: 0.392 | Train Acc: 12.78%\n",
      "\t Val. Loss: 0.292 |  Val. Acc: 20.49%\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "830e813b336f48d08211fac6f5140ce0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training:   0%|          | 0/800 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tTrain Loss: 0.379 | Train Acc: 13.79%\n",
      "\t Val. Loss: 0.288 |  Val. Acc: 20.17%\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e2728e1e89044370b0e24ff46155563d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training:   0%|          | 0/800 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tTrain Loss: 0.369 | Train Acc: 14.61%\n",
      "\t Val. Loss: 0.282 |  Val. Acc: 20.98%\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7c36eff75eb34974aecb4efc875c2b61",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training:   0%|          | 0/800 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[34m\u001B[1mwandb\u001B[0m: \u001B[33mWARNING\u001B[0m Calling wandb.run.save without any arguments is deprecated.Changes to attributes are automatically persisted.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tTrain Loss: 0.361 | Train Acc: 15.59%\n",
      "\t Val. Loss: 0.277 |  Val. Acc: 21.90%\n",
      "ct_LSTM_bi_False_nl_1_bs_64_es_128_hs_128_endo_0.5_decdo_0.5_ne_15\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>train_acc</td><td>▁▁▁▂▂▃▄▅▅▆▆▇▇██</td></tr><tr><td>train_loss</td><td>█▆▅▄▃▂▂▂▂▁▁▁▁▁▁</td></tr><tr><td>valid_acc</td><td>▁▁▂▃▄▅▆▆▆▇▇█▇██</td></tr><tr><td>valid_loss</td><td>█▆▅▃▃▂▂▂▂▁▁▁▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>train_acc</td><td>0.15588</td></tr><tr><td>train_loss</td><td>0.36053</td></tr><tr><td>valid_acc</td><td>0.21904</td></tr><tr><td>valid_loss</td><td>0.27669</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">ancient-sweep-1</strong> at: <a href='https://wandb.ai/cs22m045/DL_ASSIGNMENT_3/runs/as4hm8y3' target=\"_blank\">https://wandb.ai/cs22m045/DL_ASSIGNMENT_3/runs/as4hm8y3</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20230516_071700-as4hm8y3/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error in callback <function _WandbInit._pause_backend at 0x786e3559fe20> (for post_run_cell):\n"
     ]
    },
    {
     "ename": "BrokenPipeError",
     "evalue": "[Errno 32] Broken pipe",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m\n",
      "\u001B[0;31mBrokenPipeError\u001B[0m                           Traceback (most recent call last)\n",
      "File \u001B[0;32m/opt/conda/lib/python3.10/site-packages/backcall/backcall.py:104\u001B[0m, in \u001B[0;36mcallback_prototype.<locals>.adapt.<locals>.adapted\u001B[0;34m(*args, **kwargs)\u001B[0m\n",
      "\u001B[1;32m    102\u001B[0m                 kwargs\u001B[38;5;241m.\u001B[39mpop(name)\n",
      "\u001B[1;32m    103\u001B[0m \u001B[38;5;66;03m#            print(args, kwargs, unmatched_pos, cut_positional, unmatched_kw)\u001B[39;00m\n",
      "\u001B[0;32m--> 104\u001B[0m             \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mcallback\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "\n",
      "File \u001B[0;32m/opt/conda/lib/python3.10/site-packages/wandb/sdk/wandb_init.py:419\u001B[0m, in \u001B[0;36m_WandbInit._pause_backend\u001B[0;34m(self)\u001B[0m\n",
      "\u001B[1;32m    417\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mbackend\u001B[38;5;241m.\u001B[39minterface \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n",
      "\u001B[1;32m    418\u001B[0m     logger\u001B[38;5;241m.\u001B[39minfo(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mpausing backend\u001B[39m\u001B[38;5;124m\"\u001B[39m)  \u001B[38;5;66;03m# type: ignore\u001B[39;00m\n",
      "\u001B[0;32m--> 419\u001B[0m     \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mbackend\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43minterface\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mpublish_pause\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n",
      "\n",
      "File \u001B[0;32m/opt/conda/lib/python3.10/site-packages/wandb/sdk/interface/interface.py:665\u001B[0m, in \u001B[0;36mInterfaceBase.publish_pause\u001B[0;34m(self)\u001B[0m\n",
      "\u001B[1;32m    663\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mpublish_pause\u001B[39m(\u001B[38;5;28mself\u001B[39m) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m:\n",
      "\u001B[1;32m    664\u001B[0m     pause \u001B[38;5;241m=\u001B[39m pb\u001B[38;5;241m.\u001B[39mPauseRequest()\n",
      "\u001B[0;32m--> 665\u001B[0m     \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_publish_pause\u001B[49m\u001B[43m(\u001B[49m\u001B[43mpause\u001B[49m\u001B[43m)\u001B[49m\n",
      "\n",
      "File \u001B[0;32m/opt/conda/lib/python3.10/site-packages/wandb/sdk/interface/interface_shared.py:340\u001B[0m, in \u001B[0;36mInterfaceShared._publish_pause\u001B[0;34m(self, pause)\u001B[0m\n",
      "\u001B[1;32m    338\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m_publish_pause\u001B[39m(\u001B[38;5;28mself\u001B[39m, pause: pb\u001B[38;5;241m.\u001B[39mPauseRequest) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m:\n",
      "\u001B[1;32m    339\u001B[0m     rec \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_make_request(pause\u001B[38;5;241m=\u001B[39mpause)\n",
      "\u001B[0;32m--> 340\u001B[0m     \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_publish\u001B[49m\u001B[43m(\u001B[49m\u001B[43mrec\u001B[49m\u001B[43m)\u001B[49m\n",
      "\n",
      "File \u001B[0;32m/opt/conda/lib/python3.10/site-packages/wandb/sdk/interface/interface_sock.py:51\u001B[0m, in \u001B[0;36mInterfaceSock._publish\u001B[0;34m(self, record, local)\u001B[0m\n",
      "\u001B[1;32m     49\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m_publish\u001B[39m(\u001B[38;5;28mself\u001B[39m, record: \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mpb.Record\u001B[39m\u001B[38;5;124m\"\u001B[39m, local: Optional[\u001B[38;5;28mbool\u001B[39m] \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m:\n",
      "\u001B[1;32m     50\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_assign(record)\n",
      "\u001B[0;32m---> 51\u001B[0m     \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_sock_client\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43msend_record_publish\u001B[49m\u001B[43m(\u001B[49m\u001B[43mrecord\u001B[49m\u001B[43m)\u001B[49m\n",
      "\n",
      "File \u001B[0;32m/opt/conda/lib/python3.10/site-packages/wandb/sdk/lib/sock_client.py:221\u001B[0m, in \u001B[0;36mSockClient.send_record_publish\u001B[0;34m(self, record)\u001B[0m\n",
      "\u001B[1;32m    219\u001B[0m server_req \u001B[38;5;241m=\u001B[39m spb\u001B[38;5;241m.\u001B[39mServerRequest()\n",
      "\u001B[1;32m    220\u001B[0m server_req\u001B[38;5;241m.\u001B[39mrecord_publish\u001B[38;5;241m.\u001B[39mCopyFrom(record)\n",
      "\u001B[0;32m--> 221\u001B[0m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43msend_server_request\u001B[49m\u001B[43m(\u001B[49m\u001B[43mserver_req\u001B[49m\u001B[43m)\u001B[49m\n",
      "\n",
      "File \u001B[0;32m/opt/conda/lib/python3.10/site-packages/wandb/sdk/lib/sock_client.py:155\u001B[0m, in \u001B[0;36mSockClient.send_server_request\u001B[0;34m(self, msg)\u001B[0m\n",
      "\u001B[1;32m    154\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21msend_server_request\u001B[39m(\u001B[38;5;28mself\u001B[39m, msg: Any) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m:\n",
      "\u001B[0;32m--> 155\u001B[0m     \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_send_message\u001B[49m\u001B[43m(\u001B[49m\u001B[43mmsg\u001B[49m\u001B[43m)\u001B[49m\n",
      "\n",
      "File \u001B[0;32m/opt/conda/lib/python3.10/site-packages/wandb/sdk/lib/sock_client.py:152\u001B[0m, in \u001B[0;36mSockClient._send_message\u001B[0;34m(self, msg)\u001B[0m\n",
      "\u001B[1;32m    150\u001B[0m header \u001B[38;5;241m=\u001B[39m struct\u001B[38;5;241m.\u001B[39mpack(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m<BI\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;28mord\u001B[39m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mW\u001B[39m\u001B[38;5;124m\"\u001B[39m), raw_size)\n",
      "\u001B[1;32m    151\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_lock:\n",
      "\u001B[0;32m--> 152\u001B[0m     \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_sendall_with_error_handle\u001B[49m\u001B[43m(\u001B[49m\u001B[43mheader\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m+\u001B[39;49m\u001B[43m \u001B[49m\u001B[43mdata\u001B[49m\u001B[43m)\u001B[49m\n",
      "\n",
      "File \u001B[0;32m/opt/conda/lib/python3.10/site-packages/wandb/sdk/lib/sock_client.py:130\u001B[0m, in \u001B[0;36mSockClient._sendall_with_error_handle\u001B[0;34m(self, data)\u001B[0m\n",
      "\u001B[1;32m    128\u001B[0m start_time \u001B[38;5;241m=\u001B[39m time\u001B[38;5;241m.\u001B[39mmonotonic()\n",
      "\u001B[1;32m    129\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n",
      "\u001B[0;32m--> 130\u001B[0m     sent \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_sock\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43msend\u001B[49m\u001B[43m(\u001B[49m\u001B[43mdata\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[1;32m    131\u001B[0m     \u001B[38;5;66;03m# sent equal to 0 indicates a closed socket\u001B[39;00m\n",
      "\u001B[1;32m    132\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m sent \u001B[38;5;241m==\u001B[39m \u001B[38;5;241m0\u001B[39m:\n",
      "\n",
      "\u001B[0;31mBrokenPipeError\u001B[0m: [Errno 32] Broken pipe"
     ]
    }
   ],
   "source": [
    "sweep_id = wandb.sweep(sweep_config, entity=\"cs22m045\", project=\"DL_ASSIGNMENT_3\")\n",
    "wandb.agent(sweep_id,run_wandb, count=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error in callback <function _WandbInit._resume_backend at 0x786e3559fd90> (for pre_run_cell):\n"
     ]
    },
    {
     "ename": "BrokenPipeError",
     "evalue": "[Errno 32] Broken pipe",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m\n",
      "\u001B[0;31mBrokenPipeError\u001B[0m                           Traceback (most recent call last)\n",
      "File \u001B[0;32m/opt/conda/lib/python3.10/site-packages/backcall/backcall.py:104\u001B[0m, in \u001B[0;36mcallback_prototype.<locals>.adapt.<locals>.adapted\u001B[0;34m(*args, **kwargs)\u001B[0m\n",
      "\u001B[1;32m    102\u001B[0m                 kwargs\u001B[38;5;241m.\u001B[39mpop(name)\n",
      "\u001B[1;32m    103\u001B[0m \u001B[38;5;66;03m#            print(args, kwargs, unmatched_pos, cut_positional, unmatched_kw)\u001B[39;00m\n",
      "\u001B[0;32m--> 104\u001B[0m             \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mcallback\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "\n",
      "File \u001B[0;32m/opt/conda/lib/python3.10/site-packages/wandb/sdk/wandb_init.py:424\u001B[0m, in \u001B[0;36m_WandbInit._resume_backend\u001B[0;34m(self)\u001B[0m\n",
      "\u001B[1;32m    422\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mbackend \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mbackend\u001B[38;5;241m.\u001B[39minterface \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n",
      "\u001B[1;32m    423\u001B[0m     logger\u001B[38;5;241m.\u001B[39minfo(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mresuming backend\u001B[39m\u001B[38;5;124m\"\u001B[39m)  \u001B[38;5;66;03m# type: ignore\u001B[39;00m\n",
      "\u001B[0;32m--> 424\u001B[0m     \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mbackend\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43minterface\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mpublish_resume\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n",
      "\n",
      "File \u001B[0;32m/opt/conda/lib/python3.10/site-packages/wandb/sdk/interface/interface.py:673\u001B[0m, in \u001B[0;36mInterfaceBase.publish_resume\u001B[0;34m(self)\u001B[0m\n",
      "\u001B[1;32m    671\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mpublish_resume\u001B[39m(\u001B[38;5;28mself\u001B[39m) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m:\n",
      "\u001B[1;32m    672\u001B[0m     resume \u001B[38;5;241m=\u001B[39m pb\u001B[38;5;241m.\u001B[39mResumeRequest()\n",
      "\u001B[0;32m--> 673\u001B[0m     \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_publish_resume\u001B[49m\u001B[43m(\u001B[49m\u001B[43mresume\u001B[49m\u001B[43m)\u001B[49m\n",
      "\n",
      "File \u001B[0;32m/opt/conda/lib/python3.10/site-packages/wandb/sdk/interface/interface_shared.py:344\u001B[0m, in \u001B[0;36mInterfaceShared._publish_resume\u001B[0;34m(self, resume)\u001B[0m\n",
      "\u001B[1;32m    342\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m_publish_resume\u001B[39m(\u001B[38;5;28mself\u001B[39m, resume: pb\u001B[38;5;241m.\u001B[39mResumeRequest) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m:\n",
      "\u001B[1;32m    343\u001B[0m     rec \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_make_request(resume\u001B[38;5;241m=\u001B[39mresume)\n",
      "\u001B[0;32m--> 344\u001B[0m     \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_publish\u001B[49m\u001B[43m(\u001B[49m\u001B[43mrec\u001B[49m\u001B[43m)\u001B[49m\n",
      "\n",
      "File \u001B[0;32m/opt/conda/lib/python3.10/site-packages/wandb/sdk/interface/interface_sock.py:51\u001B[0m, in \u001B[0;36mInterfaceSock._publish\u001B[0;34m(self, record, local)\u001B[0m\n",
      "\u001B[1;32m     49\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m_publish\u001B[39m(\u001B[38;5;28mself\u001B[39m, record: \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mpb.Record\u001B[39m\u001B[38;5;124m\"\u001B[39m, local: Optional[\u001B[38;5;28mbool\u001B[39m] \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m:\n",
      "\u001B[1;32m     50\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_assign(record)\n",
      "\u001B[0;32m---> 51\u001B[0m     \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_sock_client\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43msend_record_publish\u001B[49m\u001B[43m(\u001B[49m\u001B[43mrecord\u001B[49m\u001B[43m)\u001B[49m\n",
      "\n",
      "File \u001B[0;32m/opt/conda/lib/python3.10/site-packages/wandb/sdk/lib/sock_client.py:221\u001B[0m, in \u001B[0;36mSockClient.send_record_publish\u001B[0;34m(self, record)\u001B[0m\n",
      "\u001B[1;32m    219\u001B[0m server_req \u001B[38;5;241m=\u001B[39m spb\u001B[38;5;241m.\u001B[39mServerRequest()\n",
      "\u001B[1;32m    220\u001B[0m server_req\u001B[38;5;241m.\u001B[39mrecord_publish\u001B[38;5;241m.\u001B[39mCopyFrom(record)\n",
      "\u001B[0;32m--> 221\u001B[0m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43msend_server_request\u001B[49m\u001B[43m(\u001B[49m\u001B[43mserver_req\u001B[49m\u001B[43m)\u001B[49m\n",
      "\n",
      "File \u001B[0;32m/opt/conda/lib/python3.10/site-packages/wandb/sdk/lib/sock_client.py:155\u001B[0m, in \u001B[0;36mSockClient.send_server_request\u001B[0;34m(self, msg)\u001B[0m\n",
      "\u001B[1;32m    154\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21msend_server_request\u001B[39m(\u001B[38;5;28mself\u001B[39m, msg: Any) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m:\n",
      "\u001B[0;32m--> 155\u001B[0m     \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_send_message\u001B[49m\u001B[43m(\u001B[49m\u001B[43mmsg\u001B[49m\u001B[43m)\u001B[49m\n",
      "\n",
      "File \u001B[0;32m/opt/conda/lib/python3.10/site-packages/wandb/sdk/lib/sock_client.py:152\u001B[0m, in \u001B[0;36mSockClient._send_message\u001B[0;34m(self, msg)\u001B[0m\n",
      "\u001B[1;32m    150\u001B[0m header \u001B[38;5;241m=\u001B[39m struct\u001B[38;5;241m.\u001B[39mpack(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m<BI\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;28mord\u001B[39m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mW\u001B[39m\u001B[38;5;124m\"\u001B[39m), raw_size)\n",
      "\u001B[1;32m    151\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_lock:\n",
      "\u001B[0;32m--> 152\u001B[0m     \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_sendall_with_error_handle\u001B[49m\u001B[43m(\u001B[49m\u001B[43mheader\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m+\u001B[39;49m\u001B[43m \u001B[49m\u001B[43mdata\u001B[49m\u001B[43m)\u001B[49m\n",
      "\n",
      "File \u001B[0;32m/opt/conda/lib/python3.10/site-packages/wandb/sdk/lib/sock_client.py:130\u001B[0m, in \u001B[0;36mSockClient._sendall_with_error_handle\u001B[0;34m(self, data)\u001B[0m\n",
      "\u001B[1;32m    128\u001B[0m start_time \u001B[38;5;241m=\u001B[39m time\u001B[38;5;241m.\u001B[39mmonotonic()\n",
      "\u001B[1;32m    129\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n",
      "\u001B[0;32m--> 130\u001B[0m     sent \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_sock\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43msend\u001B[49m\u001B[43m(\u001B[49m\u001B[43mdata\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[1;32m    131\u001B[0m     \u001B[38;5;66;03m# sent equal to 0 indicates a closed socket\u001B[39;00m\n",
      "\u001B[1;32m    132\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m sent \u001B[38;5;241m==\u001B[39m \u001B[38;5;241m0\u001B[39m:\n",
      "\n",
      "\u001B[0;31mBrokenPipeError\u001B[0m: [Errno 32] Broken pipe"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error in callback <function _WandbInit._pause_backend at 0x786e3559fe20> (for post_run_cell):\n"
     ]
    },
    {
     "ename": "BrokenPipeError",
     "evalue": "[Errno 32] Broken pipe",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m\n",
      "\u001B[0;31mBrokenPipeError\u001B[0m                           Traceback (most recent call last)\n",
      "File \u001B[0;32m/opt/conda/lib/python3.10/site-packages/backcall/backcall.py:104\u001B[0m, in \u001B[0;36mcallback_prototype.<locals>.adapt.<locals>.adapted\u001B[0;34m(*args, **kwargs)\u001B[0m\n",
      "\u001B[1;32m    102\u001B[0m                 kwargs\u001B[38;5;241m.\u001B[39mpop(name)\n",
      "\u001B[1;32m    103\u001B[0m \u001B[38;5;66;03m#            print(args, kwargs, unmatched_pos, cut_positional, unmatched_kw)\u001B[39;00m\n",
      "\u001B[0;32m--> 104\u001B[0m             \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mcallback\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "\n",
      "File \u001B[0;32m/opt/conda/lib/python3.10/site-packages/wandb/sdk/wandb_init.py:419\u001B[0m, in \u001B[0;36m_WandbInit._pause_backend\u001B[0;34m(self)\u001B[0m\n",
      "\u001B[1;32m    417\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mbackend\u001B[38;5;241m.\u001B[39minterface \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n",
      "\u001B[1;32m    418\u001B[0m     logger\u001B[38;5;241m.\u001B[39minfo(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mpausing backend\u001B[39m\u001B[38;5;124m\"\u001B[39m)  \u001B[38;5;66;03m# type: ignore\u001B[39;00m\n",
      "\u001B[0;32m--> 419\u001B[0m     \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mbackend\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43minterface\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mpublish_pause\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n",
      "\n",
      "File \u001B[0;32m/opt/conda/lib/python3.10/site-packages/wandb/sdk/interface/interface.py:665\u001B[0m, in \u001B[0;36mInterfaceBase.publish_pause\u001B[0;34m(self)\u001B[0m\n",
      "\u001B[1;32m    663\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mpublish_pause\u001B[39m(\u001B[38;5;28mself\u001B[39m) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m:\n",
      "\u001B[1;32m    664\u001B[0m     pause \u001B[38;5;241m=\u001B[39m pb\u001B[38;5;241m.\u001B[39mPauseRequest()\n",
      "\u001B[0;32m--> 665\u001B[0m     \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_publish_pause\u001B[49m\u001B[43m(\u001B[49m\u001B[43mpause\u001B[49m\u001B[43m)\u001B[49m\n",
      "\n",
      "File \u001B[0;32m/opt/conda/lib/python3.10/site-packages/wandb/sdk/interface/interface_shared.py:340\u001B[0m, in \u001B[0;36mInterfaceShared._publish_pause\u001B[0;34m(self, pause)\u001B[0m\n",
      "\u001B[1;32m    338\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m_publish_pause\u001B[39m(\u001B[38;5;28mself\u001B[39m, pause: pb\u001B[38;5;241m.\u001B[39mPauseRequest) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m:\n",
      "\u001B[1;32m    339\u001B[0m     rec \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_make_request(pause\u001B[38;5;241m=\u001B[39mpause)\n",
      "\u001B[0;32m--> 340\u001B[0m     \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_publish\u001B[49m\u001B[43m(\u001B[49m\u001B[43mrec\u001B[49m\u001B[43m)\u001B[49m\n",
      "\n",
      "File \u001B[0;32m/opt/conda/lib/python3.10/site-packages/wandb/sdk/interface/interface_sock.py:51\u001B[0m, in \u001B[0;36mInterfaceSock._publish\u001B[0;34m(self, record, local)\u001B[0m\n",
      "\u001B[1;32m     49\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m_publish\u001B[39m(\u001B[38;5;28mself\u001B[39m, record: \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mpb.Record\u001B[39m\u001B[38;5;124m\"\u001B[39m, local: Optional[\u001B[38;5;28mbool\u001B[39m] \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m:\n",
      "\u001B[1;32m     50\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_assign(record)\n",
      "\u001B[0;32m---> 51\u001B[0m     \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_sock_client\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43msend_record_publish\u001B[49m\u001B[43m(\u001B[49m\u001B[43mrecord\u001B[49m\u001B[43m)\u001B[49m\n",
      "\n",
      "File \u001B[0;32m/opt/conda/lib/python3.10/site-packages/wandb/sdk/lib/sock_client.py:221\u001B[0m, in \u001B[0;36mSockClient.send_record_publish\u001B[0;34m(self, record)\u001B[0m\n",
      "\u001B[1;32m    219\u001B[0m server_req \u001B[38;5;241m=\u001B[39m spb\u001B[38;5;241m.\u001B[39mServerRequest()\n",
      "\u001B[1;32m    220\u001B[0m server_req\u001B[38;5;241m.\u001B[39mrecord_publish\u001B[38;5;241m.\u001B[39mCopyFrom(record)\n",
      "\u001B[0;32m--> 221\u001B[0m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43msend_server_request\u001B[49m\u001B[43m(\u001B[49m\u001B[43mserver_req\u001B[49m\u001B[43m)\u001B[49m\n",
      "\n",
      "File \u001B[0;32m/opt/conda/lib/python3.10/site-packages/wandb/sdk/lib/sock_client.py:155\u001B[0m, in \u001B[0;36mSockClient.send_server_request\u001B[0;34m(self, msg)\u001B[0m\n",
      "\u001B[1;32m    154\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21msend_server_request\u001B[39m(\u001B[38;5;28mself\u001B[39m, msg: Any) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m:\n",
      "\u001B[0;32m--> 155\u001B[0m     \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_send_message\u001B[49m\u001B[43m(\u001B[49m\u001B[43mmsg\u001B[49m\u001B[43m)\u001B[49m\n",
      "\n",
      "File \u001B[0;32m/opt/conda/lib/python3.10/site-packages/wandb/sdk/lib/sock_client.py:152\u001B[0m, in \u001B[0;36mSockClient._send_message\u001B[0;34m(self, msg)\u001B[0m\n",
      "\u001B[1;32m    150\u001B[0m header \u001B[38;5;241m=\u001B[39m struct\u001B[38;5;241m.\u001B[39mpack(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m<BI\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;28mord\u001B[39m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mW\u001B[39m\u001B[38;5;124m\"\u001B[39m), raw_size)\n",
      "\u001B[1;32m    151\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_lock:\n",
      "\u001B[0;32m--> 152\u001B[0m     \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_sendall_with_error_handle\u001B[49m\u001B[43m(\u001B[49m\u001B[43mheader\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m+\u001B[39;49m\u001B[43m \u001B[49m\u001B[43mdata\u001B[49m\u001B[43m)\u001B[49m\n",
      "\n",
      "File \u001B[0;32m/opt/conda/lib/python3.10/site-packages/wandb/sdk/lib/sock_client.py:130\u001B[0m, in \u001B[0;36mSockClient._sendall_with_error_handle\u001B[0;34m(self, data)\u001B[0m\n",
      "\u001B[1;32m    128\u001B[0m start_time \u001B[38;5;241m=\u001B[39m time\u001B[38;5;241m.\u001B[39mmonotonic()\n",
      "\u001B[1;32m    129\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n",
      "\u001B[0;32m--> 130\u001B[0m     sent \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_sock\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43msend\u001B[49m\u001B[43m(\u001B[49m\u001B[43mdata\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[1;32m    131\u001B[0m     \u001B[38;5;66;03m# sent equal to 0 indicates a closed socket\u001B[39;00m\n",
      "\u001B[1;32m    132\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m sent \u001B[38;5;241m==\u001B[39m \u001B[38;5;241m0\u001B[39m:\n",
      "\n",
      "\u001B[0;31mBrokenPipeError\u001B[0m: [Errno 32] Broken pipe"
     ]
    }
   ],
   "source": [
    "\n",
    "# N_EPOCHS = 1\n",
    "# CLIP = 1\n",
    "# INPUT_DIM = input_vocab_size\n",
    "# OUTPUT_DIM = output_vocab_size\n",
    "# ENC_EMB_DIM = 128\n",
    "# DEC_EMB_DIM = 128\n",
    "# HIDDEN_SIZE = 256\n",
    "# num_layers = 1\n",
    "# ENC_DROPOUT = 0.5\n",
    "# DEC_DROPOUT = 0.5\n",
    "# TEACHER_FORCING = 0.5\n",
    "# BI_DIRECTION = True\n",
    "# CELL_TYPE = 'LSTM'\n",
    "# pred_src = \"$bindya|\"\n",
    "# pred_trg = '$बिन्द्या|'\n",
    "\n",
    "# enc = Encoder(input_size=INPUT_DIM, embedding_size=ENC_EMB_DIM, hidden_size=HIDDEN_SIZE, num_layers=num_layers, dropout=ENC_DROPOUT, cell_type=CELL_TYPE, bidirectional=BI_DIRECTION)\n",
    "# dec = Decoder(output_dim=OUTPUT_DIM, emb_dim=DEC_EMB_DIM, hidden_size=HIDDEN_SIZE, num_layers=num_layers, dropout=DEC_DROPOUT, cell_type=CELL_TYPE, bidirectional=BI_DIRECTION)\n",
    "\n",
    "# model = Seq2Seq(enc, dec, device, teacher_forcing_ratio=TEACHER_FORCING).to(device)\n",
    "# def init_weights(m):\n",
    "#     for name, param in m.named_parameters():\n",
    "#         nn.init.uniform_(param.data, -0.08, 0.08)\n",
    "\n",
    "\n",
    "# model.apply(init_weights)\n",
    "# optimizer = optim.Adam(model.parameters())\n",
    "# criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# best_valid_loss = float('inf')\n",
    "# gbar = tqdm(range(1, N_EPOCHS + 1),position=1,leave=True, desc='Epochs', total=N_EPOCHS)\n",
    "# for epoch in gbar:\n",
    "#     train_loss, train_accuracy = train(model, train_dataloader, optimizer, criterion, CLIP)\n",
    "#     valid_loss, valid_accuracy = evaluate(model, valid_dataloader, criterion)\n",
    "#     gbar.set_postfix(train_loss=train_loss, train_acc=train_accuracy, val_loss=valid_loss, val_acc=valid_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
