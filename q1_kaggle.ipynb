{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "outputs": [],
   "source": [
    "#  [code] {\"jupyter\":{\"outputs_hidden\":false}}"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "outputs": [],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load\n",
    "# Input data files are available in the read-only \"../input/\" directory\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "# for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "#     for filename in filenames:\n",
    "#         os.path.join(dirname, filename)\n",
    "\n",
    "\n",
    "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\"\n",
    "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "if 'kaggle' in os.environ['PYTHONPATH']:\n",
    "    print('Running on Kaggle')\n",
    "else:\n",
    "    print('Running on local')\n",
    "\n",
    "print(os.environ['PYTHONPATH'])"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "## Import data"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "outputs": [],
   "source": [
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.autograd import Variable\n",
    "import torch.nn.functional as F\n",
    "import pickle\n",
    "import torch\n",
    "import random\n",
    "from torch.utils.data import Dataset, DataLoader"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "outputs": [],
   "source": [
    "# Instantiates the device to be used as GPU/CPU based on availability\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Executing on \" + (\"cuda:0\" if torch.cuda.is_available() else \"cpu\"))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "outputs": [],
   "source": [
    "df_train = pd.read_csv(\"Data/hin/hin_train.csv\")\n",
    "df_test = pd.read_csv('Data/hin/hin_test.csv')\n",
    "df_valid = pd.read_csv('Data/hin/hin_valid.csv')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "outputs": [],
   "source": [
    "df_train = df_train.iloc[:2000]\n",
    "df_test = df_test.iloc[:200]\n",
    "df_valid = df_valid.iloc[:200]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "outputs": [],
   "source": [
    "PAD_CHAR = '_'\n",
    "EOW_CHAR = '|'\n",
    "SOW_CHAR = '$'\n",
    "BATCH_SIZE = 3"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "outputs": [],
   "source": [
    "eng_alphabets = [chr(alpha) for alpha in range(ord('a'), ord('z') + 1)]\n",
    "# eng_alpha2index = {pad_char:0}\n",
    "in_dict = {PAD_CHAR: 0, EOW_CHAR: 1, SOW_CHAR: 2}\n",
    "for index, alpha in enumerate(eng_alphabets):\n",
    "\tin_dict[alpha] = index + 3\n",
    "print(in_dict)\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "outputs": [],
   "source": [
    "hindi_alphabets = [chr(alpha) for alpha in range(2304, 2432)]\n",
    "hindi_alphabet_size = len(hindi_alphabets)\n",
    "out_dict = {PAD_CHAR: 0, EOW_CHAR: 1, SOW_CHAR: 2}\n",
    "for index, alpha in enumerate(hindi_alphabets):\n",
    "\tout_dict[alpha] = index + 3"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "outputs": [],
   "source": [
    "print(out_dict)\n",
    "print(len(out_dict))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [],
   "source": [
    "if df_train.iloc[0][0][0] != SOW_CHAR:\n",
    "\tdf_train = df_train.iloc[:, ].apply(lambda x: SOW_CHAR + x + EOW_CHAR)\n",
    "\tdf_test = df_test.iloc[:, ].apply(lambda x: SOW_CHAR + x + EOW_CHAR)\n",
    "\tdf_valid = df_valid.iloc[:, ].apply(lambda x: SOW_CHAR + x + EOW_CHAR)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-02T16:44:43.301508600Z",
     "start_time": "2023-05-02T16:44:43.256516100Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [],
   "source": [
    "df_train = df_train.set_axis(['X', 'Y'], axis=1)\n",
    "df_valid = df_valid.set_axis(['X', 'Y'], axis=1)\n",
    "df_test = df_test.set_axis(['X', 'Y'], axis=1)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-02T16:44:43.404838Z",
     "start_time": "2023-05-02T16:44:43.305968900Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                    X                  Y\n",
      "0           $bindhya|         $बिन्द्या|\n",
      "1         $kirankant|         $किरणकांत|\n",
      "2       $yagyopaveet|        $यज्ञोपवीत|\n",
      "3           $ratania|          $रटानिया|\n",
      "4        $vaganyache|        $वागण्याचे|\n",
      "...               ...                ...\n",
      "1995    $culmination|        $कल्मिनेशन|\n",
      "1996  $complimentary|  $कॉम्प्लीमेंट्री|\n",
      "1997      $chattoraj|         $चट्टोराज|\n",
      "1998     $kaareegaro|          $कारीगरो|\n",
      "1999    $rugnambabat|      $रुग्णांबाबत|\n",
      "\n",
      "[2000 rows x 2 columns]\n",
      "                  X              Y\n",
      "0       $sikhaaega|      $सिखाएगा|\n",
      "1           $learn|         $लर्न|\n",
      "2        $twitters|     $ट्विटर्स|\n",
      "3     $tirunelveli|  $तिरुनेलवेली|\n",
      "4    $independence|  $इंडिपेंडेंस|\n",
      "..              ...            ...\n",
      "195         $ochoa|         $ओकोआ|\n",
      "196       $science|        $साइंस|\n",
      "197     $sarkarein|      $सरकारें|\n",
      "198     $bremerton|      $ब्रेमटन|\n",
      "199      $gurupado|      $गुरुपदो|\n",
      "\n",
      "[200 rows x 2 columns]\n",
      "                  X              Y\n",
      "0           $bajai|         $बजाई|\n",
      "1       $sanghthan|        $संघठन|\n",
      "2         $haiwaan|        $हैवान|\n",
      "3         $nilgiri|      $नीलगिरि|\n",
      "4       $drutgrami|  $द्रुतग्रामी|\n",
      "...             ...            ...\n",
      "4090     $paranshu|       $परांशु|\n",
      "4091    $romanchit|     $रोमांचित|\n",
      "4092  $ekamreshwar|  $एकाम्रेश्वर|\n",
      "4093    $bluetooth|    $ब्ल्यूटूथ|\n",
      "4094    $govindram|   $गोविंद्राम|\n",
      "\n",
      "[4095 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "print(df_train)\n",
    "print(df_test)\n",
    "print(df_valid)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-02T16:44:43.424398900Z",
     "start_time": "2023-05-02T16:44:43.325224200Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max input length 24\n",
      "max output length 22\n",
      "max_length 24\n"
     ]
    }
   ],
   "source": [
    "max_input_length = max(df_train.iloc[:, 0].apply(lambda x: len(x)).max(),\n",
    "\t\t\t\t\t   df_test.iloc[:, 0].apply(lambda x: len(x)).max(),\n",
    "\t\t\t\t\t   df_valid.iloc[:, 0].apply(lambda x: len(x)).max())\n",
    "\n",
    "max_output_length = max(df_train.iloc[:, 1].apply(lambda x: len(x)).max(),\n",
    "\t\t\t\t\t\tdf_test.iloc[:, 1].apply(lambda x: len(x)).max(),\n",
    "\t\t\t\t\t\tdf_valid.iloc[:, 1].apply(lambda x: len(x)).max())\n",
    "\n",
    "print(\"max input length\", max_input_length)\n",
    "print(\"max output length\", max_output_length)\n",
    "MAX_LENGTH = max(max_input_length, max_output_length)\n",
    "print(\"max_length\", MAX_LENGTH)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-02T16:44:43.424398900Z",
     "start_time": "2023-05-02T16:44:43.361616700Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input Character max 29\n",
      "output Character size 131\n"
     ]
    }
   ],
   "source": [
    "input_vocab_size = len(in_dict)\n",
    "output_vocab_size = len(out_dict)\n",
    "print(\"Input Character max\", input_vocab_size)\n",
    "print(\"output Character size\", output_vocab_size)\n",
    "\n",
    "train = df_train.values.tolist()\n",
    "valid = df_valid.values.tolist()\n",
    "test = df_test.values.tolist()\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-02T16:44:43.424398900Z",
     "start_time": "2023-05-02T16:44:43.391628Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input Character max 29\n",
      "output Character size 131\n"
     ]
    }
   ],
   "source": [
    "input_vocab_size = len(in_dict)\n",
    "output_vocab_size = len(out_dict)\n",
    "print(\"Input Character max\", input_vocab_size)\n",
    "print(\"output Character size\", output_vocab_size)\n",
    "\n",
    "train = df_train.values.tolist()\n",
    "valid = df_valid.values.tolist()\n",
    "test = df_test.values.tolist()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-02T16:44:43.424398900Z",
     "start_time": "2023-05-02T16:44:43.404838Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [],
   "source": [
    "def inputToTensor(line):\n",
    "\t# print([in_dict[x] for x in line])\n",
    "\ttensor = torch.tensor(data=([in_dict[x] for x in line]), dtype=torch.long)\n",
    "\treturn tensor\n",
    "\n",
    "\n",
    "def charToTensor(char, dic=in_dict):\n",
    "\ttensor = torch.zeros(len(dic))\n",
    "\ttensor[dic[char]] = 1\n",
    "\treturn tensor\n",
    "\n",
    "\n",
    "def outToTensor(word):\n",
    "\ttensor = torch.tensor([out_dict[x] for x in word])\n",
    "\treturn tensor\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-02T16:44:43.596276200Z",
     "start_time": "2023-05-02T16:44:43.424398900Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 2,  4, 11, 16,  6, 10, 27,  3,  1])\n"
     ]
    }
   ],
   "source": [
    "print(inputToTensor(train[0][0]))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-02T16:44:43.611912600Z",
     "start_time": "2023-05-02T16:44:43.471755200Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "$किरणकांत|\n"
     ]
    }
   ],
   "source": [
    "print(train[1][1])\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-02T16:44:43.611912600Z",
     "start_time": "2023-05-02T16:44:43.484831200Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "outputs": [
    {
     "data": {
      "text/plain": "tensor([ 2,  4, 11, 16,  6, 10, 27,  3,  1])"
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputToTensor(\"$bindhya|\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-02T16:44:43.628022200Z",
     "start_time": "2023-05-02T16:44:43.506448300Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'_': 0, '|': 1, '$': 2, 'a': 3, 'b': 4, 'c': 5, 'd': 6, 'e': 7, 'f': 8, 'g': 9, 'h': 10, 'i': 11, 'j': 12, 'k': 13, 'l': 14, 'm': 15, 'n': 16, 'o': 17, 'p': 18, 'q': 19, 'r': 20, 's': 21, 't': 22, 'u': 23, 'v': 24, 'w': 25, 'x': 26, 'y': 27, 'z': 28}\n"
     ]
    }
   ],
   "source": [
    "print(in_dict)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-02T16:44:43.628022200Z",
     "start_time": "2023-05-02T16:44:43.523391500Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([10,  7, 14, 14, 17])\n"
     ]
    }
   ],
   "source": [
    "print(inputToTensor(\"hello\"))\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-02T16:44:43.628022200Z",
     "start_time": "2023-05-02T16:44:43.541792400Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "outputs": [],
   "source": [
    "def generate_batch(data_batch):\n",
    "\t#     print(data_batch)\n",
    "\ttensor_data = [inputToTensor(x[0].ljust(max_input_length, PAD_CHAR)) for x in data_batch]\n",
    "\ttensor_target = [outToTensor(x[1].ljust(max_output_length, PAD_CHAR)) for x in data_batch]\n",
    "\tpadded_input_batch = (torch.nn.utils.rnn.pad_sequence(tensor_data, batch_first=True, padding_value=1).T).to(device)\n",
    "\tpadded_output_batch = (torch.nn.utils.rnn.pad_sequence(tensor_target, batch_first=True, padding_value=1).T).to(device)\n",
    "\t#     print(tensor_data)\n",
    "\t#     print(padded_input_batch.shape)\n",
    "\t#     print(padded_output_batch.shape)\n",
    "\treturn padded_input_batch, padded_output_batch"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-02T16:44:43.631535700Z",
     "start_time": "2023-05-02T16:44:43.553913Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "outputs": [],
   "source": [
    "train_dataloader = DataLoader(train, batch_size=BATCH_SIZE, shuffle=True, collate_fn=generate_batch)\n",
    "test_dataloader = DataLoader(test, batch_size=BATCH_SIZE, shuffle=False, collate_fn=generate_batch)\n",
    "valid_dataloader = DataLoader(test, batch_size=BATCH_SIZE, shuffle=False, collate_fn=generate_batch)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-02T16:44:43.631535700Z",
     "start_time": "2023-05-02T16:44:43.571689600Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([24, 3])\n",
      "torch.Size([22, 3])\n"
     ]
    }
   ],
   "source": [
    "\n",
    "for data,target in train_dataloader:\n",
    "    # print(data)\n",
    "    # print(target)\n",
    "    print(data.shape)\n",
    "    print(target.shape)\n",
    "    if True:\n",
    "        break"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-02T16:44:43.631535700Z",
     "start_time": "2023-05-02T16:44:43.596276200Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "outputs": [],
   "source": [
    "class Encoder(nn.Module):\n",
    "    def __init__(self, input_dim, emb_dim, hid_dim, n_layers, dropout):\n",
    "        super().__init__()\n",
    "        self.hid_dim = hid_dim\n",
    "        self.n_layers = n_layers\n",
    "        self.embedding = nn.Embedding(input_dim, emb_dim)\n",
    "        self.rnn = nn.LSTM(emb_dim, hid_dim, n_layers, dropout = dropout)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self, src):\n",
    "        #src = [src len, batch size]\n",
    "        # print(\"encoder forward prop\")\n",
    "\n",
    "        embedded = self.dropout(self.embedding(src))\n",
    "        # embedded = embedded.permute(1,0,2)\n",
    "        # print(\"encoder embedded shape\", embedded.shape)\n",
    "        #embedded = [src len, batch size, emb dim]\n",
    "        outputs, (hidden, cell) = self.rnn(embedded)\n",
    "        # print(\"encoder hidden dimension\", hidden.shape)\n",
    "        # print(\"encoder output dimension\", outputs.shape)\n",
    "        # print(\"encoder cell dimension\", cell.shape)\n",
    "        #outputs = [src len, batch size, hid dim * n directions]\n",
    "        #hidden = [n layers * n directions, batch size, hid dim]\n",
    "        #cell = [n layers * n directions, batch size, hid dim]\n",
    "        #outputs are always from the top hidden layer\n",
    "        return hidden, cell"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-02T16:44:43.631535700Z",
     "start_time": "2023-05-02T16:44:43.596276200Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "outputs": [],
   "source": [
    "class Decoder(nn.Module):\n",
    "    def __init__(self, output_dim, emb_dim, hid_dim, n_layers, dropout):\n",
    "        super().__init__()\n",
    "\n",
    "        self.output_dim = output_dim\n",
    "        self.hid_dim = hid_dim\n",
    "        self.n_layers = n_layers\n",
    "\n",
    "        self.embedding = nn.Embedding(output_dim, emb_dim)\n",
    "\n",
    "        self.rnn = nn.LSTM(emb_dim, hid_dim, n_layers, dropout = dropout)\n",
    "\n",
    "        self.fc_out = nn.Linear(hid_dim, output_dim)\n",
    "\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self, input, hidden, cell):\n",
    "\n",
    "        #input = [batch size]\n",
    "        #hidden = [n layers * n directions, batch size, hid dim]\n",
    "        #cell = [n layers * n directions, batch size, hid dim]\n",
    "\n",
    "        #n directions in the decoder will both always be 1, therefore:\n",
    "        #hidden = [n layers, batch size, hid dim]\n",
    "        #context = [n layers, batch size, hid dim]\n",
    "        # print(\"decoder hidden shape\", hidden.shape)\n",
    "        # print(\"decoder context shape\", cell.shape)\n",
    "        input = input.unsqueeze(0)\n",
    "\n",
    "        #input = [1, batch size]\n",
    "\n",
    "        embedded = self.dropout(self.embedding(input))\n",
    "        # print(\"decoder embedded shape\", embedded.shape)\n",
    "        #embedded = [1, batch size, emb dim]\n",
    "\n",
    "        output, (hidden, cell) = self.rnn(embedded, (hidden, cell))\n",
    "        # print(\"decoder output shape\", output.shape)\n",
    "        # print(\"decoder hidden shape\", hidden.shape)\n",
    "        # print(\"decoder context shape\", cell.shape)\n",
    "        #output = [seq len, batch size, hid dim * n directions]\n",
    "        #hidden = [n layers * n directions, batch size, hid dim]\n",
    "        #cell = [n layers * n directions, batch size, hid dim]\n",
    "\n",
    "        #seq len and n directions will always be 1 in the decoder, therefore:\n",
    "        #output = [1, batch size, hid dim]\n",
    "        #hidden = [n layers, batch size, hid dim]\n",
    "        #cell = [n layers, batch size, hid dim]\n",
    "\n",
    "        prediction = self.fc_out(output.squeeze(0))\n",
    "\n",
    "        #prediction = [batch size, output dim]\n",
    "        # print(\"decoder prediction shape\", prediction.shape)\n",
    "        return prediction, hidden, cell"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-02T16:44:43.631535700Z",
     "start_time": "2023-05-02T16:44:43.611912600Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "outputs": [],
   "source": [
    "class Seq2Seq(nn.Module):\n",
    "    def __init__(self, encoder, decoder, device):\n",
    "        super().__init__()\n",
    "\n",
    "        self.encoder = encoder\n",
    "        self.decoder = decoder\n",
    "        self.device = device\n",
    "\n",
    "        assert encoder.hid_dim == decoder.hid_dim, \\\n",
    "            \"Hidden dimensions of encoder and decoder must be equal!\"\n",
    "        assert encoder.n_layers == decoder.n_layers, \\\n",
    "            \"Encoder and decoder must have equal number of layers!\"\n",
    "\n",
    "    def forward(self, src, trg, teacher_forcing_ratio = 0.5):\n",
    "        # src = src.permute(1,0)\n",
    "        # trg = trg.permute(1,0)\n",
    "        #src = [src len, batch size]\n",
    "        #trg = [trg len, batch size]\n",
    "        #teacher_forcing_ratio is probability to use teacher forcing\n",
    "        #e.g. if teacher_forcing_ratio is 0.75 we use ground-truth inputs 75% of the time\n",
    "        # print(\"seq2seq forward prop src shape\", src.shape)\n",
    "        # print(\"seq2seq forward prop trg shape\", trg.shape)\n",
    "        batch_size = trg.shape[1]\n",
    "        trg_len = trg.shape[0]\n",
    "\n",
    "        trg_vocab_size = self.decoder.output_dim\n",
    "        # print(\"seq2seq trg vocab size\", trg_vocab_size)\n",
    "        # print(\"seq2seq batch size\", batch_size)\n",
    "        # print(\"seq2seq trg len\", trg_len)\n",
    "        #tensor to store decoder outputs\n",
    "        outputs = torch.zeros(trg_len, batch_size, trg_vocab_size).to(self.device)\n",
    "\n",
    "        #last hidden state of the encoder is used as the initial hidden state of the decoder\n",
    "        hidden, cell = self.encoder(src)\n",
    "        # print(\"seq2seq hidden shape\", hidden.shape)\n",
    "        # print(\"seq2seq cell shape\", cell.shape)\n",
    "        #first input to the decoder is the <sos> tokens\n",
    "        input = trg[0,:]\n",
    "        # print(\"first input to decoder\", input)\n",
    "        for t in range(1, trg_len):\n",
    "\t\t\t            #insert input token embedding, previous hidden and previous cell states\n",
    "            #receive output tensor (predictions) and new hidden and cell states\n",
    "            output, hidden, cell = self.decoder(input, hidden, cell)\n",
    "\n",
    "            #place predictions in a tensor holding predictions for each token\n",
    "            outputs[t] = output\n",
    "\n",
    "            #decide if we are going to use teacher forcing or not\n",
    "            teacher_force = random.random() < teacher_forcing_ratio\n",
    "\n",
    "            #get the highest predicted token from our predictions\n",
    "            top1 = output.argmax(1)\n",
    "\n",
    "            #if teacher forcing, use actual next token as next input\n",
    "            #if not, use predicted token\n",
    "            input = trg[t] if teacher_force else top1\n",
    "\n",
    "        return outputs"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-02T16:44:43.833780600Z",
     "start_time": "2023-05-02T16:44:43.631535700Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "outputs": [],
   "source": [
    "INPUT_DIM = input_vocab_size\n",
    "OUTPUT_DIM = output_vocab_size\n",
    "ENC_EMB_DIM = 256\n",
    "DEC_EMB_DIM = 256\n",
    "HID_DIM = 512\n",
    "N_LAYERS = 2\n",
    "ENC_DROPOUT = 0.5\n",
    "DEC_DROPOUT = 0.5"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-02T16:44:43.881783700Z",
     "start_time": "2023-05-02T16:44:43.657740Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "outputs": [],
   "source": [
    "enc = Encoder(INPUT_DIM, ENC_EMB_DIM, HID_DIM, N_LAYERS, ENC_DROPOUT)\n",
    "dec = Decoder(OUTPUT_DIM, DEC_EMB_DIM, HID_DIM, N_LAYERS, DEC_DROPOUT)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-02T16:44:43.897785700Z",
     "start_time": "2023-05-02T16:44:43.675486100Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "outputs": [],
   "source": [
    "model = Seq2Seq(enc, dec, device).to(device)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-02T16:44:43.911628300Z",
     "start_time": "2023-05-02T16:44:43.755671Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "outputs": [
    {
     "data": {
      "text/plain": "Seq2Seq(\n  (encoder): Encoder(\n    (embedding): Embedding(29, 256)\n    (rnn): LSTM(256, 512, num_layers=2, dropout=0.5)\n    (dropout): Dropout(p=0.5, inplace=False)\n  )\n  (decoder): Decoder(\n    (embedding): Embedding(131, 256)\n    (rnn): LSTM(256, 512, num_layers=2, dropout=0.5)\n    (fc_out): Linear(in_features=512, out_features=131, bias=True)\n    (dropout): Dropout(p=0.5, inplace=False)\n  )\n)"
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def init_weights(m):\n",
    "    for name, param in m.named_parameters():\n",
    "        nn.init.uniform_(param.data, -0.08, 0.08)\n",
    "\n",
    "model.apply(init_weights)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-02T16:44:43.982727100Z",
     "start_time": "2023-05-02T16:44:43.771475600Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "outputs": [],
   "source": [
    "optimizer = optim.Adam(model.parameters())"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-02T16:44:43.996486300Z",
     "start_time": "2023-05-02T16:44:43.982727100Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "outputs": [],
   "source": [
    "# TRG_PAD_IDX = TRG.vocab.stoi[TRG.pad_token]\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-02T16:44:44.054932500Z",
     "start_time": "2023-05-02T16:44:44.001509800Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "outputs": [],
   "source": [
    "def train(model, iterator, optimizer, criterion, clip):\n",
    "\n",
    "    model.train()\n",
    "\n",
    "    epoch_loss = 0\n",
    "\n",
    "    for i, (data, target) in enumerate(iterator):\n",
    "        # if(i == 2):\n",
    "        #     break\n",
    "        src = data\n",
    "        trg = target\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        # print(\"train target shape\", trg.shape)\n",
    "        output = model(src, trg)\n",
    "\n",
    "        #trg = [trg len, batch size]\n",
    "        #output = [trg len, batch size, output dim]\n",
    "        # trg = trg.permute(1,0)\n",
    "        # output = output.permute(1,0, 2)\n",
    "        # print(\"train target shape\", trg.shape)\n",
    "        # print(\"train output shape\", output.shape)\n",
    "        output_dim = output.shape[-1]\n",
    "        output = output[1:].reshape(-1, output_dim)\n",
    "        trg = trg[1:].reshape(-1)\n",
    "        # print(\"target shape\", trg.shape)\n",
    "        # print(\"output shape\", output.shape)\n",
    "        #trg = [(trg len - 1) * batch size]\n",
    "        #output = [(trg len - 1) * batch size, output dim]\n",
    "\n",
    "        loss = criterion(output, trg)\n",
    "\n",
    "        loss.backward()\n",
    "\n",
    "        # torch.nn.utils.clip_grad_norm_(model.parameters(), clip)\n",
    "        #\n",
    "        optimizer.step()\n",
    "        #\n",
    "        ls = loss.item()\n",
    "        epoch_loss += ls\n",
    "#         print(ls)\n",
    "    return epoch_loss / len(iterator)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-02T16:44:44.066559700Z",
     "start_time": "2023-05-02T16:44:44.011766700Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[36], line 9\u001B[0m\n\u001B[0;32m      4\u001B[0m best_valid_loss \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mfloat\u001B[39m(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124minf\u001B[39m\u001B[38;5;124m'\u001B[39m)\n\u001B[0;32m      6\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m epoch \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mrange\u001B[39m(N_EPOCHS):\n\u001B[0;32m      7\u001B[0m \n\u001B[0;32m      8\u001B[0m     \u001B[38;5;66;03m# start_time = time.time()\u001B[39;00m\n\u001B[1;32m----> 9\u001B[0m     train_loss \u001B[38;5;241m=\u001B[39m \u001B[43mtrain\u001B[49m\u001B[43m(\u001B[49m\u001B[43mmodel\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtrain_dataloader\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43moptimizer\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcriterion\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mCLIP\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     10\u001B[0m     \u001B[38;5;28mprint\u001B[39m(train_loss)\n\u001B[0;32m     11\u001B[0m     \u001B[38;5;66;03m# valid_loss = evaluate(model, valid_iterator, criterion)\u001B[39;00m\n",
      "Cell \u001B[1;32mIn[35], line 15\u001B[0m, in \u001B[0;36mtrain\u001B[1;34m(model, iterator, optimizer, criterion, clip)\u001B[0m\n\u001B[0;32m     13\u001B[0m optimizer\u001B[38;5;241m.\u001B[39mzero_grad()\n\u001B[0;32m     14\u001B[0m \u001B[38;5;66;03m# print(\"train target shape\", trg.shape)\u001B[39;00m\n\u001B[1;32m---> 15\u001B[0m output \u001B[38;5;241m=\u001B[39m \u001B[43mmodel\u001B[49m\u001B[43m(\u001B[49m\u001B[43msrc\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtrg\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     17\u001B[0m \u001B[38;5;66;03m#trg = [trg len, batch size]\u001B[39;00m\n\u001B[0;32m     18\u001B[0m \u001B[38;5;66;03m#output = [trg len, batch size, output dim]\u001B[39;00m\n\u001B[0;32m     19\u001B[0m \u001B[38;5;66;03m# trg = trg.permute(1,0)\u001B[39;00m\n\u001B[0;32m     20\u001B[0m \u001B[38;5;66;03m# output = output.permute(1,0, 2)\u001B[39;00m\n\u001B[0;32m     21\u001B[0m \u001B[38;5;66;03m# print(\"train target shape\", trg.shape)\u001B[39;00m\n\u001B[0;32m     22\u001B[0m \u001B[38;5;66;03m# print(\"train output shape\", output.shape)\u001B[39;00m\n\u001B[0;32m     23\u001B[0m output_dim \u001B[38;5;241m=\u001B[39m output\u001B[38;5;241m.\u001B[39mshape[\u001B[38;5;241m-\u001B[39m\u001B[38;5;241m1\u001B[39m]\n",
      "File \u001B[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\torch\\nn\\modules\\module.py:1501\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[1;34m(self, *args, **kwargs)\u001B[0m\n\u001B[0;32m   1496\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[0;32m   1497\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[0;32m   1498\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks\n\u001B[0;32m   1499\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[0;32m   1500\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[1;32m-> 1501\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mforward_call\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   1502\u001B[0m \u001B[38;5;66;03m# Do not call functions when jit is used\u001B[39;00m\n\u001B[0;32m   1503\u001B[0m full_backward_hooks, non_full_backward_hooks \u001B[38;5;241m=\u001B[39m [], []\n",
      "Cell \u001B[1;32mIn[28], line 43\u001B[0m, in \u001B[0;36mSeq2Seq.forward\u001B[1;34m(self, src, trg, teacher_forcing_ratio)\u001B[0m\n\u001B[0;32m     39\u001B[0m         \u001B[38;5;66;03m# print(\"first input to decoder\", input)\u001B[39;00m\n\u001B[0;32m     40\u001B[0m         \u001B[38;5;28;01mfor\u001B[39;00m t \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mrange\u001B[39m(\u001B[38;5;241m1\u001B[39m, trg_len):\n\u001B[0;32m     41\u001B[0m \t\t\t            \u001B[38;5;66;03m#insert input token embedding, previous hidden and previous cell states\u001B[39;00m\n\u001B[0;32m     42\u001B[0m             \u001B[38;5;66;03m#receive output tensor (predictions) and new hidden and cell states\u001B[39;00m\n\u001B[1;32m---> 43\u001B[0m             output, hidden, cell \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mdecoder\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43minput\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mhidden\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcell\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     45\u001B[0m             \u001B[38;5;66;03m#place predictions in a tensor holding predictions for each token\u001B[39;00m\n\u001B[0;32m     46\u001B[0m             outputs[t] \u001B[38;5;241m=\u001B[39m output\n",
      "File \u001B[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\torch\\nn\\modules\\module.py:1501\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[1;34m(self, *args, **kwargs)\u001B[0m\n\u001B[0;32m   1496\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[0;32m   1497\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[0;32m   1498\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks\n\u001B[0;32m   1499\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[0;32m   1500\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[1;32m-> 1501\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mforward_call\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   1502\u001B[0m \u001B[38;5;66;03m# Do not call functions when jit is used\u001B[39;00m\n\u001B[0;32m   1503\u001B[0m full_backward_hooks, non_full_backward_hooks \u001B[38;5;241m=\u001B[39m [], []\n",
      "Cell \u001B[1;32mIn[27], line 49\u001B[0m, in \u001B[0;36mDecoder.forward\u001B[1;34m(self, input, hidden, cell)\u001B[0m\n\u001B[0;32m     36\u001B[0m output, (hidden, cell) \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mrnn(embedded, (hidden, cell))\n\u001B[0;32m     37\u001B[0m \u001B[38;5;66;03m# print(\"decoder output shape\", output.shape)\u001B[39;00m\n\u001B[0;32m     38\u001B[0m \u001B[38;5;66;03m# print(\"decoder hidden shape\", hidden.shape)\u001B[39;00m\n\u001B[0;32m     39\u001B[0m \u001B[38;5;66;03m# print(\"decoder context shape\", cell.shape)\u001B[39;00m\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m     46\u001B[0m \u001B[38;5;66;03m#hidden = [n layers, batch size, hid dim]\u001B[39;00m\n\u001B[0;32m     47\u001B[0m \u001B[38;5;66;03m#cell = [n layers, batch size, hid dim]\u001B[39;00m\n\u001B[1;32m---> 49\u001B[0m prediction \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mfc_out(\u001B[43moutput\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43msqueeze\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m0\u001B[39;49m\u001B[43m)\u001B[49m)\n\u001B[0;32m     51\u001B[0m \u001B[38;5;66;03m#prediction = [batch size, output dim]\u001B[39;00m\n\u001B[0;32m     52\u001B[0m \u001B[38;5;66;03m# print(\"decoder prediction shape\", prediction.shape)\u001B[39;00m\n\u001B[0;32m     53\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m prediction, hidden, cell\n",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "N_EPOCHS = 10\n",
    "CLIP = 1\n",
    "\n",
    "best_valid_loss = float('inf')\n",
    "\n",
    "for epoch in range(N_EPOCHS):\n",
    "\n",
    "    # start_time = time.time()\n",
    "    train_loss = train(model, train_dataloader, optimizer, criterion, CLIP)\n",
    "    print(train_loss)\n",
    "    # valid_loss = evaluate(model, valid_iterator, criterion)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-02T16:56:24.574445800Z",
     "start_time": "2023-05-02T16:44:44.031766900Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-05-02T16:56:24.565141900Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
