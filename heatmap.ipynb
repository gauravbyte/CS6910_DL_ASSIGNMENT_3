{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['c:\\\\Users\\\\gaura\\\\PycharmProjects\\\\scientificProject', 'c:\\\\Program Files\\\\Python311\\\\python311.zip', 'c:\\\\Program Files\\\\Python311\\\\DLLs', 'c:\\\\Program Files\\\\Python311\\\\Lib', 'c:\\\\Program Files\\\\Python311', '', 'C:\\\\Users\\\\gaura\\\\AppData\\\\Roaming\\\\Python\\\\Python311\\\\site-packages', 'C:\\\\Users\\\\gaura\\\\AppData\\\\Roaming\\\\Python\\\\Python311\\\\site-packages\\\\win32', 'C:\\\\Users\\\\gaura\\\\AppData\\\\Roaming\\\\Python\\\\Python311\\\\site-packages\\\\win32\\\\lib', 'C:\\\\Users\\\\gaura\\\\AppData\\\\Roaming\\\\Python\\\\Python311\\\\site-packages\\\\Pythonwin', 'c:\\\\Program Files\\\\Python311\\\\Lib\\\\site-packages']\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from tqdm.auto import tqdm\n",
    "from datetime import time\n",
    "import pandas as pd  # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data import Dataset\n",
    "import sys\n",
    "import torch.nn.functional as F\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "print(sys.path)\n",
    "import random\n",
    "import os\n",
    "\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        os.path.join(dirname, filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # !pip install wandb\n",
    "# import wandb\n",
    "# wandb.login(key = \"d4c2dc0cbf8caf1ee8dc1563f3d5c10594df22b5\")\n",
    "# wandb.init(project=\"DL_ASSIGNMENT_3_with_attention\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %env WANDB_SILENT=true\n",
    "# wandb.init(timeout=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Executing on cpu\n",
      "Running on local\n",
      "(51199, 2)\n",
      "(4095, 2)\n",
      "(4095, 2)\n",
      "{'_': 0, '|': 1, '$': 2, 'a': 3, 'b': 4, 'c': 5, 'd': 6, 'e': 7, 'f': 8, 'g': 9, 'h': 10, 'i': 11, 'j': 12, 'k': 13, 'l': 14, 'm': 15, 'n': 16, 'o': 17, 'p': 18, 'q': 19, 'r': 20, 's': 21, 't': 22, 'u': 23, 'v': 24, 'w': 25, 'x': 26, 'y': 27, 'z': 28}\n",
      "ouput char set  {'ए', 'र', 'ॉ', 'व', 'फ', 'क', 'थ', 'ऱ', 'इ', 'ऍ', 'म', 'ु', 'घ', 'ब', 'छ', 'ी', 'ँ', 'च', 'प', 'ण', 'ृ', '्', 'श', 'े', 'ः', 'ल', 'द', 'भ', 'ढ', 'ई', 'आ', 'झ', 'ठ', 'उ', 'ळ', 'ौ', 'ऐ', 'ॅ', 'ओ', 'ञ', 'औ', 'ऋ', 'ि', 'ज', '़', 'ं', 'ा', 'न', 'ध', 'त', 'ड', 'ो', 'ह', 'स', 'ू', 'ट', 'ख', 'अ', 'य', 'ऊ', 'ष', 'ऑ', 'ग', 'ै'}\n",
      "ouput char set size 64\n",
      "max input length 25\n",
      "max output length 19\n",
      "max_length 25\n",
      "Input Character max 29\n",
      "output Character size 67\n",
      "Input Character max 29\n",
      "output Character size 67\n",
      "tensor([ 4, 10, 23, 14, 22, 10,  3, 18,  3, 16,  3])\n",
      "व्हायकी\n",
      "{'_': 0, '|': 1, '$': 2, 'a': 3, 'b': 4, 'c': 5, 'd': 6, 'e': 7, 'f': 8, 'g': 9, 'h': 10, 'i': 11, 'j': 12, 'k': 13, 'l': 14, 'm': 15, 'n': 16, 'o': 17, 'p': 18, 'q': 19, 'r': 20, 's': 21, 't': 22, 'u': 23, 'v': 24, 'w': 25, 'x': 26, 'y': 27, 'z': 28}\n",
      "tensor([10,  7, 14, 14, 17])\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Executing on \" + (\"cuda:0\" if torch.cuda.is_available() else \"cpu\"))\n",
    "\n",
    "if 'PYTHONPATH' in os.environ:\n",
    "    if 'kaggle' in os.environ['PYTHONPATH']:\n",
    "        print('Running on Kaggle')\n",
    "        df_train = pd.read_csv(\"/kaggle/input/aksharantar_sampled/aksharantar_sampled/mar/mar_train.csv\")\n",
    "        df_test = pd.read_csv('/kaggle/input/aksharantar_sampled/aksharantar_sampled/mar/mar_test.csv')\n",
    "        df_valid = pd.read_csv('/kaggle/input/aksharantar/aksharantar_sampled/mar/mar_valid.csv')\n",
    "else:\n",
    "    #change the path to Data/mar\n",
    "    print('Running on local')\n",
    "    df_train = pd.read_csv(\"Data/mar/mar_train.csv\")\n",
    "    df_test = pd.read_csv('Data/mar/mar_test.csv')\n",
    "    df_valid = pd.read_csv('Data/mar/mar_valid.csv')\n",
    "\n",
    "print(df_train.shape)\n",
    "print(df_test.shape)\n",
    "print(df_valid.shape)\n",
    "\n",
    "PAD_CHAR = '_'  # padding character\n",
    "EOW_CHAR = '|'  # end of word character\n",
    "SOW_CHAR = '$'  # start of word character\n",
    "BATCH_SIZE = 32\n",
    "ENGLISH_ALPHA = [chr(alpha) for alpha in range(ord('a'), ord('z') + 1)]\n",
    "INPUT_CHAR_INDX = {PAD_CHAR: 0, EOW_CHAR: 1, SOW_CHAR: 2}\n",
    "for index, alpha in enumerate(ENGLISH_ALPHA):\n",
    "    INPUT_CHAR_INDX[alpha] = index + 3\n",
    "\n",
    "INPUT_INDX_CHAR = {v: k for k, v in INPUT_CHAR_INDX.items()}\n",
    "\n",
    "df_train = df_train.set_axis(['X', 'Y'], axis=1)\n",
    "df_valid = df_valid.set_axis(['X', 'Y'], axis=1)\n",
    "df_test = df_test.set_axis(['X', 'Y'], axis=1)\n",
    "\n",
    "print(INPUT_CHAR_INDX)\n",
    "\n",
    "ouput_words = df_train['Y'].tolist() + df_test['Y'].tolist() + df_valid['Y'].tolist()\n",
    "output_char_set = set()\n",
    "for word in ouput_words:\n",
    "    for char in word:\n",
    "        output_char_set.add(char)\n",
    "OUT_ALPHA = list(output_char_set)\n",
    "# OUT_ALPHA = [chr(alpha) for alpha in range(2304, 2432)]\n",
    "OUT_ALPHA_SIZE = len(OUT_ALPHA)\n",
    "OUTPUT_CHAR_INDEX = {PAD_CHAR: 0, EOW_CHAR: 1, SOW_CHAR: 2}\n",
    "for index, alpha in enumerate(OUT_ALPHA):\n",
    "    OUTPUT_CHAR_INDEX[alpha] = index + 3\n",
    "# %%\n",
    "\n",
    "OUTPUT_INDEX_CHAR = {v: k for k, v in OUTPUT_CHAR_INDEX.items()}\n",
    "\n",
    "print(\"ouput char set \",output_char_set)\n",
    "print(\"ouput char set size\",len(output_char_set))\n",
    "\n",
    "OUTPUT_INDEX_CHAR = {v: k for k, v in OUTPUT_CHAR_INDEX.items()}\n",
    "\n",
    "# print(OUTPUT_CHAR_INDEX)\n",
    "# print(len(OUTPUT_CHAR_INDEX))\n",
    "\n",
    "df_train = df_train.set_axis(['X', 'Y'], axis=1)\n",
    "df_valid = df_valid.set_axis(['X', 'Y'], axis=1)\n",
    "df_test = df_test.set_axis(['X', 'Y'], axis=1)\n",
    "# %%\n",
    "# print(df_train)\n",
    "# print(df_test)\n",
    "# print(df_valid)\n",
    "\n",
    "if 'kaggle' not in sys.path:\n",
    "    df_train = df_train.iloc[:2000,:]\n",
    "    df_test = df_test.iloc[:200,:]\n",
    "    df_valid = df_valid.iloc[:200,:]\n",
    "\n",
    "# %%\n",
    "max_input_length = max(df_train.iloc[:, 0].apply(lambda x: len(x)).max(),\n",
    "                       df_test.iloc[:, 0].apply(lambda x: len(x)).max(),\n",
    "                       df_valid.iloc[:, 0].apply(lambda x: len(x)).max())\n",
    "\n",
    "max_output_length = max(df_train.iloc[:, 1].apply(lambda x: len(x)).max(),\n",
    "                        df_test.iloc[:, 1].apply(lambda x: len(x)).max(),\n",
    "                        df_valid.iloc[:, 1].apply(lambda x: len(x)).max())\n",
    "\n",
    "print(\"max input length\", max_input_length)\n",
    "print(\"max output length\", max_output_length)\n",
    "MAX_LENGTH = max(max_input_length, max_output_length)\n",
    "print(\"max_length\", MAX_LENGTH)\n",
    "# %%\n",
    "input_vocab_size = len(INPUT_CHAR_INDX)\n",
    "output_vocab_size = len(OUTPUT_CHAR_INDEX)\n",
    "print(\"Input Character max\", input_vocab_size)\n",
    "print(\"output Character size\", output_vocab_size)\n",
    "\n",
    "train_list = df_train.values.tolist()\n",
    "valid_list = df_valid.values.tolist()\n",
    "test_list = df_test.values.tolist()\n",
    "\n",
    "# %%\n",
    "input_vocab_size = len(INPUT_CHAR_INDX)\n",
    "output_vocab_size = len(OUTPUT_CHAR_INDEX)\n",
    "print(\"Input Character max\", input_vocab_size)\n",
    "print(\"output Character size\", output_vocab_size)\n",
    "\n",
    "train_list = df_train.values.tolist()\n",
    "valid_list = df_valid.values.tolist()\n",
    "test_list = df_test.values.tolist()\n",
    "\n",
    "\n",
    "# %% md\n",
    "class Transliterate(Dataset):\n",
    "    def __init__(self, df_data, in_dict, out_dict):\n",
    "        super().__init__()\n",
    "        self.df_data_word = df_data.copy()\n",
    "        self.in_dict = in_dict\n",
    "        self.out_dict = out_dict\n",
    "        self.df_data = df_data.iloc[:, ].apply(lambda x: SOW_CHAR + x + EOW_CHAR)\n",
    "\n",
    "\n",
    "    def __get_random_word__(self):\n",
    "        idx = random.randint(0, len(self.df_data))\n",
    "        input_word = self.df_data_word.iloc[idx][0]\n",
    "        output_word = self.df_data_word.iloc[idx][1]\n",
    "        return input_word, output_word\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df_data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        input_word = self.df_data.iloc[idx][0]\n",
    "        output_word = self.df_data.iloc[idx][1]\n",
    "        input_tensor = inputToTensor(input_word)\n",
    "        output_tensor = outToTensor(output_word)\n",
    "        return input_tensor, output_tensor\n",
    "\n",
    "    def __getrandom__(self):\n",
    "        idx = random.randint(0,len(self.data_list))\n",
    "        input_word = self.df_data[idx][0]\n",
    "        output_word = self.df_data[idx][1]\n",
    "        input_tensor = inputToTensor(input_word)\n",
    "        output_tensor = outToTensor(output_word)\n",
    "        return input_tensor, output_tensor\n",
    "\n",
    "    def preprocess(self, word):\n",
    "        return SOW_CHAR + word + EOW_CHAR\n",
    "\n",
    "\n",
    "train_data = Transliterate(df_train, INPUT_CHAR_INDX, OUTPUT_CHAR_INDEX)\n",
    "valid_data = Transliterate(df_valid, INPUT_CHAR_INDX, OUTPUT_CHAR_INDEX)\n",
    "test_data = Transliterate(df_test, INPUT_CHAR_INDX, OUTPUT_CHAR_INDEX)\n",
    "# %%\n",
    "def inputToTensor(line):\n",
    "    tensor = torch.tensor(data=([INPUT_CHAR_INDX[x] for x in line]), dtype=torch.long)\n",
    "    return tensor\n",
    "\n",
    "\n",
    "def charToTensor(char, dic=INPUT_CHAR_INDX):\n",
    "    tensor = torch.zeros(len(dic))\n",
    "    tensor[dic[char]] = 1\n",
    "    return tensor\n",
    "\n",
    "\n",
    "def outToTensor(word):\n",
    "    tensor = torch.tensor([OUTPUT_CHAR_INDEX[x] for x in word])\n",
    "    return tensor\n",
    "\n",
    "\n",
    "# %%\n",
    "print(inputToTensor(train_list[0][0]))\n",
    "# %%\n",
    "print(train_list[1][1])\n",
    "\n",
    "# %%\n",
    "inputToTensor(\"$bindhya|\")\n",
    "# %%\n",
    "print(INPUT_CHAR_INDX)\n",
    "# %%\n",
    "print(inputToTensor(\"hello\"))\n",
    "\n",
    "\n",
    "# %%\n",
    "def generate_batch(data_batch):\n",
    "    train_batch = [x[0] for x in data_batch]\n",
    "    target_batch = [x[1] for x in data_batch]\n",
    "    train_pad = torch.nn.utils.rnn.pad_sequence(train_batch, batch_first=True, padding_value=0)\n",
    "    train_pad = train_pad[:, :MAX_LENGTH]\n",
    "    train_pad = torch.nn.functional.pad(train_pad, (0, MAX_LENGTH - train_pad.size(1)), value=0)\n",
    "    target_pad = torch.nn.utils.rnn.pad_sequence(target_batch, batch_first=True, padding_value=0)\n",
    "    target_pad = target_pad[:, :MAX_LENGTH]\n",
    "    target_pad = torch.nn.functional.pad(target_pad, (0, MAX_LENGTH - target_pad.size(1)), value=0)\n",
    "    padded_input_batch = train_pad.T.to(device)\n",
    "    padded_output_batch = target_pad.T.to(device)\n",
    "    return padded_input_batch, padded_output_batch\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# for data, target in train_dataloader:\n",
    "#     print(data.shape)\n",
    "#     print(target.shape)\n",
    "#     if True:\n",
    "#         break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(nn.Module):\n",
    "    def __init__(self, input_size, embedding_size, hidden_size, num_layers, dropout, cell_type, bidirectional=True,\n",
    "                 batch_size=BATCH_SIZE):\n",
    "        super().__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_layers = num_layers\n",
    "        self.embedding = nn.Embedding(input_size, embedding_size)\n",
    "        self.cell_type = cell_type\n",
    "        self.batch_size = batch_size\n",
    "        self.bidirectional = bidirectional\n",
    "        if cell_type == 'RNN':\n",
    "            self.rnn = nn.RNN(embedding_size, hidden_size, num_layers, dropout=dropout, bidirectional=bidirectional)\n",
    "        elif cell_type == 'LSTM':\n",
    "            self.rnn = nn.LSTM(embedding_size, hidden_size, num_layers, dropout=dropout, bidirectional=bidirectional)\n",
    "        elif cell_type == 'GRU':\n",
    "            self.rnn = nn.GRU(embedding_size, hidden_size, num_layers, dropout=dropout, bidirectional=bidirectional)\n",
    "        # self.rnn = nn.LSTM(embedding_size, hidden_size, n_layers, dropout=dropout)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self, src, hidden=None):\n",
    "        self.batch_size = src.shape[1]\n",
    "        embedded = self.dropout(self.embedding(src))\n",
    "        if self.cell_type == 'LSTM':\n",
    "            output, (hidden, cell) = self.rnn(embedded)\n",
    "        else:\n",
    "            output, hidden = self.rnn(embedded, hidden)\n",
    "        if self.bidirectional:\n",
    "            # Split hidden and cell into two halves along the first dimension\n",
    "            hidden_chunks = torch.chunk(hidden, 2, dim=0)\n",
    "            hidden = 0.5 * (hidden_chunks[0] + hidden_chunks[1])\n",
    "\n",
    "            if self.cell_type == \"LSTM\":\n",
    "                cell_chunks = torch.chunk(cell, 2, dim=0)\n",
    "                cell = 0.5 * (cell_chunks[0] + cell_chunks[1])\n",
    "\n",
    "            # Compute the average of forward and backward outputs\n",
    "            output = output.permute(2, 1, 0)\n",
    "            output_chunks = torch.chunk(output, 2, dim=0)\n",
    "            output = 0.5 * (output_chunks[0] + output_chunks[1])\n",
    "            output = output.permute(2, 1, 0)\n",
    "\n",
    "        if (self.cell_type == \"LSTM\"):\n",
    "            return output, hidden, cell\n",
    "        else:\n",
    "            return output, hidden\n",
    "\n",
    "    def initHidden(self):\n",
    "        if self.bidirectional == True:\n",
    "            return torch.zeros(2 * self.num_layers, self.batch_size, self.hidden_size, device=device)\n",
    "        else:\n",
    "            return torch.zeros(self.num_layers, self.batch_size, self.hidden_size, device=device)\n",
    "\n",
    "\n",
    "# write decoder with attention\n",
    "\n",
    "\n",
    "class Decoder_with_attention(nn.Module):\n",
    "    def __init__(self, hidden_size, output_size, num_layers, dropout, embedding_size, cell_type=\"LSTM\",\n",
    "                 batch_size=BATCH_SIZE):\n",
    "        super(Decoder_with_attention, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.output_size = output_size\n",
    "        self.num_layers = num_layers\n",
    "        self.batch_size = batch_size\n",
    "        self.embedding_size = embedding_size\n",
    "        self.cell_type = cell_type\n",
    "        self.embedding = nn.Embedding(output_size, embedding_size)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.attn = nn.Linear(self.hidden_size + self.embedding_size, MAX_LENGTH)\n",
    "        self.attn_combine = nn.Linear(self.hidden_size + self.embedding_size, self.hidden_size)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        if cell_type == 'RNN':\n",
    "            self.rnn = nn.RNN(self.hidden_size, self.hidden_size, num_layers, dropout=dropout)\n",
    "        elif cell_type == 'LSTM':\n",
    "            self.rnn = nn.LSTM(self.hidden_size, self.hidden_size, num_layers, dropout=dropout)\n",
    "        elif cell_type == 'GRU':\n",
    "            self.rnn = nn.GRU(self.hidden_size, self.hidden_size, num_layers, dropout=dropout)\n",
    "\n",
    "        self.out = nn.Linear(self.hidden_size, self.output_size)\n",
    "        self.softmax = nn.LogSoftmax(dim=1)\n",
    "\n",
    "    def forward(self, input, hidden, encoder_outputs):\n",
    "\n",
    "        input = input.unsqueeze(0)\n",
    "        self.batch_size = input.size(1)\n",
    "        output = self.embedding(input).view(-1, self.batch_size, self.embedding_size)\n",
    "        output = self.dropout(output)\n",
    "        if self.cell_type == \"LSTM\":\n",
    "            attn_weights = F.softmax(self.attn(torch.cat((output[0], hidden[0][0]), 1)), dim=1)\n",
    "        else:\n",
    "            attn_weights = F.softmax(self.attn(torch.cat((output[0], hidden[0]), 1)), dim=1)\n",
    "\n",
    "        attn_applied = torch.bmm(attn_weights.unsqueeze(1), encoder_outputs.permute(1, 0, 2))\n",
    "        attn_applied = attn_applied.squeeze(1)\n",
    "        # print(\"attention applied shape\",attn_applied.shape)\n",
    "        output = torch.cat((output[0], attn_applied), 1)\n",
    "        output = self.attn_combine(output).unsqueeze(0)\n",
    "        output = F.relu(output)\n",
    "        if self.cell_type == \"LSTM\":\n",
    "            output, (hidden, cell) = self.rnn(output, (hidden[0], hidden[1]))\n",
    "            return self.out(output[0]), hidden, cell, attn_weights\n",
    "        else:\n",
    "            output, hidden = self.rnn(output, hidden)\n",
    "            return self.out(output[0]), hidden, attn_weights\n",
    "\n",
    "\n",
    "class Seq2Seq(nn.Module):\n",
    "    def __init__(self, encoder, decoder, device, teacher_forcing_ratio=0.5, heatmap=False):\n",
    "        super().__init__()\n",
    "        self.encoder = encoder\n",
    "        self.decoder = decoder\n",
    "        self.device = device\n",
    "        self.heatmap = heatmap\n",
    "        self.teacher_forcing_ratio = teacher_forcing_ratio\n",
    "\n",
    "    def forward(self, src, trg, heatmap=False):\n",
    "        attention_weights = []\n",
    "        batch_size = trg.shape[1]\n",
    "        trg_len = trg.shape[0]\n",
    "        trg_vocab_size = self.decoder.output_size\n",
    "        outputs = torch.zeros(trg_len, batch_size, trg_vocab_size).to(self.device)\n",
    "        encoder_hidden = self.encoder.initHidden()\n",
    "        # encoder_hidden = self.encoder.initHidden()\n",
    "        if self.encoder.cell_type == 'LSTM':\n",
    "            encoder_output, encoder_hidden, encoder_cell = self.encoder(src, encoder_hidden)\n",
    "        else:\n",
    "            encoder_output, encoder_hidden = self.encoder(src, encoder_hidden)\n",
    "        input_decoder = trg[0, :]\n",
    "        decoder_hidden = encoder_hidden\n",
    "\n",
    "        if self.decoder.cell_type == 'LSTM':\n",
    "            decoder_cell = encoder_cell\n",
    "\n",
    "        for t in range(1, trg_len):\n",
    "            if self.decoder.cell_type == 'LSTM':\n",
    "                decoder_output, decoder_hidden, decoder_cell, attn_weights = self.decoder(input_decoder, (\n",
    "                decoder_hidden, decoder_cell), encoder_output)\n",
    "\n",
    "            else:\n",
    "                decoder_output, decoder_hidden, attn_weights = self.decoder(input_decoder, decoder_hidden,\n",
    "                                                                            encoder_output)\n",
    "            # print(\"attention_weights\",attn_weights)\n",
    "            if (heatmap):\n",
    "                attention_weights.append(attn_weights)\n",
    "            outputs[t] = decoder_output\n",
    "            teacher_force = random.random() < self.teacher_forcing_ratio\n",
    "            top1 = decoder_output.argmax(1)\n",
    "            input_decoder = trg[t] if teacher_force else top1\n",
    "\n",
    "        return outputs, attention_weights\n",
    "\n",
    "\n",
    "def get_accuracy(preds, target):\n",
    "    \"\"\"\n",
    "    Returns accuracy per batch, i.e. if you get 8/10 right, this returns 0.8, NOT 8\n",
    "    \"\"\"\n",
    "    preds = preds.argmax(dim=2)\n",
    "    preds = preds[1:]\n",
    "    target = target[1:]\n",
    "    matches = torch.eq(preds, target)\n",
    "    columns_matches = torch.sum(matches, dim=0)\n",
    "    num_matching_columns = torch.sum(columns_matches == target.shape[0])\n",
    "    acc = num_matching_columns / target.shape[1]\n",
    "    return acc.item()\n",
    "\n",
    "\n",
    "def train(model, iterator, optimizer, criterion, clip):\n",
    "    model.train()\n",
    "    epoch_loss = 0\n",
    "    epoch_acc = 0\n",
    "    pbar = tqdm(iterator, desc=\"Training\", position=0, leave=True)\n",
    "\n",
    "    for i, (data, target) in enumerate(pbar):\n",
    "        src = data.to(device)\n",
    "        trg = target.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        output, attn_weights = model(src, trg)\n",
    "        # print(\"attention weights\", attn_weights)\n",
    "        # print(\"attention weights shape\", attn_weights.shape)\n",
    "        # attn_weightscpu = attn_weights.cpu().detach().numpy()\n",
    "        # sns.heatmap(attn_weightscpu, cmap=\"YlGnBu\", annot=False,fmt='.2f')\n",
    "        # plt.show()\n",
    "        output_dim = output.shape[-1]\n",
    "        output_reshaped = output[1:].reshape(-1, output_dim)\n",
    "        trg_reshaped = trg[1:].reshape(-1)\n",
    "        loss = criterion(output_reshaped, trg_reshaped)\n",
    "        loss.backward()\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), clip)\n",
    "        optimizer.step()\n",
    "        acc = get_accuracy(output, trg)\n",
    "        epoch_acc += acc\n",
    "        epoch_loss += loss.item()\n",
    "        pbar.set_postfix(train_loss=epoch_loss / (i + 1), train_acc=epoch_acc / (i + 1))\n",
    "        if True:\n",
    "            break\n",
    "    return epoch_loss / len(iterator), epoch_acc / len(iterator)\n",
    "\n",
    "\n",
    "from matplotlib.font_manager import FontProperties\n",
    "\n",
    "font_prop = FontProperties(fname='Mangal 400.TTF')\n",
    "\n",
    "# %%\n",
    "def plot_attention_heatmap(model, iterator):\n",
    "    for i, (data, target) in enumerate(iterator):\n",
    "        src = data.to(device)\n",
    "        trg = target.to(device)\n",
    "        # get first 10 examples\n",
    "        # src = data[:10].to(device)\n",
    "        # trg = target[:10].to(device)\n",
    "        output, attention_weights = model(src, trg, heatmap=True)\n",
    "        # attention_weights = torch.stack(attention_weights).squeeze()  # Convert the list to a tensor\n",
    "        # attention_weights = torch.cat(attention_weights, dim=0)\n",
    "        # attention_weights = torch.stack(attention_weights).squeeze().cpu().detach().numpy()\n",
    "        attention_weights = torch.stack(attention_weights, dim=0)  # Convert the list to a tensor\n",
    "\n",
    "        attention_weights = attention_weights.squeeze().cpu().detach().numpy()  # Convert the tensor to a numpy array\n",
    "        # attention_weights shape = (trg_len, batch_size, src_len)\n",
    "        # attention_weights.permute(1,0,2)\n",
    "        attention_weights = attention_weights.transpose(1, 0, 2)\n",
    "        # attention_weights shape = (batch_size, trg_len, src_len)\n",
    "        # print(\"attention weights shape\",attention_weights.shape)\n",
    "        # print(\"attention weights\",attention_weights)\n",
    "        # get first 10 examples\n",
    "        attention_weights = attention_weights[:10]\n",
    "        #convert attention weights to list\n",
    "        attention_weights_list = attention_weights.tolist()\n",
    "        # get first 10 examples\n",
    "        # src shape = (src_len, batch_size)\n",
    "        src = src.transpose(1, 0)\n",
    "        trg = trg.transpose(1, 0)\n",
    "        src = src[:10]\n",
    "        trg = trg[:10]\n",
    "        #convert source targe to list\n",
    "        src_list = src.tolist()\n",
    "        trg_list = trg.tolist()\n",
    "        fig, axes = plt.subplots(3, 3, figsize=(10, 10))\n",
    "        fig.tight_layout(pad=5.0)\n",
    "        fig.subplots_adjust(top=0.90)\n",
    "        axes = axes.ravel()\n",
    "\n",
    "        for j in range(len(attention_weights)-1):\n",
    "\n",
    "            output_vs_input_attention = attention_weights[j]\n",
    "            max_src_len = src.shape[1]\n",
    "            max_trg_len = trg.shape[1]\n",
    "\n",
    "            for k in range(max_src_len):\n",
    "                if src[j][k] == 0:\n",
    "                    max_src_len = k + 1\n",
    "                    break\n",
    "\n",
    "            for k in range(max_trg_len):\n",
    "                if trg[j][k] == 0:\n",
    "                    max_trg_len = k + 1\n",
    "                    break\n",
    "            cur_src = src_list[j][:max_src_len]\n",
    "            cur_trg = trg_list[j][:max_trg_len]\n",
    "            output_vs_input_attention = output_vs_input_attention[:max_trg_len, :max_src_len]\n",
    "\n",
    "            # Plot heatmap\n",
    "            sns.heatmap(output_vs_input_attention, ax=axes[j], cmap=\"YlGnBu\", cbar=False)\n",
    "\n",
    "            # Set x-axis and y-axis labels\n",
    "            axes[j].set_xlabel(\"Input\")\n",
    "            axes[j].set_ylabel(\"Output\")\n",
    "\n",
    "            # Set x-tick labels and rotate if needed\n",
    "            input_characters = [INPUT_INDEX_CHAR[i] for i in cur_src]\n",
    "            axes[j].set_xticks(range(len(cur_src)))\n",
    "            axes[j].set_xticklabels(input_characters, rotation=90)\n",
    "\n",
    "            # Set y-tick labels\n",
    "            output_characters = [OUTPUT_INDEX_CHAR[i] for i in cur_trg]\n",
    "            axes[j].set_yticks(range(len(cur_trg)))\n",
    "            axes[j].set_yticklabels(output_characters, fontproperties=font_prop, fontdict={'fontsize': 9})\n",
    "\n",
    "        fig.tight_layout()\n",
    "\n",
    "        # Show the plot\n",
    "        plt.show()\n",
    "\n",
    "        if True:\n",
    "            break\n",
    "\n",
    "\n",
    "def evaluate(model, iterator, criterion):\n",
    "    model.eval()\n",
    "    epoch_loss = 0\n",
    "    epoch_acc = 0\n",
    "    # with torch.no_grad():\n",
    "    for i, (data, target) in enumerate(iterator):\n",
    "        src = data.to(device)\n",
    "        trg = target.to(device)\n",
    "        output, _ = model(src, trg)\n",
    "        output_dim = output.shape[-1]\n",
    "        output_reshaped = output[1:].reshape(-1, output_dim)\n",
    "        trg_reshaped = trg[1:].reshape(-1)\n",
    "        loss = criterion(output_reshaped, trg_reshaped)\n",
    "        acc = get_accuracy(output, trg)\n",
    "        epoch_acc += acc\n",
    "        epoch_loss += loss.item()\n",
    "    return epoch_loss / len(iterator), epoch_acc / len(iterator)\n",
    "\n",
    "\n",
    "def predict(model, input_word, actual_output):\n",
    "    data_pred = [[input_word, actual_output]]\n",
    "    data_batch = DataLoader(data_pred, batch_size=BATCH_SIZE, shuffle=False, collate_fn=generate_batch)\n",
    "    iterator = data_batch\n",
    "\n",
    "    src = data\n",
    "    trg = target\n",
    "    output = model(src, trg, 0)\n",
    "    output_dim = output.shape[-1]\n",
    "    # output_reshaped = output[1:].reshape(-1, output_dim)\n",
    "    # trg_reshaped = trg[1:].reshape(-1)\n",
    "    preds = output.argmax(dim=2)\n",
    "    print(\"input word\", input_word)\n",
    "    print(\"actual word\", actual_output)\n",
    "    predicted_word = \"\"\n",
    "    for i in preds:\n",
    "        if i.item() in [0, 1, 2]:\n",
    "            continue\n",
    "        predicted_word += predicted_word + OUTPUT_INDEX_CHAR[i.item()]\n",
    "    print(\"predicted word\", predicted_word)\n",
    "    return preds\n",
    "\n",
    "\n",
    "N_EPOCHS = 1\n",
    "CLIP = 1\n",
    "INPUT_DIM = input_vocab_size\n",
    "OUTPUT_DIM = output_vocab_size\n",
    "ENC_EMB_DIM = 128\n",
    "DEC_EMB_DIM = 128\n",
    "HIDDEN_SIZE = 256\n",
    "num_layers = 1\n",
    "ENC_DROPOUT = 0.5\n",
    "DEC_DROPOUT = 0.5\n",
    "TEACHER_FORCING = 0.5\n",
    "BI_DIRECTION = True\n",
    "CELL_TYPE = 'LSTM'\n",
    "pred_src = \"$bindya|\"\n",
    "pred_trg = '$बिन्द्या|'\n",
    "BATCH_SIZE = 32\n",
    "enc = Encoder(input_size=INPUT_DIM, embedding_size=ENC_EMB_DIM, hidden_size=HIDDEN_SIZE, num_layers=num_layers,\n",
    "              dropout=ENC_DROPOUT, cell_type=CELL_TYPE, bidirectional=BI_DIRECTION)\n",
    "dec = Decoder_with_attention(output_size=OUTPUT_DIM, embedding_size=DEC_EMB_DIM, hidden_size=HIDDEN_SIZE,\n",
    "                             num_layers=num_layers,\n",
    "                             dropout=DEC_DROPOUT, cell_type=CELL_TYPE, batch_size=BATCH_SIZE)\n",
    "\n",
    "model = Seq2Seq(enc, dec, device, teacher_forcing_ratio=TEACHER_FORCING).to(device)\n",
    "\n",
    "\n",
    "def init_weights(m):\n",
    "    for name, param in m.named_parameters():\n",
    "        nn.init.uniform_(param.data, -0.08, 0.08)\n",
    "\n",
    "\n",
    "model.apply(init_weights)\n",
    "optimizer = optim.Adam(model.parameters())\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "train_dataloader = DataLoader(train_data, batch_size=BATCH_SIZE, shuffle=True, collate_fn=generate_batch)\n",
    "valid_dataloader = DataLoader(valid_data, batch_size=BATCH_SIZE, shuffle=True, collate_fn=generate_batch)\n",
    "best_valid_loss = float('inf')\n",
    "gbar = tqdm(range(1, N_EPOCHS + 1), position=1, leave=True, desc='Epochs', total=N_EPOCHS)\n",
    "for epoch in gbar:\n",
    "    train_loss, train_accuracy = train(model, train_dataloader, optimizer, criterion, CLIP)\n",
    "    valid_loss, valid_accuracy = evaluate(model, valid_dataloader, criterion)\n",
    "    gbar.set_postfix(train_loss=train_loss, train_acc=train_accuracy, val_loss=valid_loss, val_acc=valid_accuracy)\n",
    "\n",
    "plot_attention_heatmap(model, valid_dataloader)\n",
    "\n",
    "# predict(model, pred_src, pred_trg)\n",
    "# predict(model,\"$बिन्द्या|\",\"$bindya|\")\n",
    "# %%\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "60a62cbffaa24f9d8389e0dad7ce9c4c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epochs:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0b74811fdc9841bb817e407ddc6eccc8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training:   0%|          | 0/63 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output_vs_input_attention: [[0.04304728 0.04130663 0.03903323 0.03682202 0.0383426  0.04077644\n",
      "  0.0391021  0.04220822 0.04436603 0.03673236 0.04603872 0.04064633\n",
      "  0.03959212 0.0409282  0.03855649 0.03936538 0.03712577 0.0372786\n",
      "  0.04338118 0.04213373 0.0378908  0.03875923 0.03732267 0.04257388\n",
      "  0.03667003]\n",
      " [0.04232514 0.03918045 0.03737214 0.0395832  0.03856567 0.03883145\n",
      "  0.03810683 0.04042097 0.04436811 0.03676223 0.04290728 0.04407556\n",
      "  0.03813439 0.04158723 0.03844789 0.04190353 0.038177   0.03871708\n",
      "  0.04080508 0.0397373  0.04065789 0.03801807 0.03742133 0.0431244\n",
      "  0.04076975]\n",
      " [0.04307262 0.03816289 0.04059734 0.03830596 0.03880376 0.03939869\n",
      "  0.039357   0.04022218 0.04228455 0.03760792 0.04417914 0.03900603\n",
      "  0.03938824 0.04106387 0.03749073 0.04504024 0.0398767  0.03823737\n",
      "  0.04187925 0.04068879 0.03661278 0.0373898  0.03827858 0.0443035\n",
      "  0.03875213]\n",
      " [0.04422278 0.03595548 0.03981612 0.0382745  0.03820362 0.0404743\n",
      "  0.03724071 0.04010743 0.0423643  0.0385269  0.04469392 0.04145656\n",
      "  0.03783486 0.04055949 0.03641708 0.04613653 0.03890232 0.03884379\n",
      "  0.0433591  0.04246356 0.03813379 0.03821733 0.03708843 0.04069539\n",
      "  0.04001173]\n",
      " [0.04323867 0.03939127 0.0386828  0.03764429 0.03728799 0.04091942\n",
      "  0.0391627  0.03993563 0.0394051  0.03622545 0.04498272 0.04149627\n",
      "  0.0362864  0.03950353 0.03759376 0.04356014 0.03913745 0.04004014\n",
      "  0.04416379 0.04142153 0.03875478 0.03927253 0.03822008 0.0435035\n",
      "  0.04017013]\n",
      " [0.04114492 0.03991687 0.04032345 0.03563623 0.04003524 0.03930673\n",
      "  0.04041525 0.03948209 0.04260235 0.03737101 0.04630564 0.04289731\n",
      "  0.04108919 0.03930281 0.03713974 0.04184209 0.03811634 0.03747228\n",
      "  0.04157709 0.04129509 0.03901713 0.03793821 0.03724027 0.04222783\n",
      "  0.04030486]\n",
      " [0.03976063 0.03867752 0.03838941 0.03911721 0.04027865 0.04071248\n",
      "  0.04091071 0.04004832 0.04338492 0.03785113 0.04426778 0.04164944\n",
      "  0.0405213  0.04103632 0.03483516 0.04496578 0.03929766 0.03783816\n",
      "  0.03901934 0.03909129 0.03733068 0.03735606 0.03731955 0.0454495\n",
      "  0.04089111]\n",
      " [0.04222656 0.03696524 0.03761523 0.03935517 0.03859497 0.03940643\n",
      "  0.04133827 0.04109738 0.04210068 0.03695696 0.04532025 0.04193776\n",
      "  0.03930463 0.04022905 0.03646096 0.04377427 0.03943485 0.03876366\n",
      "  0.04226989 0.04152563 0.03779209 0.03741947 0.03847839 0.04212332\n",
      "  0.03950884]\n",
      " [0.04104725 0.03753608 0.04034782 0.03677999 0.03884973 0.03922347\n",
      "  0.03909108 0.04125809 0.04435877 0.03806078 0.0445481  0.04099317\n",
      "  0.04084055 0.04101332 0.03554412 0.04545147 0.03880953 0.0387895\n",
      "  0.04121999 0.03947418 0.03820879 0.03986263 0.03652439 0.04348504\n",
      "  0.03868218]\n",
      " [0.04276047 0.03797296 0.04551882 0.03709596 0.03937808 0.03915322\n",
      "  0.0381746  0.0371895  0.04353653 0.03729453 0.04744313 0.04019303\n",
      "  0.04044054 0.04049947 0.03636892 0.04318908 0.03974414 0.03677853\n",
      "  0.04005323 0.03947304 0.03753104 0.03944999 0.03737185 0.04320237\n",
      "  0.04018698]\n",
      " [0.04262136 0.03688524 0.04231353 0.03904052 0.03829852 0.04138624\n",
      "  0.04045956 0.03993453 0.04140741 0.03591758 0.04538162 0.04171677\n",
      "  0.04157533 0.03999255 0.03630879 0.04264912 0.03640428 0.03866393\n",
      "  0.04096953 0.0401372  0.03700636 0.03991054 0.03835129 0.04324823\n",
      "  0.03942002]\n",
      " [0.04079352 0.03652616 0.0407045  0.03687882 0.03975582 0.04001794\n",
      "  0.03899326 0.04106675 0.04426218 0.04220585 0.04319413 0.04318518\n",
      "  0.04064697 0.04013965 0.0365837  0.04339122 0.03959429 0.03557364\n",
      "  0.04115099 0.04172903 0.03852583 0.03833457 0.03811337 0.04140512\n",
      "  0.03722741]\n",
      " [0.04443553 0.03811408 0.04038184 0.03459226 0.03809395 0.04011916\n",
      "  0.03771333 0.04231931 0.04442743 0.03965336 0.04544974 0.04430318\n",
      "  0.03818433 0.0422854  0.03537899 0.03919438 0.03907099 0.03956429\n",
      "  0.03981804 0.0410573  0.03688167 0.03801323 0.037427   0.04207653\n",
      "  0.0414446 ]\n",
      " [0.04144038 0.03808247 0.03873175 0.03745314 0.03943693 0.04039323\n",
      "  0.04028368 0.03907811 0.04263286 0.03678461 0.04488188 0.03974961\n",
      "  0.03971497 0.04107152 0.03768564 0.04511441 0.03732648 0.03791984\n",
      "  0.04140846 0.03946398 0.04021346 0.03818119 0.0379799  0.04591398\n",
      "  0.03905747]\n",
      " [0.04170924 0.0364405  0.03876538 0.03763004 0.03752669 0.04122813\n",
      "  0.04148509 0.03859083 0.04179855 0.03706642 0.04502973 0.04222127\n",
      "  0.03783924 0.04189884 0.0363132  0.04430398 0.03821244 0.03853535\n",
      "  0.04325295 0.03970346 0.03778105 0.03918839 0.0385887  0.0442412\n",
      "  0.04064923]\n",
      " [0.04066788 0.03785981 0.03760751 0.03821201 0.03831569 0.03982428\n",
      "  0.04133587 0.04075998 0.04262937 0.03764124 0.04153042 0.04369569\n",
      "  0.03852301 0.04120906 0.03692498 0.04406951 0.0406583  0.03839311\n",
      "  0.04118848 0.03965721 0.04011968 0.03888598 0.03646187 0.04484413\n",
      "  0.03898497]\n",
      " [0.04184993 0.03706317 0.03838664 0.03769977 0.0380536  0.04002193\n",
      "  0.03937497 0.03937022 0.04264697 0.03555588 0.04505799 0.04179335\n",
      "  0.03845344 0.03950727 0.04007928 0.04269976 0.03908199 0.03906088\n",
      "  0.04101695 0.0415488  0.03896181 0.03876314 0.03888872 0.0451499\n",
      "  0.03991359]\n",
      " [0.04190867 0.03673604 0.03794385 0.03900147 0.03648845 0.03968228\n",
      "  0.0400543  0.03799501 0.04301646 0.03676386 0.04390934 0.04295043\n",
      "  0.03840787 0.03969027 0.0380127  0.04390748 0.0377818  0.03903502\n",
      "  0.04198702 0.03979772 0.04070031 0.03922255 0.03744075 0.04572061\n",
      "  0.04184573]\n",
      " [0.04482776 0.03893284 0.04063888 0.03733414 0.03722243 0.0436942\n",
      "  0.03936098 0.0408909  0.04378594 0.03844641 0.04387961 0.04207765\n",
      "  0.03984788 0.0387263  0.03474199 0.04260216 0.03925646 0.0371238\n",
      "  0.03967562 0.04148813 0.03655646 0.03971182 0.03838554 0.04093504\n",
      "  0.03985705]\n",
      " [0.04315729 0.0367018  0.04116715 0.03898084 0.03803201 0.04361491\n",
      "  0.03983025 0.03978333 0.04409108 0.03571327 0.04117572 0.0430801\n",
      "  0.04165206 0.03867521 0.03505634 0.04231578 0.0380966  0.03840108\n",
      "  0.04129583 0.04140307 0.03601778 0.04139436 0.03908421 0.04236081\n",
      "  0.03891912]\n",
      " [0.04302629 0.03856834 0.03967356 0.03628305 0.04050062 0.04009081\n",
      "  0.03890201 0.04202373 0.04666631 0.03871636 0.04455367 0.04272356\n",
      "  0.03685058 0.04205955 0.03613491 0.03928258 0.03896287 0.03969298\n",
      "  0.0381523  0.0405068  0.03759278 0.03731311 0.03981837 0.04243732\n",
      "  0.03946757]\n",
      " [0.04139065 0.03659671 0.04075526 0.03852813 0.03851445 0.04009833\n",
      "  0.04243608 0.03822701 0.04100822 0.0386823  0.04363355 0.04214517\n",
      "  0.03931066 0.0391263  0.03844685 0.04400222 0.03799539 0.03794619\n",
      "  0.0421368  0.04112005 0.03749054 0.03905819 0.03650079 0.04409232\n",
      "  0.04075792]\n",
      " [0.04414448 0.03613102 0.03898884 0.03924523 0.03706501 0.04018744\n",
      "  0.03918663 0.04041392 0.04290715 0.0373959  0.04412065 0.04194773\n",
      "  0.03885124 0.0409326  0.03796516 0.0427609  0.03879535 0.03976798\n",
      "  0.04270487 0.0397353  0.04013063 0.03680183 0.03785902 0.04379978\n",
      "  0.03816129]\n",
      " [0.04308436 0.03943896 0.03912453 0.03575373 0.03884769 0.04135974\n",
      "  0.03922771 0.04199542 0.04392021 0.03894896 0.04589402 0.04332437\n",
      "  0.03705876 0.04155605 0.03580651 0.03955991 0.03965421 0.03840491\n",
      "  0.040421   0.04052868 0.03966574 0.03665348 0.03664541 0.04287072\n",
      "  0.04025493]]\n",
      "src tensor([ 2, 23, 22, 21,  3, 24,  3,  5, 10,  3,  1,  0])\n",
      "trg tensor([ 2, 36, 52, 24, 56,  6, 49, 20, 49,  1,  0])\n",
      "output vs intput attention shape (11, 12)\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "'int' object is not iterable",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mTypeError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[53], line 379\u001B[0m\n\u001B[0;32m    374\u001B[0m     train_loss, train_accuracy \u001B[39m=\u001B[39m train(model, train_dataloader, optimizer, criterion, CLIP)\n\u001B[0;32m    377\u001B[0m     gbar\u001B[39m.\u001B[39mset_postfix(train_loss\u001B[39m=\u001B[39mtrain_loss, train_acc\u001B[39m=\u001B[39mtrain_accuracy, val_loss\u001B[39m=\u001B[39mvalid_loss, val_acc\u001B[39m=\u001B[39mvalid_accuracy)\n\u001B[1;32m--> 379\u001B[0m plot_attention_heatmap(model,valid_dataloader)\n\u001B[0;32m    381\u001B[0m \u001B[39m# predict(model, pred_src, pred_trg)\u001B[39;00m\n\u001B[0;32m    382\u001B[0m \u001B[39m# predict(model,\"$बिन्द्या|\",\"$bindya|\")\u001B[39;00m\n",
      "Cell \u001B[1;32mIn[53], line 264\u001B[0m, in \u001B[0;36mplot_attention_heatmap\u001B[1;34m(model, iterator)\u001B[0m\n\u001B[0;32m    262\u001B[0m axes[j]\u001B[39m.\u001B[39mset_ylabel(\u001B[39m\"\u001B[39m\u001B[39mOutput\u001B[39m\u001B[39m\"\u001B[39m)\n\u001B[0;32m    263\u001B[0m \u001B[39m# Set x-tick labels and rotate if needed\u001B[39;00m\n\u001B[1;32m--> 264\u001B[0m input_characters \u001B[39m=\u001B[39m [INPUT_INDX_CHAR[i] \u001B[39mfor\u001B[39;00m i \u001B[39min\u001B[39;00m src[j]\u001B[39m.\u001B[39mtolist()]\n\u001B[0;32m    265\u001B[0m output_characters \u001B[39m=\u001B[39m [OUTPUT_INDEX_CHAR[i] \u001B[39mfor\u001B[39;00m i \u001B[39min\u001B[39;00m trg[j]\u001B[39m.\u001B[39mtolist()]\n\u001B[0;32m    266\u001B[0m axes[j]\u001B[39m.\u001B[39mset_xticklabels(input_characters, rotation\u001B[39m=\u001B[39m\u001B[39m90\u001B[39m)\n",
      "\u001B[1;31mTypeError\u001B[0m: 'int' object is not iterable"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x1000 with 9 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "\n",
    "\n",
    "class Encoder(nn.Module):\n",
    "    def __init__(self, input_size, embedding_size, hidden_size, num_layers, dropout, cell_type, bidirectional=True, batch_size=BATCH_SIZE):\n",
    "        super().__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_layers = num_layers\n",
    "        self.embedding = nn.Embedding(input_size, embedding_size)\n",
    "        self.cell_type = cell_type\n",
    "        self.batch_size = batch_size\n",
    "        self.bidirectional = bidirectional\n",
    "        if cell_type == 'RNN':\n",
    "            self.rnn = nn.RNN(embedding_size, hidden_size, num_layers, dropout=dropout, bidirectional=bidirectional)\n",
    "        elif cell_type == 'LSTM':\n",
    "            self.rnn = nn.LSTM(embedding_size, hidden_size, num_layers, dropout=dropout, bidirectional=bidirectional)\n",
    "        elif cell_type == 'GRU':\n",
    "            self.rnn = nn.GRU(embedding_size, hidden_size, num_layers, dropout=dropout, bidirectional=bidirectional)\n",
    "        # self.rnn = nn.LSTM(embedding_size, hidden_size, n_layers, dropout=dropout)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self, src, hidden=None):\n",
    "        self.batch_size = src.shape[1]\n",
    "        embedded = self.dropout(self.embedding(src))\n",
    "        if self.cell_type == 'LSTM':\n",
    "            output, (hidden, cell) = self.rnn(embedded)\n",
    "        else:\n",
    "            output, hidden = self.rnn(embedded,hidden)\n",
    "        if self.bidirectional:\n",
    "    # Split hidden and cell into two halves along the first dimension\n",
    "            hidden_chunks = torch.chunk(hidden, 2, dim=0)\n",
    "            hidden = 0.5 * (hidden_chunks[0] + hidden_chunks[1])\n",
    "\n",
    "            if self.cell_type == \"LSTM\":\n",
    "                cell_chunks = torch.chunk(cell, 2, dim=0)\n",
    "                cell = 0.5 * (cell_chunks[0] + cell_chunks[1])\n",
    "\n",
    "    # Compute the average of forward and backward outputs\n",
    "            output = output.permute(2, 1, 0)\n",
    "            output_chunks = torch.chunk(output, 2, dim=0)\n",
    "            output = 0.5 * (output_chunks[0] + output_chunks[1])\n",
    "            output = output.permute(2, 1, 0)\n",
    "\n",
    "        if (self.cell_type == \"LSTM\"):\n",
    "            return output, hidden, cell\n",
    "        else:\n",
    "            return output, hidden\n",
    "\n",
    "    def initHidden(self):\n",
    "        if self.bidirectional == True:\n",
    "            return torch.zeros(2*self.num_layers, self.batch_size, self.hidden_size, device=device)\n",
    "        else:\n",
    "            return torch.zeros(self.num_layers, self.batch_size, self.hidden_size, device=device)\n",
    "\n",
    "# write decoder with attention\n",
    "\n",
    "\n",
    "class Decoder_with_attention(nn.Module):\n",
    "    def __init__(self,hidden_size,output_size,num_layers,dropout,embedding_size, cell_type =\"LSTM\",batch_size=BATCH_SIZE):\n",
    "        super(Decoder_with_attention,self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.output_size = output_size\n",
    "        self.num_layers = num_layers\n",
    "        self.batch_size = batch_size\n",
    "        self.embedding_size = embedding_size\n",
    "        self.cell_type = cell_type\n",
    "        self.embedding = nn.Embedding(output_size,embedding_size)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.attn = nn.Linear(self.hidden_size+self.embedding_size,MAX_LENGTH)\n",
    "        self.attn_combine = nn.Linear(self.hidden_size+self.embedding_size,self.hidden_size)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        if cell_type == 'RNN':\n",
    "            self.rnn = nn.RNN(self.hidden_size,self.hidden_size,num_layers,dropout=dropout)\n",
    "        elif cell_type == 'LSTM':\n",
    "            self.rnn = nn.LSTM(self.hidden_size,self.hidden_size,num_layers,dropout=dropout)\n",
    "        elif cell_type == 'GRU':\n",
    "            self.rnn = nn.GRU(self.hidden_size,self.hidden_size,num_layers,dropout=dropout)\n",
    "\n",
    "        self.out = nn.Linear(self.hidden_size,self.output_size)\n",
    "        self.softmax = nn.LogSoftmax(dim=1)\n",
    "\n",
    "    def forward(self,input,hidden,encoder_outputs):\n",
    "    \n",
    "        input = input.unsqueeze(0)\n",
    "        self.batch_size = input.size(1)\n",
    "        output = self.embedding(input).view(-1,self.batch_size,self.embedding_size)\n",
    "        output = self.dropout(output)\n",
    "        if self.cell_type == \"LSTM\":\n",
    "            attn_weights = F.softmax(self.attn(torch.cat((output[0],hidden[0][0]),1)),dim=1)\n",
    "        else:\n",
    "            attn_weights = F.softmax(self.attn(torch.cat((output[0],hidden[0]),1)),dim=1)\n",
    "\n",
    "        attn_applied = torch.bmm(attn_weights.unsqueeze(1),encoder_outputs.permute(1,0,2))\n",
    "        attn_applied = attn_applied.squeeze(1)\n",
    "        # print(\"attention applied shape\",attn_applied.shape)\n",
    "        output = torch.cat((output[0],attn_applied),1)\n",
    "        output = self.attn_combine(output).unsqueeze(0)\n",
    "        output = F.relu(output)\n",
    "        if self.cell_type == \"LSTM\":\n",
    "            output,(hidden,cell) = self.rnn(output,(hidden[0],hidden[1]))\n",
    "            return self.out(output[0]),hidden,cell,attn_weights\n",
    "        else:\n",
    "            output,hidden = self.rnn(output,hidden)\n",
    "            return self.out(output[0]),hidden,attn_weights  \n",
    "        \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "class Seq2Seq(nn.Module):\n",
    "    def __init__(self, encoder, decoder, device, teacher_forcing_ratio=0.5,heatmap=False):\n",
    "        super().__init__()\n",
    "        self.encoder = encoder\n",
    "        self.decoder = decoder\n",
    "        self.device = device\n",
    "        self.heatmap = heatmap\n",
    "        self.teacher_forcing_ratio = teacher_forcing_ratio\n",
    "\n",
    "    def forward(self, src, trg, heatmap=False):\n",
    "        attention_weights = []\n",
    "        batch_size = trg.shape[1]\n",
    "        trg_len = trg.shape[0]\n",
    "        trg_vocab_size = self.decoder.output_size\n",
    "        outputs = torch.zeros(trg_len, batch_size, trg_vocab_size).to(self.device)\n",
    "        encoder_hidden = self.encoder.initHidden()\n",
    "        # encoder_hidden = self.encoder.initHidden()\n",
    "        if self.encoder.cell_type == 'LSTM':\n",
    "            encoder_output, encoder_hidden, encoder_cell = self.encoder(src,encoder_hidden)\n",
    "        else:\n",
    "            encoder_output, encoder_hidden = self.encoder(src,encoder_hidden)\n",
    "        input_decoder = trg[0, :]\n",
    "        decoder_hidden = encoder_hidden\n",
    "\n",
    "        if self.decoder.cell_type == 'LSTM':\n",
    "            decoder_cell = encoder_cell\n",
    "\n",
    "        \n",
    "        for t in range(1, trg_len):\n",
    "            if self.decoder.cell_type == 'LSTM':\n",
    "                decoder_output, decoder_hidden, decoder_cell,attn_weights = self.decoder(input_decoder,( decoder_hidden, decoder_cell),encoder_output)\n",
    "\n",
    "            else:\n",
    "                decoder_output, decoder_hidden, attn_weights = self.decoder(input_decoder, decoder_hidden,encoder_output)\n",
    "            # print(\"attention_weights\",attn_weights)\n",
    "            if(heatmap):\n",
    "                attention_weights.append(attn_weights)\n",
    "            outputs[t] = decoder_output\n",
    "            teacher_force = random.random() < self.teacher_forcing_ratio\n",
    "            top1 = decoder_output.argmax(1)\n",
    "            input_decoder = trg[t] if teacher_force else top1\n",
    "        \n",
    "        return outputs,attention_weights\n",
    "\n",
    "\n",
    "def get_accuracy(preds, target):\n",
    "    \"\"\"\n",
    "    Returns accuracy per batch, i.e. if you get 8/10 right, this returns 0.8, NOT 8\n",
    "    \"\"\"\n",
    "    preds = preds.argmax(dim=2)\n",
    "    preds = preds[1:]\n",
    "    target = target[1:]\n",
    "    matches = torch.eq(preds, target)\n",
    "    columns_matches = torch.sum(matches, dim=0)\n",
    "    num_matching_columns = torch.sum(columns_matches == target.shape[0])\n",
    "    acc = num_matching_columns / target.shape[1]\n",
    "    return acc.item()\n",
    "\n",
    "\n",
    "def train(model, iterator, optimizer, criterion, clip):\n",
    "    model.train()\n",
    "    epoch_loss = 0\n",
    "    epoch_acc = 0\n",
    "    pbar = tqdm(iterator, desc=\"Training\", position=0, leave=True)\n",
    "    \n",
    "    for i, (data, target) in enumerate(pbar):\n",
    "        src = data.to(device)\n",
    "        trg = target.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        output,attn_weights = model(src, trg)\n",
    "        # print(\"attention weights\", attn_weights)\n",
    "        # print(\"attention weights shape\", attn_weights.shape)\n",
    "        # attn_weightscpu = attn_weights.cpu().detach().numpy()\n",
    "        # sns.heatmap(attn_weightscpu, cmap=\"YlGnBu\", annot=False,fmt='.2f')\n",
    "        # plt.show()\n",
    "        output_dim = output.shape[-1]\n",
    "        output_reshaped = output[1:].reshape(-1, output_dim)\n",
    "        trg_reshaped = trg[1:].reshape(-1)\n",
    "        loss = criterion(output_reshaped, trg_reshaped)\n",
    "        loss.backward()\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), clip)\n",
    "        optimizer.step()\n",
    "        acc = get_accuracy(output, trg)\n",
    "        epoch_acc += acc\n",
    "        epoch_loss += loss.item()\n",
    "        pbar.set_postfix(train_loss=epoch_loss / (i + 1), train_acc=epoch_acc / (i + 1))\n",
    "        if True:\n",
    "            break\n",
    "    return epoch_loss / len(iterator), epoch_acc / len(iterator)\n",
    "\n",
    "\n",
    "from matplotlib.font_manager import FontProperties\n",
    "font_prop = FontProperties(fname='Mangal 400.TTF')\n",
    "\n",
    "def plot_attention_heatmap(model,iterator):\n",
    "    for i, (data, target) in enumerate(iterator):\n",
    "        src = data.to(device)\n",
    "        trg = target.to(device)\n",
    "        #get first 10 examples\n",
    "        # src = data[:10].to(device)\n",
    "        # trg = target[:10].to(device)\n",
    "        output,attention_weights= model(src,trg,heatmap=True)\n",
    "        # attention_weights = torch.stack(attention_weights).squeeze()  # Convert the list to a tensor\n",
    "        # attention_weights = torch.cat(attention_weights, dim=0) \n",
    "        # attention_weights = torch.stack(attention_weights).squeeze().cpu().detach().numpy()\n",
    "        attention_weights = torch.stack(attention_weights, dim=0)  # Convert the list to a tensor\n",
    "\n",
    "        attention_weights = attention_weights.squeeze().cpu().detach().numpy()  # Convert the tensor to a numpy array\n",
    "        #attention_weights shape = (trg_len, batch_size, src_len)\n",
    "        # attention_weights.permute(1,0,2)\n",
    "        attention_weights = attention_weights.transpose(1,0,2)\n",
    "        # attention_weights shape = (batch_size, trg_len, src_len)\n",
    "        # print(\"attention weights shape\",attention_weights.shape)\n",
    "        # print(\"attention weights\",attention_weights)\n",
    "        #get first 10 examples\n",
    "        attention_weights = attention_weights[:10]\n",
    "        #get first 10 examples\n",
    "        # src shape = (src_len, batch_size)\n",
    "        src = src.transpose(1,0)\n",
    "        trg = trg.transpose(1,0)\n",
    "        src = src[:10]\n",
    "        trg = trg[:10]\n",
    "\n",
    "\n",
    "        fig, axes = plt.subplots(3, 3, figsize=(10,10))\n",
    "        fig.tight_layout(pad=5.0)\n",
    "        fig.subplots_adjust(top=0.90)\n",
    "        axes = axes.ravel()\n",
    "\n",
    "        for j in range(attention_weights.shape[0]):\n",
    "            output_vs_input_attention = attention_weights[j]\n",
    "            print(\"Output_vs_input_attention:\", output_vs_input_attention)\n",
    "            max_src_len = src.shape[1]\n",
    "            max_trg_len = trg.shape[1]\n",
    "            for k in range(max_src_len):\n",
    "                if src[j][k] == 0:\n",
    "                    max_src_len = k+1\n",
    "                    break\n",
    "            \n",
    "            for k in range(max_trg_len):\n",
    "                if trg[j][k] == 0:\n",
    "                    max_trg_len = k+1\n",
    "                    break\n",
    "            src = src[j][:max_src_len] \n",
    "            trg = trg[j][:max_trg_len]\n",
    "            print(\"src\", src)\n",
    "            print(\"trg\", trg)\n",
    "            output_vs_input_attention = output_vs_input_attention[:max_trg_len, :max_src_len]\n",
    "            print(\"output vs intput attention shape\", output_vs_input_attention.shape)\n",
    "\n",
    "            # Plot heatmap\n",
    "            # heatmap = axes.imshow(output_vs_input_attention, cmap='hot',cbar=False)\n",
    "\n",
    "            # Set x-axis and y-axis labels\n",
    "            axes[j].set_xlabel(\"Input\")\n",
    "            axes[j].set_ylabel(\"Output\")\n",
    "            # Set x-tick labels and rotate if needed\n",
    "            input_characters = [INPUT_INDX_CHAR[i] for i in src[j].tolist()]\n",
    "            output_characters = [OUTPUT_INDEX_CHAR[i] for i in trg[j].tolist()]\n",
    "            axes[j].set_xticklabels(input_characters, rotation=90)\n",
    "            \n",
    "            # Set y-tick labels\n",
    "            axes[j].set_yticklabels(output_characters, fontproperties = font_prop, fontdict={'fontsize':16})\n",
    "            sns.heatmap(output_vs_input_attention, cmap=\"YlGnBu\",cbar=False)\n",
    "            # # Show the colorbar\n",
    "            # cbar = ax.figure.colorbar(heatmap, ax=ax)\n",
    "\n",
    "            # Adjust plot layout for better alignment\n",
    "\n",
    "            \n",
    "            # if True:\n",
    "            #     break\n",
    "\n",
    "\n",
    "\n",
    "        \n",
    "        fig.tight_layout()\n",
    "\n",
    "            # Show the plot\n",
    "        plt.show()\n",
    "\n",
    "\n",
    "        if True:\n",
    "            break\n",
    "\n",
    "\n",
    "\n",
    "def evaluate(model, iterator, criterion):\n",
    "    model.eval()\n",
    "    epoch_loss = 0\n",
    "    epoch_acc = 0\n",
    "    # with torch.no_grad():\n",
    "    for i, (data, target) in enumerate(iterator):\n",
    "        src = data.to(device)\n",
    "        trg = target.to(device)\n",
    "        output, _ = model(src, trg)\n",
    "        output_dim = output.shape[-1]\n",
    "        output_reshaped = output[1:].reshape(-1, output_dim)\n",
    "        trg_reshaped = trg[1:].reshape(-1)\n",
    "        loss = criterion(output_reshaped, trg_reshaped)\n",
    "        acc = get_accuracy(output, trg)\n",
    "        epoch_acc += acc\n",
    "        epoch_loss += loss.item()\n",
    "    return epoch_loss / len(iterator), epoch_acc / len(iterator)\n",
    "\n",
    "\n",
    "def predict(model, input_word, actual_output):\n",
    "    data_pred = [[input_word, actual_output]]\n",
    "    data_batch = DataLoader(data_pred, batch_size=BATCH_SIZE, shuffle=False, collate_fn=generate_batch)\n",
    "    iterator = data_batch\n",
    "\n",
    "    src = data\n",
    "    trg = target\n",
    "    output = model(src, trg, 0)\n",
    "    output_dim = output.shape[-1]\n",
    "    # output_reshaped = output[1:].reshape(-1, output_dim)\n",
    "    # trg_reshaped = trg[1:].reshape(-1)\n",
    "    preds = output.argmax(dim=2)\n",
    "    print(\"input word\", input_word)\n",
    "    print(\"actual word\", actual_output)\n",
    "    predicted_word = \"\"\n",
    "    for i in preds:\n",
    "        if i.item() in [0, 1, 2]:\n",
    "            continue\n",
    "        predicted_word += predicted_word + OUTPUT_INDEX_CHAR[i.item()]\n",
    "    print(\"predicted word\", predicted_word)\n",
    "    return preds\n",
    "\n",
    "\n",
    "N_EPOCHS = 1\n",
    "CLIP = 1\n",
    "INPUT_DIM = input_vocab_size\n",
    "OUTPUT_DIM = output_vocab_size\n",
    "ENC_EMB_DIM = 128\n",
    "DEC_EMB_DIM = 128\n",
    "HIDDEN_SIZE = 256\n",
    "num_layers = 1\n",
    "ENC_DROPOUT = 0.5\n",
    "DEC_DROPOUT = 0.5\n",
    "TEACHER_FORCING = 0.5\n",
    "BI_DIRECTION = True\n",
    "CELL_TYPE = 'LSTM'\n",
    "pred_src = \"$bindya|\"\n",
    "pred_trg = '$बिन्द्या|'\n",
    "BATCH_SIZE = 32\n",
    "enc = Encoder(input_size=INPUT_DIM, embedding_size=ENC_EMB_DIM, hidden_size=HIDDEN_SIZE, num_layers=num_layers,\n",
    "              dropout=ENC_DROPOUT, cell_type=CELL_TYPE, bidirectional=BI_DIRECTION)\n",
    "dec = Decoder_with_attention(output_size=OUTPUT_DIM, embedding_size=DEC_EMB_DIM, hidden_size=HIDDEN_SIZE, num_layers=num_layers,\n",
    "              dropout=DEC_DROPOUT, cell_type=CELL_TYPE,batch_size=BATCH_SIZE)\n",
    "\n",
    "model = Seq2Seq(enc, dec, device, teacher_forcing_ratio=TEACHER_FORCING).to(device)\n",
    "\n",
    "\n",
    "def init_weights(m):\n",
    "    for name, param in m.named_parameters():\n",
    "        nn.init.uniform_(param.data, -0.08, 0.08)\n",
    "\n",
    "\n",
    "model.apply(init_weights)\n",
    "optimizer = optim.Adam(model.parameters())\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "train_dataloader = DataLoader(train_data, batch_size=BATCH_SIZE, shuffle=True, collate_fn=generate_batch)\n",
    "valid_dataloader = DataLoader(valid_data, batch_size=BATCH_SIZE, shuffle=True, collate_fn=generate_batch)\n",
    "best_valid_loss = float('inf')\n",
    "gbar = tqdm(range(1, N_EPOCHS + 1), position=1, leave=True, desc='Epochs', total=N_EPOCHS)\n",
    "for epoch in gbar:\n",
    "    train_loss, train_accuracy = train(model, train_dataloader, optimizer, criterion, CLIP)\n",
    "\n",
    "\n",
    "    gbar.set_postfix(train_loss=train_loss, train_acc=train_accuracy, val_loss=valid_loss, val_acc=valid_accuracy)\n",
    "\n",
    "plot_attention_heatmap(model,valid_dataloader)\n",
    "\n",
    "# predict(model, pred_src, pred_trg)\n",
    "# predict(model,\"$बिन्द्या|\",\"$bindya|\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25\n"
     ]
    }
   ],
   "source": [
    "print(MAX_LENGTH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "sweep_config = {\n",
    "  \"name\": \"CS6910 Assignment 3\",\n",
    "  \"metric\": {\n",
    "      \"name\":\"validation_accuracy\",\n",
    "      \"goal\": \"maximize\"\n",
    "  },\n",
    "  \"method\": \"bayes\",\n",
    "  \"parameters\": {\n",
    "        \n",
    "        \"cell_type\": {\n",
    "            \"values\": [\"LSTM\",\"GRU\"]\n",
    "        },\n",
    "        \"bidirectional\": {\n",
    "            \"values\": [True, False]\n",
    "        },\n",
    "        \"num_epochs\": {\n",
    "            \"values\": [20,25]\n",
    "        },\n",
    "        \"num_layers\": {\n",
    "            \"values\": [1, 2, 3]\n",
    "        },\n",
    "        \"batch_size\": {\n",
    "            \"values\": [32,64,128]\n",
    "        },\n",
    "        \"embedding_size\": {\n",
    "            \"values\": [128, 256, 512]\n",
    "        },\n",
    "        \"hidden_size\": {\n",
    "            \"values\": [128, 256, 512]\n",
    "        },\n",
    "        \"learning_rate\": {\n",
    "            \"values\": [0.001,0.0001]\n",
    "        },\n",
    "        \"enc_dropout\": {\n",
    "            \"values\": [0.2,0.3,0.5]\n",
    "        },\n",
    "        \"dec_dropout\": {\n",
    "            \"values\": [0.2,0.3,0.5]\n",
    "        }\n",
    "    }\n",
    "}\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_train(INPUT_DIM, OUTPUT_DIM, EMBEDDING_SIZE, HIDDEN_SIZE, NUM_LAYERS, ENC_DROPOUT, DEC_DROPOUT,  BIDIRECTIONAL, CELL_TYPE, LEARNING_RATE, N_EPOCHS, CLIP,BATCH_SIZE):\n",
    "    train_dataloader = DataLoader(train_data, batch_size=BATCH_SIZE, shuffle=True, collate_fn=generate_batch)\n",
    "    valid_dataloader = DataLoader(valid_data, batch_size=BATCH_SIZE, shuffle=True, collate_fn=generate_batch)\n",
    "    encoder = Encoder(input_size=INPUT_DIM, embedding_size=EMBEDDING_SIZE, hidden_size=HIDDEN_SIZE, num_layers=NUM_LAYERS, dropout=ENC_DROPOUT, bidirectional=BIDIRECTIONAL, cell_type=CELL_TYPE)\n",
    "    decoder = Decoder(output_dim=OUTPUT_DIM, emb_dim=EMBEDDING_SIZE, hidden_size=HIDDEN_SIZE, num_layers=NUM_LAYERS, dropout=DEC_DROPOUT, cell_type=CELL_TYPE)\n",
    "    model = Seq2Seq(encoder, decoder, device).to(device)\n",
    "    optimizer = optim.Adam(model.parameters(), lr=LEARNING_RATE)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    # pbar = tqdm(range(N_EPOCHS), desc=\"Epochs\",position=0, leave=True)\n",
    "    gbar = tqdm(range(1, N_EPOCHS + 1),position=1,leave=True, desc='Epochs', total=N_EPOCHS)\n",
    "#     gbar = N_EPOCHS\n",
    "    for epoch in gbar:\n",
    "\n",
    "        train_loss, train_acc = train(model, train_dataloader, optimizer, criterion, clip=CLIP)\n",
    "        # print(run_name)\n",
    "        valid_loss, valid_acc = evaluate(model,valid_dataloader, criterion)\n",
    "        print(\"Epoch: \",epoch)\n",
    "        print(f'\\tTrain Loss: {train_loss:.3f} | Train Acc: {train_acc * 100:.2f}%')\n",
    "        print(f'\\t Val. Loss: {valid_loss:.3f} |  Val. Acc: {valid_acc * 100:.2f}%')\n",
    "        wandb.log({\"train_loss\": train_loss, \"train_acc\": train_acc, \"valid_loss\": valid_loss, \"valid_acc\": valid_acc})\n",
    "        gbar.set_postfix(train_loss=train_loss, train_acc=train_acc, valid_loss=valid_loss, valid_acc=valid_acc)\n",
    "    return valid_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_wandb():\n",
    "    wandb.init()\n",
    "    config = wandb.config\n",
    "    LEARNING_RATE = config.learning_rate\n",
    "    BATCH_SIZE = config.batch_size\n",
    "    EMBEDDING_SIZE = config.embedding_size\n",
    "    HIDDEN_SIZE = config.hidden_size\n",
    "    ENC_DROPOUT = config.enc_dropout\n",
    "    DEC_DROPOUT = config.dec_dropout\n",
    "    NUM_LAYERS = config.num_layers\n",
    "    BIDIRECTIONAL = config.bidirectional\n",
    "    CELL_TYPE = config.cell_type\n",
    "    N_EPOCHS = config.num_epochs\n",
    "    CLIP = 1\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    INPUT_DIM = len(INPUT_CHAR_INDX)\n",
    "    OUTPUT_DIM = len(OUTPUT_CHAR_INDEX)\n",
    "    model_train(INPUT_DIM=INPUT_DIM, OUTPUT_DIM=OUTPUT_DIM, EMBEDDING_SIZE=EMBEDDING_SIZE, HIDDEN_SIZE=HIDDEN_SIZE, NUM_LAYERS=NUM_LAYERS, ENC_DROPOUT=ENC_DROPOUT,DEC_DROPOUT=DEC_DROPOUT, BIDIRECTIONAL=BIDIRECTIONAL, CELL_TYPE=CELL_TYPE, LEARNING_RATE=LEARNING_RATE, N_EPOCHS=N_EPOCHS, CLIP=CLIP,BATCH_SIZE=BATCH_SIZE)\n",
    "    # best_valid_loss = float('inf')\n",
    "    print(\"cell_type\",CELL_TYPE,\"bidirectional\",BIDIRECTIONAL,\"num_layers\",NUM_LAYERS,\"batch_size\",BATCH_SIZE,\"embedding_size\",EMBEDDING_SIZE,\"hidden_size\",HIDDEN_SIZE,\"enc_dropout\",ENC_DROPOUT,\"dec_dropout\",DEC_DROPOUT,\"num_epochs\",N_EPOCHS)\n",
    "    run_name = \"ct_{}_bi_{}_nl_{}_bs_{}_es_{}_hs_{}_endo_{}_decdo_{}_ne_{}\".format(CELL_TYPE,BIDIRECTIONAL,NUM_LAYERS,BATCH_SIZE,EMBEDDING_SIZE,HIDDEN_SIZE,ENC_DROPOUT,DEC_DROPOUT,N_EPOCHS)\n",
    "    print(run_name)\n",
    "    wandb.run.name = run_name\n",
    "    wandb.run.save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # wandb.init()\n",
    "# config=wandb.config\n",
    "# LEARNING_RATE = 0.001\n",
    "# BATCH_SIZE = 32\n",
    "# EMBEDDING_SIZE = 128\n",
    "# HIDDEN_SIZE = 512\n",
    "# ENC_DROPOUT = 0.2\n",
    "# DEC_DROPOUT = 0.2\n",
    "# NUM_LAYERS = 2\n",
    "# BIDIRECTIONAL = True\n",
    "# CELL_TYPE = 'LSTM'\n",
    "# N_EPOCHS = 1\n",
    "# CLIP = 1\n",
    "# device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "# train_dataloader = DataLoader(train_data, batch_size=BATCH_SIZE, shuffle=True, collate_fn=generate_batch)\n",
    "# valid_dataloader = DataLoader(valid_data, batch_size=BATCH_SIZE, shuffle=False,     collate_fn=generate_batch)\n",
    "# INPUT_DIM = len(INPUT_CHAR_INDX)\n",
    "# OUTPUT_DIM = len(OUTPUT_CHAR_INDEX)\n",
    "# model_train(INPUT_DIM=INPUT_DIM, OUTPUT_DIM=OUTPUT_DIM, EMBEDDING_SIZE=EMBEDDING_SIZE, HIDDEN_SIZE=HIDDEN_SIZE, NUM_LAYERS=NUM_LAYERS, ENC_DROPOUT=ENC_DROPOUT,DEC_DROPOUT=DEC_DROPOUT, BIDIRECTIONAL=BIDIRECTIONAL, CELL_TYPE=CELL_TYPE, LEARNING_RATE=LEARNING_RATE, N_EPOCHS=N_EPOCHS, CLIP=CLIP,BATCH_SIZE=BATCH_SIZE)\n",
    "# # best_valid_loss = float('inf')\n",
    "# # run_name = \"ct_{}_bi_{}_nl_{}_bs_{}_es_{}_hs_{}_do_{}_ne{}\".format(CELL_TYPE,BIDIRECTIONAL,NUM_LAYERS,BATCH_SIZE,EMBEDDING_SIZE,HIDDEN_SIZE,DROPOUT,N_EPOCHS)\n",
    "# # print(run_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[34m\u001B[1mwandb\u001B[0m: \u001B[33mWARNING\u001B[0m Calling wandb.login() after wandb.init() has no effect.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Create sweep with ID: x2ojhehe\n",
      "Sweep URL: https://wandb.ai/cs22m045/DL_ASSIGNMENT_3/sweeps/x2ojhehe\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "wandb: Waiting for W&B process to finish... (success).\n",
      "wandb: 🚀 View run graceful-meadow-11 at: https://wandb.ai/cs22m045/DL_ASSIGNMENT_3/runs/n92g2j3z\n",
      "wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\n",
      "wandb: Find logs at: ./wandb/run-20230516_071553-n92g2j3z/logs\n",
      "\u001B[34m\u001B[1mwandb\u001B[0m: Agent Starting Run: as4hm8y3 with config:\n",
      "\u001B[34m\u001B[1mwandb\u001B[0m: \tbatch_size: 64\n",
      "\u001B[34m\u001B[1mwandb\u001B[0m: \tbidirectional: False\n",
      "\u001B[34m\u001B[1mwandb\u001B[0m: \tcell_type: LSTM\n",
      "\u001B[34m\u001B[1mwandb\u001B[0m: \tdec_dropout: 0.5\n",
      "\u001B[34m\u001B[1mwandb\u001B[0m: \tembedding_size: 128\n",
      "\u001B[34m\u001B[1mwandb\u001B[0m: \tenc_dropout: 0.5\n",
      "\u001B[34m\u001B[1mwandb\u001B[0m: \thidden_size: 128\n",
      "\u001B[34m\u001B[1mwandb\u001B[0m: \tlearning_rate: 0.001\n",
      "\u001B[34m\u001B[1mwandb\u001B[0m: \tnum_epochs: 15\n",
      "\u001B[34m\u001B[1mwandb\u001B[0m: \tnum_layers: 1\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.15.2 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.15.0"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/kaggle/working/wandb/run-20230516_071700-as4hm8y3</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/cs22m045/DL_ASSIGNMENT_3/runs/as4hm8y3' target=\"_blank\">ancient-sweep-1</a></strong> to <a href='https://wandb.ai/cs22m045/DL_ASSIGNMENT_3' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/cs22m045/DL_ASSIGNMENT_3/sweeps/x2ojhehe' target=\"_blank\">https://wandb.ai/cs22m045/DL_ASSIGNMENT_3/sweeps/x2ojhehe</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/cs22m045/DL_ASSIGNMENT_3' target=\"_blank\">https://wandb.ai/cs22m045/DL_ASSIGNMENT_3</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/cs22m045/DL_ASSIGNMENT_3/sweeps/x2ojhehe' target=\"_blank\">https://wandb.ai/cs22m045/DL_ASSIGNMENT_3/sweeps/x2ojhehe</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/cs22m045/DL_ASSIGNMENT_3/runs/as4hm8y3' target=\"_blank\">https://wandb.ai/cs22m045/DL_ASSIGNMENT_3/runs/as4hm8y3</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/torch/nn/modules/rnn.py:71: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.5 and num_layers=1\n",
      "  warnings.warn(\"dropout option adds dropout after all but last \"\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b6a1fbe9a205471389e359110fd20e24",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epochs:   0%|          | 0/15 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d96f4a7a3f624af8a825d2e9c6153c55",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training:   0%|          | 0/800 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tTrain Loss: 1.267 | Train Acc: 0.00%\n",
      "\t Val. Loss: 0.873 |  Val. Acc: 0.02%\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ca39fbafe6e74335b53a23abcc5d3cf8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training:   0%|          | 0/800 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tTrain Loss: 1.013 | Train Acc: 0.03%\n",
      "\t Val. Loss: 0.723 |  Val. Acc: 0.59%\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d3ab165077704e11a38edd04295b835b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training:   0%|          | 0/800 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tTrain Loss: 0.849 | Train Acc: 0.22%\n",
      "\t Val. Loss: 0.576 |  Val. Acc: 1.98%\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "562c24c7b15249448a6fd0aa18ba4289",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training:   0%|          | 0/800 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tTrain Loss: 0.715 | Train Acc: 1.16%\n",
      "\t Val. Loss: 0.475 |  Val. Acc: 5.27%\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "505ea329bb524997a908ae0dcc0c8028",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training:   0%|          | 0/800 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tTrain Loss: 0.613 | Train Acc: 2.88%\n",
      "\t Val. Loss: 0.412 |  Val. Acc: 8.96%\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4a56d067e7d84ad9ada21e788644e3b9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training:   0%|          | 0/800 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tTrain Loss: 0.550 | Train Acc: 4.52%\n",
      "\t Val. Loss: 0.381 |  Val. Acc: 11.43%\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "67c2613fc7e5498e8783ad34f1f0b1d4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training:   0%|          | 0/800 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tTrain Loss: 0.503 | Train Acc: 6.20%\n",
      "\t Val. Loss: 0.361 |  Val. Acc: 14.29%\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0c39ed978a05414787bd6bccfbcfa19d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training:   0%|          | 0/800 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tTrain Loss: 0.470 | Train Acc: 7.91%\n",
      "\t Val. Loss: 0.349 |  Val. Acc: 15.04%\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "93b0c550caf244febf98c24a15e85ec7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training:   0%|          | 0/800 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tTrain Loss: 0.445 | Train Acc: 9.28%\n",
      "\t Val. Loss: 0.328 |  Val. Acc: 17.04%\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5f8b84438c8e464a8befdae8b9befe85",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training:   0%|          | 0/800 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tTrain Loss: 0.424 | Train Acc: 10.36%\n",
      "\t Val. Loss: 0.314 |  Val. Acc: 17.68%\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "500ba7fd891d4a99ae35f81662540603",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training:   0%|          | 0/800 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tTrain Loss: 0.406 | Train Acc: 11.70%\n",
      "\t Val. Loss: 0.306 |  Val. Acc: 18.61%\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e2ce3ad49b0d493abfd468609722c0d8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training:   0%|          | 0/800 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tTrain Loss: 0.392 | Train Acc: 12.78%\n",
      "\t Val. Loss: 0.292 |  Val. Acc: 20.49%\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "830e813b336f48d08211fac6f5140ce0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training:   0%|          | 0/800 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tTrain Loss: 0.379 | Train Acc: 13.79%\n",
      "\t Val. Loss: 0.288 |  Val. Acc: 20.17%\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e2728e1e89044370b0e24ff46155563d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training:   0%|          | 0/800 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tTrain Loss: 0.369 | Train Acc: 14.61%\n",
      "\t Val. Loss: 0.282 |  Val. Acc: 20.98%\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7c36eff75eb34974aecb4efc875c2b61",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training:   0%|          | 0/800 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[34m\u001B[1mwandb\u001B[0m: \u001B[33mWARNING\u001B[0m Calling wandb.run.save without any arguments is deprecated.Changes to attributes are automatically persisted.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tTrain Loss: 0.361 | Train Acc: 15.59%\n",
      "\t Val. Loss: 0.277 |  Val. Acc: 21.90%\n",
      "ct_LSTM_bi_False_nl_1_bs_64_es_128_hs_128_endo_0.5_decdo_0.5_ne_15\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>train_acc</td><td>▁▁▁▂▂▃▄▅▅▆▆▇▇██</td></tr><tr><td>train_loss</td><td>█▆▅▄▃▂▂▂▂▁▁▁▁▁▁</td></tr><tr><td>valid_acc</td><td>▁▁▂▃▄▅▆▆▆▇▇█▇██</td></tr><tr><td>valid_loss</td><td>█▆▅▃▃▂▂▂▂▁▁▁▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>train_acc</td><td>0.15588</td></tr><tr><td>train_loss</td><td>0.36053</td></tr><tr><td>valid_acc</td><td>0.21904</td></tr><tr><td>valid_loss</td><td>0.27669</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">ancient-sweep-1</strong> at: <a href='https://wandb.ai/cs22m045/DL_ASSIGNMENT_3/runs/as4hm8y3' target=\"_blank\">https://wandb.ai/cs22m045/DL_ASSIGNMENT_3/runs/as4hm8y3</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20230516_071700-as4hm8y3/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error in callback <function _WandbInit._pause_backend at 0x786e3559fe20> (for post_run_cell):\n"
     ]
    },
    {
     "ename": "BrokenPipeError",
     "evalue": "[Errno 32] Broken pipe",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m\n",
      "\u001B[0;31mBrokenPipeError\u001B[0m                           Traceback (most recent call last)\n",
      "File \u001B[0;32m/opt/conda/lib/python3.10/site-packages/backcall/backcall.py:104\u001B[0m, in \u001B[0;36mcallback_prototype.<locals>.adapt.<locals>.adapted\u001B[0;34m(*args, **kwargs)\u001B[0m\n",
      "\u001B[1;32m    102\u001B[0m                 kwargs\u001B[38;5;241m.\u001B[39mpop(name)\n",
      "\u001B[1;32m    103\u001B[0m \u001B[38;5;66;03m#            print(args, kwargs, unmatched_pos, cut_positional, unmatched_kw)\u001B[39;00m\n",
      "\u001B[0;32m--> 104\u001B[0m             \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mcallback\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "\n",
      "File \u001B[0;32m/opt/conda/lib/python3.10/site-packages/wandb/sdk/wandb_init.py:419\u001B[0m, in \u001B[0;36m_WandbInit._pause_backend\u001B[0;34m(self)\u001B[0m\n",
      "\u001B[1;32m    417\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mbackend\u001B[38;5;241m.\u001B[39minterface \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n",
      "\u001B[1;32m    418\u001B[0m     logger\u001B[38;5;241m.\u001B[39minfo(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mpausing backend\u001B[39m\u001B[38;5;124m\"\u001B[39m)  \u001B[38;5;66;03m# type: ignore\u001B[39;00m\n",
      "\u001B[0;32m--> 419\u001B[0m     \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mbackend\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43minterface\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mpublish_pause\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n",
      "\n",
      "File \u001B[0;32m/opt/conda/lib/python3.10/site-packages/wandb/sdk/interface/interface.py:665\u001B[0m, in \u001B[0;36mInterfaceBase.publish_pause\u001B[0;34m(self)\u001B[0m\n",
      "\u001B[1;32m    663\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mpublish_pause\u001B[39m(\u001B[38;5;28mself\u001B[39m) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m:\n",
      "\u001B[1;32m    664\u001B[0m     pause \u001B[38;5;241m=\u001B[39m pb\u001B[38;5;241m.\u001B[39mPauseRequest()\n",
      "\u001B[0;32m--> 665\u001B[0m     \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_publish_pause\u001B[49m\u001B[43m(\u001B[49m\u001B[43mpause\u001B[49m\u001B[43m)\u001B[49m\n",
      "\n",
      "File \u001B[0;32m/opt/conda/lib/python3.10/site-packages/wandb/sdk/interface/interface_shared.py:340\u001B[0m, in \u001B[0;36mInterfaceShared._publish_pause\u001B[0;34m(self, pause)\u001B[0m\n",
      "\u001B[1;32m    338\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m_publish_pause\u001B[39m(\u001B[38;5;28mself\u001B[39m, pause: pb\u001B[38;5;241m.\u001B[39mPauseRequest) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m:\n",
      "\u001B[1;32m    339\u001B[0m     rec \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_make_request(pause\u001B[38;5;241m=\u001B[39mpause)\n",
      "\u001B[0;32m--> 340\u001B[0m     \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_publish\u001B[49m\u001B[43m(\u001B[49m\u001B[43mrec\u001B[49m\u001B[43m)\u001B[49m\n",
      "\n",
      "File \u001B[0;32m/opt/conda/lib/python3.10/site-packages/wandb/sdk/interface/interface_sock.py:51\u001B[0m, in \u001B[0;36mInterfaceSock._publish\u001B[0;34m(self, record, local)\u001B[0m\n",
      "\u001B[1;32m     49\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m_publish\u001B[39m(\u001B[38;5;28mself\u001B[39m, record: \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mpb.Record\u001B[39m\u001B[38;5;124m\"\u001B[39m, local: Optional[\u001B[38;5;28mbool\u001B[39m] \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m:\n",
      "\u001B[1;32m     50\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_assign(record)\n",
      "\u001B[0;32m---> 51\u001B[0m     \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_sock_client\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43msend_record_publish\u001B[49m\u001B[43m(\u001B[49m\u001B[43mrecord\u001B[49m\u001B[43m)\u001B[49m\n",
      "\n",
      "File \u001B[0;32m/opt/conda/lib/python3.10/site-packages/wandb/sdk/lib/sock_client.py:221\u001B[0m, in \u001B[0;36mSockClient.send_record_publish\u001B[0;34m(self, record)\u001B[0m\n",
      "\u001B[1;32m    219\u001B[0m server_req \u001B[38;5;241m=\u001B[39m spb\u001B[38;5;241m.\u001B[39mServerRequest()\n",
      "\u001B[1;32m    220\u001B[0m server_req\u001B[38;5;241m.\u001B[39mrecord_publish\u001B[38;5;241m.\u001B[39mCopyFrom(record)\n",
      "\u001B[0;32m--> 221\u001B[0m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43msend_server_request\u001B[49m\u001B[43m(\u001B[49m\u001B[43mserver_req\u001B[49m\u001B[43m)\u001B[49m\n",
      "\n",
      "File \u001B[0;32m/opt/conda/lib/python3.10/site-packages/wandb/sdk/lib/sock_client.py:155\u001B[0m, in \u001B[0;36mSockClient.send_server_request\u001B[0;34m(self, msg)\u001B[0m\n",
      "\u001B[1;32m    154\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21msend_server_request\u001B[39m(\u001B[38;5;28mself\u001B[39m, msg: Any) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m:\n",
      "\u001B[0;32m--> 155\u001B[0m     \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_send_message\u001B[49m\u001B[43m(\u001B[49m\u001B[43mmsg\u001B[49m\u001B[43m)\u001B[49m\n",
      "\n",
      "File \u001B[0;32m/opt/conda/lib/python3.10/site-packages/wandb/sdk/lib/sock_client.py:152\u001B[0m, in \u001B[0;36mSockClient._send_message\u001B[0;34m(self, msg)\u001B[0m\n",
      "\u001B[1;32m    150\u001B[0m header \u001B[38;5;241m=\u001B[39m struct\u001B[38;5;241m.\u001B[39mpack(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m<BI\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;28mord\u001B[39m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mW\u001B[39m\u001B[38;5;124m\"\u001B[39m), raw_size)\n",
      "\u001B[1;32m    151\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_lock:\n",
      "\u001B[0;32m--> 152\u001B[0m     \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_sendall_with_error_handle\u001B[49m\u001B[43m(\u001B[49m\u001B[43mheader\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m+\u001B[39;49m\u001B[43m \u001B[49m\u001B[43mdata\u001B[49m\u001B[43m)\u001B[49m\n",
      "\n",
      "File \u001B[0;32m/opt/conda/lib/python3.10/site-packages/wandb/sdk/lib/sock_client.py:130\u001B[0m, in \u001B[0;36mSockClient._sendall_with_error_handle\u001B[0;34m(self, data)\u001B[0m\n",
      "\u001B[1;32m    128\u001B[0m start_time \u001B[38;5;241m=\u001B[39m time\u001B[38;5;241m.\u001B[39mmonotonic()\n",
      "\u001B[1;32m    129\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n",
      "\u001B[0;32m--> 130\u001B[0m     sent \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_sock\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43msend\u001B[49m\u001B[43m(\u001B[49m\u001B[43mdata\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[1;32m    131\u001B[0m     \u001B[38;5;66;03m# sent equal to 0 indicates a closed socket\u001B[39;00m\n",
      "\u001B[1;32m    132\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m sent \u001B[38;5;241m==\u001B[39m \u001B[38;5;241m0\u001B[39m:\n",
      "\n",
      "\u001B[0;31mBrokenPipeError\u001B[0m: [Errno 32] Broken pipe"
     ]
    }
   ],
   "source": [
    "sweep_id = wandb.sweep(sweep_config, entity=\"cs22m045\", project=\"DL_ASSIGNMENT_3\")\n",
    "wandb.agent(sweep_id,run_wandb, count=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error in callback <function _WandbInit._resume_backend at 0x786e3559fd90> (for pre_run_cell):\n"
     ]
    },
    {
     "ename": "BrokenPipeError",
     "evalue": "[Errno 32] Broken pipe",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m\n",
      "\u001B[0;31mBrokenPipeError\u001B[0m                           Traceback (most recent call last)\n",
      "File \u001B[0;32m/opt/conda/lib/python3.10/site-packages/backcall/backcall.py:104\u001B[0m, in \u001B[0;36mcallback_prototype.<locals>.adapt.<locals>.adapted\u001B[0;34m(*args, **kwargs)\u001B[0m\n",
      "\u001B[1;32m    102\u001B[0m                 kwargs\u001B[38;5;241m.\u001B[39mpop(name)\n",
      "\u001B[1;32m    103\u001B[0m \u001B[38;5;66;03m#            print(args, kwargs, unmatched_pos, cut_positional, unmatched_kw)\u001B[39;00m\n",
      "\u001B[0;32m--> 104\u001B[0m             \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mcallback\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "\n",
      "File \u001B[0;32m/opt/conda/lib/python3.10/site-packages/wandb/sdk/wandb_init.py:424\u001B[0m, in \u001B[0;36m_WandbInit._resume_backend\u001B[0;34m(self)\u001B[0m\n",
      "\u001B[1;32m    422\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mbackend \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mbackend\u001B[38;5;241m.\u001B[39minterface \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n",
      "\u001B[1;32m    423\u001B[0m     logger\u001B[38;5;241m.\u001B[39minfo(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mresuming backend\u001B[39m\u001B[38;5;124m\"\u001B[39m)  \u001B[38;5;66;03m# type: ignore\u001B[39;00m\n",
      "\u001B[0;32m--> 424\u001B[0m     \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mbackend\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43minterface\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mpublish_resume\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n",
      "\n",
      "File \u001B[0;32m/opt/conda/lib/python3.10/site-packages/wandb/sdk/interface/interface.py:673\u001B[0m, in \u001B[0;36mInterfaceBase.publish_resume\u001B[0;34m(self)\u001B[0m\n",
      "\u001B[1;32m    671\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mpublish_resume\u001B[39m(\u001B[38;5;28mself\u001B[39m) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m:\n",
      "\u001B[1;32m    672\u001B[0m     resume \u001B[38;5;241m=\u001B[39m pb\u001B[38;5;241m.\u001B[39mResumeRequest()\n",
      "\u001B[0;32m--> 673\u001B[0m     \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_publish_resume\u001B[49m\u001B[43m(\u001B[49m\u001B[43mresume\u001B[49m\u001B[43m)\u001B[49m\n",
      "\n",
      "File \u001B[0;32m/opt/conda/lib/python3.10/site-packages/wandb/sdk/interface/interface_shared.py:344\u001B[0m, in \u001B[0;36mInterfaceShared._publish_resume\u001B[0;34m(self, resume)\u001B[0m\n",
      "\u001B[1;32m    342\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m_publish_resume\u001B[39m(\u001B[38;5;28mself\u001B[39m, resume: pb\u001B[38;5;241m.\u001B[39mResumeRequest) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m:\n",
      "\u001B[1;32m    343\u001B[0m     rec \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_make_request(resume\u001B[38;5;241m=\u001B[39mresume)\n",
      "\u001B[0;32m--> 344\u001B[0m     \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_publish\u001B[49m\u001B[43m(\u001B[49m\u001B[43mrec\u001B[49m\u001B[43m)\u001B[49m\n",
      "\n",
      "File \u001B[0;32m/opt/conda/lib/python3.10/site-packages/wandb/sdk/interface/interface_sock.py:51\u001B[0m, in \u001B[0;36mInterfaceSock._publish\u001B[0;34m(self, record, local)\u001B[0m\n",
      "\u001B[1;32m     49\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m_publish\u001B[39m(\u001B[38;5;28mself\u001B[39m, record: \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mpb.Record\u001B[39m\u001B[38;5;124m\"\u001B[39m, local: Optional[\u001B[38;5;28mbool\u001B[39m] \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m:\n",
      "\u001B[1;32m     50\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_assign(record)\n",
      "\u001B[0;32m---> 51\u001B[0m     \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_sock_client\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43msend_record_publish\u001B[49m\u001B[43m(\u001B[49m\u001B[43mrecord\u001B[49m\u001B[43m)\u001B[49m\n",
      "\n",
      "File \u001B[0;32m/opt/conda/lib/python3.10/site-packages/wandb/sdk/lib/sock_client.py:221\u001B[0m, in \u001B[0;36mSockClient.send_record_publish\u001B[0;34m(self, record)\u001B[0m\n",
      "\u001B[1;32m    219\u001B[0m server_req \u001B[38;5;241m=\u001B[39m spb\u001B[38;5;241m.\u001B[39mServerRequest()\n",
      "\u001B[1;32m    220\u001B[0m server_req\u001B[38;5;241m.\u001B[39mrecord_publish\u001B[38;5;241m.\u001B[39mCopyFrom(record)\n",
      "\u001B[0;32m--> 221\u001B[0m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43msend_server_request\u001B[49m\u001B[43m(\u001B[49m\u001B[43mserver_req\u001B[49m\u001B[43m)\u001B[49m\n",
      "\n",
      "File \u001B[0;32m/opt/conda/lib/python3.10/site-packages/wandb/sdk/lib/sock_client.py:155\u001B[0m, in \u001B[0;36mSockClient.send_server_request\u001B[0;34m(self, msg)\u001B[0m\n",
      "\u001B[1;32m    154\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21msend_server_request\u001B[39m(\u001B[38;5;28mself\u001B[39m, msg: Any) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m:\n",
      "\u001B[0;32m--> 155\u001B[0m     \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_send_message\u001B[49m\u001B[43m(\u001B[49m\u001B[43mmsg\u001B[49m\u001B[43m)\u001B[49m\n",
      "\n",
      "File \u001B[0;32m/opt/conda/lib/python3.10/site-packages/wandb/sdk/lib/sock_client.py:152\u001B[0m, in \u001B[0;36mSockClient._send_message\u001B[0;34m(self, msg)\u001B[0m\n",
      "\u001B[1;32m    150\u001B[0m header \u001B[38;5;241m=\u001B[39m struct\u001B[38;5;241m.\u001B[39mpack(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m<BI\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;28mord\u001B[39m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mW\u001B[39m\u001B[38;5;124m\"\u001B[39m), raw_size)\n",
      "\u001B[1;32m    151\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_lock:\n",
      "\u001B[0;32m--> 152\u001B[0m     \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_sendall_with_error_handle\u001B[49m\u001B[43m(\u001B[49m\u001B[43mheader\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m+\u001B[39;49m\u001B[43m \u001B[49m\u001B[43mdata\u001B[49m\u001B[43m)\u001B[49m\n",
      "\n",
      "File \u001B[0;32m/opt/conda/lib/python3.10/site-packages/wandb/sdk/lib/sock_client.py:130\u001B[0m, in \u001B[0;36mSockClient._sendall_with_error_handle\u001B[0;34m(self, data)\u001B[0m\n",
      "\u001B[1;32m    128\u001B[0m start_time \u001B[38;5;241m=\u001B[39m time\u001B[38;5;241m.\u001B[39mmonotonic()\n",
      "\u001B[1;32m    129\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n",
      "\u001B[0;32m--> 130\u001B[0m     sent \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_sock\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43msend\u001B[49m\u001B[43m(\u001B[49m\u001B[43mdata\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[1;32m    131\u001B[0m     \u001B[38;5;66;03m# sent equal to 0 indicates a closed socket\u001B[39;00m\n",
      "\u001B[1;32m    132\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m sent \u001B[38;5;241m==\u001B[39m \u001B[38;5;241m0\u001B[39m:\n",
      "\n",
      "\u001B[0;31mBrokenPipeError\u001B[0m: [Errno 32] Broken pipe"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error in callback <function _WandbInit._pause_backend at 0x786e3559fe20> (for post_run_cell):\n"
     ]
    },
    {
     "ename": "BrokenPipeError",
     "evalue": "[Errno 32] Broken pipe",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m\n",
      "\u001B[0;31mBrokenPipeError\u001B[0m                           Traceback (most recent call last)\n",
      "File \u001B[0;32m/opt/conda/lib/python3.10/site-packages/backcall/backcall.py:104\u001B[0m, in \u001B[0;36mcallback_prototype.<locals>.adapt.<locals>.adapted\u001B[0;34m(*args, **kwargs)\u001B[0m\n",
      "\u001B[1;32m    102\u001B[0m                 kwargs\u001B[38;5;241m.\u001B[39mpop(name)\n",
      "\u001B[1;32m    103\u001B[0m \u001B[38;5;66;03m#            print(args, kwargs, unmatched_pos, cut_positional, unmatched_kw)\u001B[39;00m\n",
      "\u001B[0;32m--> 104\u001B[0m             \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mcallback\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "\n",
      "File \u001B[0;32m/opt/conda/lib/python3.10/site-packages/wandb/sdk/wandb_init.py:419\u001B[0m, in \u001B[0;36m_WandbInit._pause_backend\u001B[0;34m(self)\u001B[0m\n",
      "\u001B[1;32m    417\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mbackend\u001B[38;5;241m.\u001B[39minterface \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n",
      "\u001B[1;32m    418\u001B[0m     logger\u001B[38;5;241m.\u001B[39minfo(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mpausing backend\u001B[39m\u001B[38;5;124m\"\u001B[39m)  \u001B[38;5;66;03m# type: ignore\u001B[39;00m\n",
      "\u001B[0;32m--> 419\u001B[0m     \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mbackend\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43minterface\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mpublish_pause\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n",
      "\n",
      "File \u001B[0;32m/opt/conda/lib/python3.10/site-packages/wandb/sdk/interface/interface.py:665\u001B[0m, in \u001B[0;36mInterfaceBase.publish_pause\u001B[0;34m(self)\u001B[0m\n",
      "\u001B[1;32m    663\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mpublish_pause\u001B[39m(\u001B[38;5;28mself\u001B[39m) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m:\n",
      "\u001B[1;32m    664\u001B[0m     pause \u001B[38;5;241m=\u001B[39m pb\u001B[38;5;241m.\u001B[39mPauseRequest()\n",
      "\u001B[0;32m--> 665\u001B[0m     \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_publish_pause\u001B[49m\u001B[43m(\u001B[49m\u001B[43mpause\u001B[49m\u001B[43m)\u001B[49m\n",
      "\n",
      "File \u001B[0;32m/opt/conda/lib/python3.10/site-packages/wandb/sdk/interface/interface_shared.py:340\u001B[0m, in \u001B[0;36mInterfaceShared._publish_pause\u001B[0;34m(self, pause)\u001B[0m\n",
      "\u001B[1;32m    338\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m_publish_pause\u001B[39m(\u001B[38;5;28mself\u001B[39m, pause: pb\u001B[38;5;241m.\u001B[39mPauseRequest) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m:\n",
      "\u001B[1;32m    339\u001B[0m     rec \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_make_request(pause\u001B[38;5;241m=\u001B[39mpause)\n",
      "\u001B[0;32m--> 340\u001B[0m     \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_publish\u001B[49m\u001B[43m(\u001B[49m\u001B[43mrec\u001B[49m\u001B[43m)\u001B[49m\n",
      "\n",
      "File \u001B[0;32m/opt/conda/lib/python3.10/site-packages/wandb/sdk/interface/interface_sock.py:51\u001B[0m, in \u001B[0;36mInterfaceSock._publish\u001B[0;34m(self, record, local)\u001B[0m\n",
      "\u001B[1;32m     49\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m_publish\u001B[39m(\u001B[38;5;28mself\u001B[39m, record: \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mpb.Record\u001B[39m\u001B[38;5;124m\"\u001B[39m, local: Optional[\u001B[38;5;28mbool\u001B[39m] \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m:\n",
      "\u001B[1;32m     50\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_assign(record)\n",
      "\u001B[0;32m---> 51\u001B[0m     \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_sock_client\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43msend_record_publish\u001B[49m\u001B[43m(\u001B[49m\u001B[43mrecord\u001B[49m\u001B[43m)\u001B[49m\n",
      "\n",
      "File \u001B[0;32m/opt/conda/lib/python3.10/site-packages/wandb/sdk/lib/sock_client.py:221\u001B[0m, in \u001B[0;36mSockClient.send_record_publish\u001B[0;34m(self, record)\u001B[0m\n",
      "\u001B[1;32m    219\u001B[0m server_req \u001B[38;5;241m=\u001B[39m spb\u001B[38;5;241m.\u001B[39mServerRequest()\n",
      "\u001B[1;32m    220\u001B[0m server_req\u001B[38;5;241m.\u001B[39mrecord_publish\u001B[38;5;241m.\u001B[39mCopyFrom(record)\n",
      "\u001B[0;32m--> 221\u001B[0m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43msend_server_request\u001B[49m\u001B[43m(\u001B[49m\u001B[43mserver_req\u001B[49m\u001B[43m)\u001B[49m\n",
      "\n",
      "File \u001B[0;32m/opt/conda/lib/python3.10/site-packages/wandb/sdk/lib/sock_client.py:155\u001B[0m, in \u001B[0;36mSockClient.send_server_request\u001B[0;34m(self, msg)\u001B[0m\n",
      "\u001B[1;32m    154\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21msend_server_request\u001B[39m(\u001B[38;5;28mself\u001B[39m, msg: Any) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m:\n",
      "\u001B[0;32m--> 155\u001B[0m     \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_send_message\u001B[49m\u001B[43m(\u001B[49m\u001B[43mmsg\u001B[49m\u001B[43m)\u001B[49m\n",
      "\n",
      "File \u001B[0;32m/opt/conda/lib/python3.10/site-packages/wandb/sdk/lib/sock_client.py:152\u001B[0m, in \u001B[0;36mSockClient._send_message\u001B[0;34m(self, msg)\u001B[0m\n",
      "\u001B[1;32m    150\u001B[0m header \u001B[38;5;241m=\u001B[39m struct\u001B[38;5;241m.\u001B[39mpack(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m<BI\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;28mord\u001B[39m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mW\u001B[39m\u001B[38;5;124m\"\u001B[39m), raw_size)\n",
      "\u001B[1;32m    151\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_lock:\n",
      "\u001B[0;32m--> 152\u001B[0m     \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_sendall_with_error_handle\u001B[49m\u001B[43m(\u001B[49m\u001B[43mheader\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m+\u001B[39;49m\u001B[43m \u001B[49m\u001B[43mdata\u001B[49m\u001B[43m)\u001B[49m\n",
      "\n",
      "File \u001B[0;32m/opt/conda/lib/python3.10/site-packages/wandb/sdk/lib/sock_client.py:130\u001B[0m, in \u001B[0;36mSockClient._sendall_with_error_handle\u001B[0;34m(self, data)\u001B[0m\n",
      "\u001B[1;32m    128\u001B[0m start_time \u001B[38;5;241m=\u001B[39m time\u001B[38;5;241m.\u001B[39mmonotonic()\n",
      "\u001B[1;32m    129\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n",
      "\u001B[0;32m--> 130\u001B[0m     sent \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_sock\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43msend\u001B[49m\u001B[43m(\u001B[49m\u001B[43mdata\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[1;32m    131\u001B[0m     \u001B[38;5;66;03m# sent equal to 0 indicates a closed socket\u001B[39;00m\n",
      "\u001B[1;32m    132\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m sent \u001B[38;5;241m==\u001B[39m \u001B[38;5;241m0\u001B[39m:\n",
      "\n",
      "\u001B[0;31mBrokenPipeError\u001B[0m: [Errno 32] Broken pipe"
     ]
    }
   ],
   "source": [
    "\n",
    "# N_EPOCHS = 1\n",
    "# CLIP = 1\n",
    "# INPUT_DIM = input_vocab_size\n",
    "# OUTPUT_DIM = output_vocab_size\n",
    "# ENC_EMB_DIM = 128\n",
    "# DEC_EMB_DIM = 128\n",
    "# HIDDEN_SIZE = 256\n",
    "# num_layers = 1\n",
    "# ENC_DROPOUT = 0.5\n",
    "# DEC_DROPOUT = 0.5\n",
    "# TEACHER_FORCING = 0.5\n",
    "# BI_DIRECTION = True\n",
    "# CELL_TYPE = 'LSTM'\n",
    "# pred_src = \"$bindya|\"\n",
    "# pred_trg = '$बिन्द्या|'\n",
    "\n",
    "# enc = Encoder(input_size=INPUT_DIM, embedding_size=ENC_EMB_DIM, hidden_size=HIDDEN_SIZE, num_layers=num_layers, dropout=ENC_DROPOUT, cell_type=CELL_TYPE, bidirectional=BI_DIRECTION)\n",
    "# dec = Decoder(output_dim=OUTPUT_DIM, emb_dim=DEC_EMB_DIM, hidden_size=HIDDEN_SIZE, num_layers=num_layers, dropout=DEC_DROPOUT, cell_type=CELL_TYPE, bidirectional=BI_DIRECTION)\n",
    "\n",
    "# model = Seq2Seq(enc, dec, device, teacher_forcing_ratio=TEACHER_FORCING).to(device)\n",
    "# def init_weights(m):\n",
    "#     for name, param in m.named_parameters():\n",
    "#         nn.init.uniform_(param.data, -0.08, 0.08)\n",
    "\n",
    "\n",
    "# model.apply(init_weights)\n",
    "# optimizer = optim.Adam(model.parameters())\n",
    "# criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# best_valid_loss = float('inf')\n",
    "# gbar = tqdm(range(1, N_EPOCHS + 1),position=1,leave=True, desc='Epochs', total=N_EPOCHS)\n",
    "# for epoch in gbar:\n",
    "#     train_loss, train_accuracy = train(model, train_dataloader, optimizer, criterion, CLIP)\n",
    "#     valid_loss, valid_accuracy = evaluate(model, valid_dataloader, criterion)\n",
    "#     gbar.set_postfix(train_loss=train_loss, train_acc=train_accuracy, val_loss=valid_loss, val_acc=valid_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
