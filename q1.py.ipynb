{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "is_executing": true
   },
   "outputs": [],
   "source": [
    "import numpy as np  # linear algebra\n",
    "import pandas as pd  # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import random\n",
    "import os\n",
    "import numpy as np  # linear algebra\n",
    "import pandas as pd  # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.autograd import Variable\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "import pickle\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 319,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Executing on cpu\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Executing on \" + (\"cuda:0\" if torch.cuda.is_available() else \"cpu\"))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-02T10:48:30.593802200Z",
     "start_time": "2023-05-02T10:48:29.826979100Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 320,
   "outputs": [],
   "source": [
    "df_train = pd.read_csv(\"Data/hin/hin_train.csv\")\n",
    "df_test = pd.read_csv('Data/hin/hin_test.csv')\n",
    "df_valid = pd.read_csv('Data/hin/hin_valid.csv')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-02T10:48:30.939894200Z",
     "start_time": "2023-05-02T10:48:29.837819400Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 321,
   "outputs": [],
   "source": [
    "PAD_CHAR = '_'\n",
    "EOW_CHAR = '|'\n",
    "SOW_CHAR = '$'\n",
    "BATCH_SIZE = 1"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-02T10:48:30.971774700Z",
     "start_time": "2023-05-02T10:48:29.954555Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 322,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'_': 0, '|': 1, '$': 2, 'a': 3, 'b': 4, 'c': 5, 'd': 6, 'e': 7, 'f': 8, 'g': 9, 'h': 10, 'i': 11, 'j': 12, 'k': 13, 'l': 14, 'm': 15, 'n': 16, 'o': 17, 'p': 18, 'q': 19, 'r': 20, 's': 21, 't': 22, 'u': 23, 'v': 24, 'w': 25, 'x': 26, 'y': 27, 'z': 28}\n"
     ]
    }
   ],
   "source": [
    "eng_alphabets = [chr(alpha) for alpha in range(ord('a'), ord('z') + 1)]\n",
    "# eng_alpha2index = {pad_char:0}\n",
    "in_dict = {PAD_CHAR: 0, EOW_CHAR: 1, SOW_CHAR: 2}\n",
    "for index, alpha in enumerate(eng_alphabets):\n",
    "\tin_dict[alpha] = index + 3\n",
    "print(in_dict)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-02T10:48:30.971774700Z",
     "start_time": "2023-05-02T10:48:29.955068Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 323,
   "outputs": [],
   "source": [
    "hindi_alphabets = [chr(alpha) for alpha in range(2304, 2432)]\n",
    "hindi_alphabet_size = len(hindi_alphabets)\n",
    "out_dict = {PAD_CHAR: 0, EOW_CHAR: 1, SOW_CHAR: 2}\n",
    "for index, alpha in enumerate(hindi_alphabets):\n",
    "\tout_dict[alpha] = index + 3"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-02T10:48:30.971774700Z",
     "start_time": "2023-05-02T10:48:29.971679300Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 324,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'_': 0, '|': 1, '$': 2, 'ऀ': 3, 'ँ': 4, 'ं': 5, 'ः': 6, 'ऄ': 7, 'अ': 8, 'आ': 9, 'इ': 10, 'ई': 11, 'उ': 12, 'ऊ': 13, 'ऋ': 14, 'ऌ': 15, 'ऍ': 16, 'ऎ': 17, 'ए': 18, 'ऐ': 19, 'ऑ': 20, 'ऒ': 21, 'ओ': 22, 'औ': 23, 'क': 24, 'ख': 25, 'ग': 26, 'घ': 27, 'ङ': 28, 'च': 29, 'छ': 30, 'ज': 31, 'झ': 32, 'ञ': 33, 'ट': 34, 'ठ': 35, 'ड': 36, 'ढ': 37, 'ण': 38, 'त': 39, 'थ': 40, 'द': 41, 'ध': 42, 'न': 43, 'ऩ': 44, 'प': 45, 'फ': 46, 'ब': 47, 'भ': 48, 'म': 49, 'य': 50, 'र': 51, 'ऱ': 52, 'ल': 53, 'ळ': 54, 'ऴ': 55, 'व': 56, 'श': 57, 'ष': 58, 'स': 59, 'ह': 60, 'ऺ': 61, 'ऻ': 62, '़': 63, 'ऽ': 64, 'ा': 65, 'ि': 66, 'ी': 67, 'ु': 68, 'ू': 69, 'ृ': 70, 'ॄ': 71, 'ॅ': 72, 'ॆ': 73, 'े': 74, 'ै': 75, 'ॉ': 76, 'ॊ': 77, 'ो': 78, 'ौ': 79, '्': 80, 'ॎ': 81, 'ॏ': 82, 'ॐ': 83, '॑': 84, '॒': 85, '॓': 86, '॔': 87, 'ॕ': 88, 'ॖ': 89, 'ॗ': 90, 'क़': 91, 'ख़': 92, 'ग़': 93, 'ज़': 94, 'ड़': 95, 'ढ़': 96, 'फ़': 97, 'य़': 98, 'ॠ': 99, 'ॡ': 100, 'ॢ': 101, 'ॣ': 102, '।': 103, '॥': 104, '०': 105, '१': 106, '२': 107, '३': 108, '४': 109, '५': 110, '६': 111, '७': 112, '८': 113, '९': 114, '॰': 115, 'ॱ': 116, 'ॲ': 117, 'ॳ': 118, 'ॴ': 119, 'ॵ': 120, 'ॶ': 121, 'ॷ': 122, 'ॸ': 123, 'ॹ': 124, 'ॺ': 125, 'ॻ': 126, 'ॼ': 127, 'ॽ': 128, 'ॾ': 129, 'ॿ': 130}\n",
      "131\n"
     ]
    }
   ],
   "source": [
    "print(out_dict)\n",
    "print(len(out_dict))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-02T10:48:30.971774700Z",
     "start_time": "2023-05-02T10:48:29.986469300Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 325,
   "outputs": [],
   "source": [
    "if df_train.iloc[0][0][0] != SOW_CHAR:\n",
    "\tdf_train = df_train.iloc[:, ].apply(lambda x: SOW_CHAR + x + EOW_CHAR)\n",
    "\tdf_test = df_test.iloc[:, ].apply(lambda x: SOW_CHAR + x + EOW_CHAR)\n",
    "\tdf_valid = df_valid.iloc[:, ].apply(lambda x: SOW_CHAR + x + EOW_CHAR)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-02T10:48:30.971774700Z",
     "start_time": "2023-05-02T10:48:29.996980200Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 326,
   "outputs": [],
   "source": [
    "df_train = df_train.set_axis(['X', 'Y'], axis=1)\n",
    "df_valid = df_valid.set_axis(['X', 'Y'], axis=1)\n",
    "df_test = df_test.set_axis(['X', 'Y'], axis=1)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-02T10:48:30.971774700Z",
     "start_time": "2023-05-02T10:48:30.072733500Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 327,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   X            Y\n",
      "0          $bindhya|   $बिन्द्या|\n",
      "1        $kirankant|   $किरणकांत|\n",
      "2      $yagyopaveet|  $यज्ञोपवीत|\n",
      "3          $ratania|    $रटानिया|\n",
      "4       $vaganyache|  $वागण्याचे|\n",
      "...              ...          ...\n",
      "51194        $toned|       $टोंड|\n",
      "51195   $mutanaazaa|   $मुतनाज़ा|\n",
      "51196    $asahmaton|    $असहमतों|\n",
      "51197    $sulgaayin|   $सुलगायीं|\n",
      "51198  $anchuthengu|  $अंचुतेंगु|\n",
      "\n",
      "[51199 rows x 2 columns]\n",
      "                   X              Y\n",
      "0        $sikhaaega|      $सिखाएगा|\n",
      "1            $learn|         $लर्न|\n",
      "2         $twitters|     $ट्विटर्स|\n",
      "3      $tirunelveli|  $तिरुनेलवेली|\n",
      "4     $independence|  $इंडिपेंडेंस|\n",
      "...              ...            ...\n",
      "4090       $saflata|       $सफ़लता|\n",
      "4091        $shbana|        $शबाना|\n",
      "4092  $khaatootolaa|     $खातूटोला|\n",
      "4093    $shivastava|     $शिवास्तव|\n",
      "4094  $preranapuree|  $प्रेरणापुरी|\n",
      "\n",
      "[4095 rows x 2 columns]\n",
      "                  X              Y\n",
      "0           $bajai|         $बजाई|\n",
      "1       $sanghthan|        $संघठन|\n",
      "2         $haiwaan|        $हैवान|\n",
      "3         $nilgiri|      $नीलगिरि|\n",
      "4       $drutgrami|  $द्रुतग्रामी|\n",
      "...             ...            ...\n",
      "4090     $paranshu|       $परांशु|\n",
      "4091    $romanchit|     $रोमांचित|\n",
      "4092  $ekamreshwar|  $एकाम्रेश्वर|\n",
      "4093    $bluetooth|    $ब्ल्यूटूथ|\n",
      "4094    $govindram|   $गोविंद्राम|\n",
      "\n",
      "[4095 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "print(df_train)\n",
    "print(df_test)\n",
    "print(df_valid)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-02T10:48:30.971774700Z",
     "start_time": "2023-05-02T10:48:30.099959100Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 328,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max input length 28\n",
      "max output length 22\n",
      "max_length 28\n"
     ]
    }
   ],
   "source": [
    "max_input_length = max(df_train.iloc[:, 0].apply(lambda x: len(x)).max(),\n",
    "\t\t\t\t\t   df_test.iloc[:, 0].apply(lambda x: len(x)).max(),\n",
    "\t\t\t\t\t   df_valid.iloc[:, 0].apply(lambda x: len(x)).max())\n",
    "\n",
    "max_output_length = max(df_train.iloc[:, 1].apply(lambda x: len(x)).max(),\n",
    "\t\t\t\t\t\tdf_test.iloc[:, 1].apply(lambda x: len(x)).max(),\n",
    "\t\t\t\t\t\tdf_valid.iloc[:, 1].apply(lambda x: len(x)).max())\n",
    "\n",
    "print(\"max input length\", max_input_length)\n",
    "print(\"max output length\", max_output_length)\n",
    "MAX_LENGTH = max(max_input_length, max_output_length)\n",
    "print(\"max_length\", MAX_LENGTH)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-02T10:48:30.971774700Z",
     "start_time": "2023-05-02T10:48:30.120390600Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 329,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input Character max 29\n",
      "output Character size 131\n"
     ]
    }
   ],
   "source": [
    "input_vocab_size = len(in_dict)\n",
    "output_vocab_size = len(out_dict)\n",
    "print(\"Input Character max\", input_vocab_size)\n",
    "print(\"output Character size\", output_vocab_size)\n",
    "\n",
    "train = df_train.values.tolist()\n",
    "valid = df_valid.values.tolist()\n",
    "test = df_test.values.tolist()\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-02T10:48:30.971774700Z",
     "start_time": "2023-05-02T10:48:30.276950100Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 330,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input Character max 29\n",
      "output Character size 131\n"
     ]
    }
   ],
   "source": [
    "input_vocab_size = len(in_dict)\n",
    "output_vocab_size = len(out_dict)\n",
    "print(\"Input Character max\", input_vocab_size)\n",
    "print(\"output Character size\", output_vocab_size)\n",
    "\n",
    "train = df_train.values.tolist()\n",
    "valid = df_valid.values.tolist()\n",
    "test = df_test.values.tolist()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-02T10:48:30.971774700Z",
     "start_time": "2023-05-02T10:48:30.305546700Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 331,
   "outputs": [],
   "source": [
    "def inputToTensor(line):\n",
    "\tprint([in_dict[x] for x in line])\n",
    "\ttensor = torch.tensor(data=([in_dict[x] for x in line]), dtype=torch.long)\n",
    "\treturn tensor\n",
    "\n",
    "\n",
    "def charToTensor(char, dic=in_dict):\n",
    "\ttensor = torch.zeros(len(dic))\n",
    "\ttensor[dic[char]] = 1\n",
    "\treturn tensor\n",
    "\n",
    "\n",
    "def outToTensor(word):\n",
    "\ttensor = torch.tensor([out_dict[x] for x in word])\n",
    "\treturn tensor\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-02T10:48:30.971774700Z",
     "start_time": "2023-05-02T10:48:30.466422400Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 332,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2, 4, 11, 16, 6, 10, 27, 3, 1]\n",
      "tensor([ 2,  4, 11, 16,  6, 10, 27,  3,  1])\n"
     ]
    }
   ],
   "source": [
    "print(inputToTensor(train[0][0]))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-02T10:48:30.971774700Z",
     "start_time": "2023-05-02T10:48:30.475508Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 333,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "$किरणकांत|\n"
     ]
    }
   ],
   "source": [
    "print(train[1][1])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-02T10:48:30.971774700Z",
     "start_time": "2023-05-02T10:48:30.492838300Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 334,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2, 4, 11, 16, 6, 10, 27, 3, 1]\n"
     ]
    },
    {
     "data": {
      "text/plain": "tensor([ 2,  4, 11, 16,  6, 10, 27,  3,  1])"
     },
     "execution_count": 334,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputToTensor(\"$bindhya|\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-02T10:48:30.971774700Z",
     "start_time": "2023-05-02T10:48:30.502550500Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 335,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'_': 0, '|': 1, '$': 2, 'a': 3, 'b': 4, 'c': 5, 'd': 6, 'e': 7, 'f': 8, 'g': 9, 'h': 10, 'i': 11, 'j': 12, 'k': 13, 'l': 14, 'm': 15, 'n': 16, 'o': 17, 'p': 18, 'q': 19, 'r': 20, 's': 21, 't': 22, 'u': 23, 'v': 24, 'w': 25, 'x': 26, 'y': 27, 'z': 28}\n"
     ]
    }
   ],
   "source": [
    "print(in_dict)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-02T10:48:30.971774700Z",
     "start_time": "2023-05-02T10:48:30.522039900Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 336,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10, 7, 14, 14, 17]\n",
      "tensor([10,  7, 14, 14, 17])\n"
     ]
    }
   ],
   "source": [
    "print(inputToTensor(\"hello\"))\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-02T10:48:30.971774700Z",
     "start_time": "2023-05-02T10:48:30.531380300Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 337,
   "outputs": [],
   "source": [
    "def generate_batch(data_batch):\n",
    "\t#     print(data_batch)\n",
    "\ttensor_data = [inputToTensor(x[0].ljust(max_input_length, PAD_CHAR)) for x in data_batch]\n",
    "\ttensor_target = [outToTensor(x[1].ljust(max_output_length, PAD_CHAR)) for x in data_batch]\n",
    "\tpadded_input_batch = torch.nn.utils.rnn.pad_sequence(tensor_data, batch_first=True, padding_value=1)\n",
    "\tpadded_output_batch = torch.nn.utils.rnn.pad_sequence(tensor_target, batch_first=True, padding_value=1)\n",
    "\t#     print(tensor_data)\n",
    "\t#     print(padded_input_batch.shape)\n",
    "\t#     print(padded_output_batch.shape)\n",
    "\treturn padded_input_batch, padded_output_batch"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-02T10:48:30.971774700Z",
     "start_time": "2023-05-02T10:48:30.543857800Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 338,
   "outputs": [],
   "source": [
    "train_dataloader = DataLoader(train, batch_size=BATCH_SIZE, shuffle=True, collate_fn=generate_batch)\n",
    "test_dataloader = DataLoader(test, batch_size=BATCH_SIZE, shuffle=False, collate_fn=generate_batch)\n",
    "valid_dataloader = DataLoader(test, batch_size=BATCH_SIZE, shuffle=False, collate_fn=generate_batch, )\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-02T10:48:30.971774700Z",
     "start_time": "2023-05-02T10:48:30.556767600Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 339,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2, 13, 23, 12, 3, 15, 4, 10, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "tensor([[ 2, 13, 23, 12,  3, 15,  4, 10,  1,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
      "          0,  0,  0,  0,  0,  0,  0,  0,  0,  0]])\n",
      "tensor([[ 2, 24, 68, 31,  5, 48,  1,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
      "          0,  0,  0,  0]])\n",
      "torch.Size([1, 28])\n",
      "torch.Size([1, 22])\n"
     ]
    }
   ],
   "source": [
    "for data,target in train_dataloader:\n",
    "    print(data)\n",
    "    print(target)\n",
    "    print(data.shape)\n",
    "    print(target.shape)\n",
    "    if True:\n",
    "        break"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-02T10:48:30.971774700Z",
     "start_time": "2023-05-02T10:48:30.564666500Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 340,
   "outputs": [],
   "source": [
    "class Encoder(nn.Module):\n",
    "    def __init__(self, input_dim, emb_dim, hid_dim, n_layers, dropout):\n",
    "        super().__init__()\n",
    "\n",
    "        self.hid_dim = hid_dim\n",
    "        self.n_layers = n_layers\n",
    "\n",
    "        self.embedding = nn.Embedding(input_dim, emb_dim)\n",
    "\n",
    "        self.rnn = nn.LSTM(emb_dim, hid_dim, n_layers, dropout = dropout)\n",
    "\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self, src):\n",
    "        #src = [src len, batch size]\n",
    "        print(\"encoder forward prop\")\n",
    "\n",
    "        embedded = self.dropout(self.embedding(src))\n",
    "        embedded = embedded.permute(1,0,2)\n",
    "        print(\"encoder embedded shape\", embedded.shape)\n",
    "        #embedded = [src len, batch size, emb dim]\n",
    "        outputs, (hidden, cell) = self.rnn(embedded)\n",
    "        print(\"encoder hidden dimension\", hidden.shape)\n",
    "        print(\"encoder output dimension\", outputs.shape)\n",
    "        print(\"encoder cell dimension\", cell.shape)\n",
    "        #outputs = [src len, batch size, hid dim * n directions]\n",
    "        #hidden = [n layers * n directions, batch size, hid dim]\n",
    "        #cell = [n layers * n directions, batch size, hid dim]\n",
    "        #outputs are always from the top hidden layer\n",
    "        return hidden, cell"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-02T10:48:30.971774700Z",
     "start_time": "2023-05-02T10:48:30.578101200Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 341,
   "outputs": [],
   "source": [
    "class Decoder(nn.Module):\n",
    "    def __init__(self, output_dim, emb_dim, hid_dim, n_layers, dropout):\n",
    "        super().__init__()\n",
    "\n",
    "        self.output_dim = output_dim\n",
    "        self.hid_dim = hid_dim\n",
    "        self.n_layers = n_layers\n",
    "\n",
    "        self.embedding = nn.Embedding(output_dim, emb_dim)\n",
    "\n",
    "        self.rnn = nn.LSTM(emb_dim, hid_dim, n_layers, dropout = dropout)\n",
    "\n",
    "        self.fc_out = nn.Linear(hid_dim, output_dim)\n",
    "\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self, input, hidden, cell):\n",
    "\n",
    "        #input = [batch size]\n",
    "        #hidden = [n layers * n directions, batch size, hid dim]\n",
    "        #cell = [n layers * n directions, batch size, hid dim]\n",
    "\n",
    "        #n directions in the decoder will both always be 1, therefore:\n",
    "        #hidden = [n layers, batch size, hid dim]\n",
    "        #context = [n layers, batch size, hid dim]\n",
    "        print(\"decoder hidden shape\", hidden.shape)\n",
    "        print(\"decoder context shape\", cell.shape)\n",
    "        input = input.unsqueeze(0)\n",
    "\n",
    "        #input = [1, batch size]\n",
    "\n",
    "        embedded = self.dropout(self.embedding(input))\n",
    "        print(\"decoder embedded shape\", embedded.shape)\n",
    "        #embedded = [1, batch size, emb dim]\n",
    "\n",
    "        output, (hidden, cell) = self.rnn(embedded, (hidden, cell))\n",
    "        print(\"decoder output shape\", output.shape)\n",
    "        print(\"decoder hidden shape\", hidden.shape)\n",
    "        print(\"decoder context shape\", cell.shape)\n",
    "        #output = [seq len, batch size, hid dim * n directions]\n",
    "        #hidden = [n layers * n directions, batch size, hid dim]\n",
    "        #cell = [n layers * n directions, batch size, hid dim]\n",
    "\n",
    "        #seq len and n directions will always be 1 in the decoder, therefore:\n",
    "        #output = [1, batch size, hid dim]\n",
    "        #hidden = [n layers, batch size, hid dim]\n",
    "        #cell = [n layers, batch size, hid dim]\n",
    "\n",
    "        prediction = self.fc_out(output.squeeze(0))\n",
    "\n",
    "        #prediction = [batch size, output dim]\n",
    "        print(\"decoder prediction shape\", prediction.shape)\n",
    "        return prediction, hidden, cell"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-02T10:48:30.971774700Z",
     "start_time": "2023-05-02T10:48:30.615029700Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 342,
   "outputs": [],
   "source": [
    "class Seq2Seq(nn.Module):\n",
    "    def __init__(self, encoder, decoder, device):\n",
    "        super().__init__()\n",
    "\n",
    "        self.encoder = encoder\n",
    "        self.decoder = decoder\n",
    "        self.device = device\n",
    "\n",
    "        assert encoder.hid_dim == decoder.hid_dim, \\\n",
    "            \"Hidden dimensions of encoder and decoder must be equal!\"\n",
    "        assert encoder.n_layers == decoder.n_layers, \\\n",
    "            \"Encoder and decoder must have equal number of layers!\"\n",
    "\n",
    "    def forward(self, src, trg, teacher_forcing_ratio = 0.5):\n",
    "\n",
    "        #src = [src len, batch size]\n",
    "        #trg = [trg len, batch size]\n",
    "        #teacher_forcing_ratio is probability to use teacher forcing\n",
    "        #e.g. if teacher_forcing_ratio is 0.75 we use ground-truth inputs 75% of the time\n",
    "\n",
    "        batch_size = trg.shape[1]\n",
    "        trg_len = trg.shape[0]\n",
    "        trg_vocab_size = self.decoder.output_dim\n",
    "\n",
    "        #tensor to store decoder outputs\n",
    "        outputs = torch.zeros(trg_len, batch_size, trg_vocab_size).to(self.device)\n",
    "\n",
    "        #last hidden state of the encoder is used as the initial hidden state of the decoder\n",
    "        hidden, cell = self.encoder(src)\n",
    "        print(\"seq2seq hidden shape\", hidden.shape)\n",
    "        print(\"seq2seq cell shape\", cell.shape)\n",
    "        #first input to the decoder is the <sos> tokens\n",
    "        input = trg[0,:]\n",
    "\n",
    "        for t in range(1, trg_len):\n",
    "\t\t\t            #insert input token embedding, previous hidden and previous cell states\n",
    "            #receive output tensor (predictions) and new hidden and cell states\n",
    "            output, hidden, cell = self.decoder(input, hidden, cell)\n",
    "\n",
    "            #place predictions in a tensor holding predictions for each token\n",
    "            outputs[t] = output\n",
    "\n",
    "            #decide if we are going to use teacher forcing or not\n",
    "            teacher_force = random.random() < teacher_forcing_ratio\n",
    "\n",
    "            #get the highest predicted token from our predictions\n",
    "            top1 = output.argmax(1)\n",
    "\n",
    "            #if teacher forcing, use actual next token as next input\n",
    "            #if not, use predicted token\n",
    "            input = trg[t] if teacher_force else top1\n",
    "\n",
    "        return outputs"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-02T10:48:31.602181400Z",
     "start_time": "2023-05-02T10:48:30.626221100Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 343,
   "outputs": [],
   "source": [
    "INPUT_DIM = input_vocab_size\n",
    "OUTPUT_DIM = output_vocab_size\n",
    "ENC_EMB_DIM = 256\n",
    "DEC_EMB_DIM = 256\n",
    "HID_DIM = 512\n",
    "N_LAYERS = 2\n",
    "ENC_DROPOUT = 0.5\n",
    "DEC_DROPOUT = 0.5"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-02T10:48:31.602181400Z",
     "start_time": "2023-05-02T10:48:30.643806300Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 344,
   "outputs": [],
   "source": [
    "enc = Encoder(INPUT_DIM, ENC_EMB_DIM, HID_DIM, N_LAYERS, ENC_DROPOUT)\n",
    "dec = Decoder(OUTPUT_DIM, DEC_EMB_DIM, HID_DIM, N_LAYERS, DEC_DROPOUT)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-02T10:48:31.602181400Z",
     "start_time": "2023-05-02T10:48:30.657734300Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 345,
   "outputs": [],
   "source": [
    "model = Seq2Seq(enc, dec, device).to(device)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-02T10:48:31.632980700Z",
     "start_time": "2023-05-02T10:48:30.756443800Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 346,
   "outputs": [
    {
     "data": {
      "text/plain": "Seq2Seq(\n  (encoder): Encoder(\n    (embedding): Embedding(29, 256)\n    (rnn): LSTM(256, 512, num_layers=2, dropout=0.5)\n    (dropout): Dropout(p=0.5, inplace=False)\n  )\n  (decoder): Decoder(\n    (embedding): Embedding(131, 256)\n    (rnn): LSTM(256, 512, num_layers=2, dropout=0.5)\n    (fc_out): Linear(in_features=512, out_features=131, bias=True)\n    (dropout): Dropout(p=0.5, inplace=False)\n  )\n)"
     },
     "execution_count": 346,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def init_weights(m):\n",
    "    for name, param in m.named_parameters():\n",
    "        nn.init.uniform_(param.data, -0.08, 0.08)\n",
    "\n",
    "model.apply(init_weights)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-02T10:48:31.696174Z",
     "start_time": "2023-05-02T10:48:30.767208800Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 347,
   "outputs": [],
   "source": [
    "optimizer = optim.Adam(model.parameters())"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-02T10:48:31.696174Z",
     "start_time": "2023-05-02T10:48:30.955977200Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 348,
   "outputs": [],
   "source": [
    "# TRG_PAD_IDX = TRG.vocab.stoi[TRG.pad_token]\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-02T10:48:31.696174Z",
     "start_time": "2023-05-02T10:48:30.964267100Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 349,
   "outputs": [],
   "source": [
    "def train(model, iterator, optimizer, criterion, clip):\n",
    "\n",
    "    model.train()\n",
    "\n",
    "    epoch_loss = 0\n",
    "\n",
    "    for i, (data, target) in enumerate(iterator):\n",
    "\n",
    "        src = data\n",
    "        trg = target\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        output = model(src, trg)\n",
    "\n",
    "        #trg = [trg len, batch size]\n",
    "        #output = [trg len, batch size, output dim]\n",
    "\n",
    "        output_dim = output.shape[-1]\n",
    "\n",
    "        output = output[1:].view(-1, output_dim)\n",
    "        trg = trg[1:].view(-1)\n",
    "\n",
    "        #trg = [(trg len - 1) * batch size]\n",
    "        #output = [(trg len - 1) * batch size, output dim]\n",
    "\n",
    "        loss = criterion(output, trg)\n",
    "\n",
    "        loss.backward()\n",
    "\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), clip)\n",
    "\n",
    "        optimizer.step()\n",
    "\n",
    "        epoch_loss += loss.item()\n",
    "\n",
    "    return epoch_loss / len(iterator)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-02T10:48:31.696174Z",
     "start_time": "2023-05-02T10:48:30.987732Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "N_EPOCHS = 10\n",
    "CLIP = 1\n",
    "\n",
    "best_valid_loss = float('inf')\n",
    "\n",
    "for epoch in range(N_EPOCHS):\n",
    "\n",
    "    # start_time = time.time()\n",
    "\n",
    "    train_loss = train(model, train_dataloader, optimizer, criterion, CLIP)\n",
    "    # valid_loss = evaluate(model, valid_iterator, criterion)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 350,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2, 24, 11, 21, 10, 14, 3, 27, 21, 10, 11, 22, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "encoder forward prop\n",
      "encoder embedded shape torch.Size([28, 1, 256])\n",
      "encoder hidden dimension torch.Size([2, 1, 512])\n",
      "encoder output dimension torch.Size([28, 1, 512])\n",
      "encoder cell dimension torch.Size([2, 1, 512])\n",
      "seq2seq hidden shape torch.Size([2, 1, 512])\n",
      "seq2seq cell shape torch.Size([2, 1, 512])\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "element 0 of tensors does not require grad and does not have a grad_fn",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mRuntimeError\u001B[0m                              Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[350], line 9\u001B[0m\n\u001B[0;32m      4\u001B[0m best_valid_loss \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mfloat\u001B[39m(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124minf\u001B[39m\u001B[38;5;124m'\u001B[39m)\n\u001B[0;32m      6\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m epoch \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mrange\u001B[39m(N_EPOCHS):\n\u001B[0;32m      7\u001B[0m \n\u001B[0;32m      8\u001B[0m     \u001B[38;5;66;03m# start_time = time.time()\u001B[39;00m\n\u001B[1;32m----> 9\u001B[0m     train_loss \u001B[38;5;241m=\u001B[39m \u001B[43mtrain\u001B[49m\u001B[43m(\u001B[49m\u001B[43mmodel\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtrain_dataloader\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43moptimizer\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcriterion\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mCLIP\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     10\u001B[0m     \u001B[38;5;66;03m# valid_loss = evaluate(model, valid_iterator, criterion)\u001B[39;00m\n",
      "Cell \u001B[1;32mIn[349], line 29\u001B[0m, in \u001B[0;36mtrain\u001B[1;34m(model, iterator, optimizer, criterion, clip)\u001B[0m\n\u001B[0;32m     24\u001B[0m \u001B[38;5;66;03m#trg = [(trg len - 1) * batch size]\u001B[39;00m\n\u001B[0;32m     25\u001B[0m \u001B[38;5;66;03m#output = [(trg len - 1) * batch size, output dim]\u001B[39;00m\n\u001B[0;32m     27\u001B[0m loss \u001B[38;5;241m=\u001B[39m criterion(output, trg)\n\u001B[1;32m---> 29\u001B[0m \u001B[43mloss\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mbackward\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     31\u001B[0m torch\u001B[38;5;241m.\u001B[39mnn\u001B[38;5;241m.\u001B[39mutils\u001B[38;5;241m.\u001B[39mclip_grad_norm_(model\u001B[38;5;241m.\u001B[39mparameters(), clip)\n\u001B[0;32m     33\u001B[0m optimizer\u001B[38;5;241m.\u001B[39mstep()\n",
      "File \u001B[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\torch\\_tensor.py:487\u001B[0m, in \u001B[0;36mTensor.backward\u001B[1;34m(self, gradient, retain_graph, create_graph, inputs)\u001B[0m\n\u001B[0;32m    477\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m has_torch_function_unary(\u001B[38;5;28mself\u001B[39m):\n\u001B[0;32m    478\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m handle_torch_function(\n\u001B[0;32m    479\u001B[0m         Tensor\u001B[38;5;241m.\u001B[39mbackward,\n\u001B[0;32m    480\u001B[0m         (\u001B[38;5;28mself\u001B[39m,),\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m    485\u001B[0m         inputs\u001B[38;5;241m=\u001B[39minputs,\n\u001B[0;32m    486\u001B[0m     )\n\u001B[1;32m--> 487\u001B[0m \u001B[43mtorch\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mautograd\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mbackward\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m    488\u001B[0m \u001B[43m    \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mgradient\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mretain_graph\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcreate_graph\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43minputs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43minputs\u001B[49m\n\u001B[0;32m    489\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\torch\\autograd\\__init__.py:200\u001B[0m, in \u001B[0;36mbackward\u001B[1;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001B[0m\n\u001B[0;32m    195\u001B[0m     retain_graph \u001B[38;5;241m=\u001B[39m create_graph\n\u001B[0;32m    197\u001B[0m \u001B[38;5;66;03m# The reason we repeat same the comment below is that\u001B[39;00m\n\u001B[0;32m    198\u001B[0m \u001B[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001B[39;00m\n\u001B[0;32m    199\u001B[0m \u001B[38;5;66;03m# calls in the traceback and some print out the last line\u001B[39;00m\n\u001B[1;32m--> 200\u001B[0m \u001B[43mVariable\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_execution_engine\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mrun_backward\u001B[49m\u001B[43m(\u001B[49m\u001B[43m  \u001B[49m\u001B[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001B[39;49;00m\n\u001B[0;32m    201\u001B[0m \u001B[43m    \u001B[49m\u001B[43mtensors\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mgrad_tensors_\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mretain_graph\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcreate_graph\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43minputs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    202\u001B[0m \u001B[43m    \u001B[49m\u001B[43mallow_unreachable\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43maccumulate_grad\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\u001B[43m)\u001B[49m\n",
      "\u001B[1;31mRuntimeError\u001B[0m: element 0 of tensors does not require grad and does not have a grad_fn"
     ]
    }
   ],
   "source": [
    "N_EPOCHS = 1\n",
    "CLIP = 1\n",
    "\n",
    "best_valid_loss = float('inf')\n",
    "\n",
    "for epoch in range(N_EPOCHS):\n",
    "\n",
    "    # start_time = time.time()\n",
    "    train_loss = train(model, train_dataloader, optimizer, criterion, CLIP)\n",
    "    # valid_loss = evaluate(model, valid_iterator, criterion)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-02T10:48:31.696174Z",
     "start_time": "2023-05-02T10:48:31.044606100Z"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
