{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['c:\\\\Users\\\\gaura\\\\PycharmProjects\\\\scientificProject', 'c:\\\\Program Files\\\\Python311\\\\python311.zip', 'c:\\\\Program Files\\\\Python311\\\\DLLs', 'c:\\\\Program Files\\\\Python311\\\\Lib', 'c:\\\\Program Files\\\\Python311', '', 'C:\\\\Users\\\\gaura\\\\AppData\\\\Roaming\\\\Python\\\\Python311\\\\site-packages', 'C:\\\\Users\\\\gaura\\\\AppData\\\\Roaming\\\\Python\\\\Python311\\\\site-packages\\\\win32', 'C:\\\\Users\\\\gaura\\\\AppData\\\\Roaming\\\\Python\\\\Python311\\\\site-packages\\\\win32\\\\lib', 'C:\\\\Users\\\\gaura\\\\AppData\\\\Roaming\\\\Python\\\\Python311\\\\site-packages\\\\Pythonwin', 'c:\\\\Program Files\\\\Python311\\\\Lib\\\\site-packages']\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from tqdm.auto import tqdm\n",
    "from datetime import time\n",
    "import pandas as pd  # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data import Dataset\n",
    "import sys\n",
    "import torch.nn.functional as F\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "print(sys.path)\n",
    "import random\n",
    "import os\n",
    "\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        os.path.join(dirname, filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # !pip install wandb\n",
    "# import wandb\n",
    "# wandb.login(key = \"d4c2dc0cbf8caf1ee8dc1563f3d5c10594df22b5\")\n",
    "# wandb.init(project=\"DL_ASSIGNMENT_3_with_attention\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %env WANDB_SILENT=true\n",
    "# wandb.init(timeout=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Executing on cpu\n",
      "Running on local\n",
      "(51199, 2)\n",
      "(4095, 2)\n",
      "(4095, 2)\n",
      "{'_': 0, '|': 1, '$': 2, 'a': 3, 'b': 4, 'c': 5, 'd': 6, 'e': 7, 'f': 8, 'g': 9, 'h': 10, 'i': 11, 'j': 12, 'k': 13, 'l': 14, 'm': 15, 'n': 16, 'o': 17, 'p': 18, 'q': 19, 'r': 20, 's': 21, 't': 22, 'u': 23, 'v': 24, 'w': 25, 'x': 26, 'y': 27, 'z': 28}\n",
      "ouput char set  {'न', 'व', 'े', 'ळ', 'ओ', 'ा', 'ध', 'ए', 'ॅ', 'ै', 'ं', 'उ', 'ऐ', 'घ', 'ऋ', 'ई', '्', 'थ', 'ड', 'ठ', 'ऑ', 'अ', 'ौ', '़', 'ॉ', 'म', 'स', 'क', 'ट', 'ऍ', 'प', 'द', 'भ', 'ण', 'श', 'छ', 'ष', 'च', 'ृ', 'ढ', 'ु', 'ँ', 'य', 'ल', 'ह', 'इ', 'झ', 'औ', 'ो', 'ः', 'ऱ', 'र', 'ब', 'ञ', 'ि', 'ख', 'ऊ', 'ू', 'आ', 'ग', 'त', 'ज', 'ी', 'फ'}\n",
      "ouput char set size 64\n",
      "max input length 25\n",
      "max output length 19\n",
      "max_length 25\n",
      "Input Character max 29\n",
      "output Character size 67\n",
      "Input Character max 29\n",
      "output Character size 67\n",
      "tensor([ 4, 10, 23, 14, 22, 10,  3, 18,  3, 16,  3])\n",
      "व्हायकी\n",
      "{'_': 0, '|': 1, '$': 2, 'a': 3, 'b': 4, 'c': 5, 'd': 6, 'e': 7, 'f': 8, 'g': 9, 'h': 10, 'i': 11, 'j': 12, 'k': 13, 'l': 14, 'm': 15, 'n': 16, 'o': 17, 'p': 18, 'q': 19, 'r': 20, 's': 21, 't': 22, 'u': 23, 'v': 24, 'w': 25, 'x': 26, 'y': 27, 'z': 28}\n",
      "tensor([10,  7, 14, 14, 17])\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Executing on \" + (\"cuda:0\" if torch.cuda.is_available() else \"cpu\"))\n",
    "\n",
    "if 'PYTHONPATH' in os.environ:\n",
    "    if 'kaggle' in os.environ['PYTHONPATH']:\n",
    "        print('Running on Kaggle')\n",
    "        df_train = pd.read_csv(\"/kaggle/input/aksharantar_sampled/aksharantar_sampled/mar/mar_train.csv\")\n",
    "        df_test = pd.read_csv('/kaggle/input/aksharantar_sampled/aksharantar_sampled/mar/mar_test.csv')\n",
    "        df_valid = pd.read_csv('/kaggle/input/aksharantar/aksharantar_sampled/mar/mar_valid.csv')\n",
    "else:\n",
    "    #change the path to Data/mar\n",
    "    print('Running on local')\n",
    "    df_train = pd.read_csv(\"Data/mar/mar_train.csv\")\n",
    "    df_test = pd.read_csv('Data/mar/mar_test.csv')\n",
    "    df_valid = pd.read_csv('Data/mar/mar_valid.csv')\n",
    "\n",
    "print(df_train.shape)\n",
    "print(df_test.shape)\n",
    "print(df_valid.shape)\n",
    "\n",
    "PAD_CHAR = '_'  # padding character\n",
    "EOW_CHAR = '|'  # end of word character\n",
    "SOW_CHAR = '$'  # start of word character\n",
    "BATCH_SIZE = 32\n",
    "ENGLISH_ALPHA = [chr(alpha) for alpha in range(ord('a'), ord('z') + 1)]\n",
    "INPUT_CHAR_INDX = {PAD_CHAR: 0, EOW_CHAR: 1, SOW_CHAR: 2}\n",
    "for index, alpha in enumerate(ENGLISH_ALPHA):\n",
    "    INPUT_CHAR_INDX[alpha] = index + 3\n",
    "\n",
    "INPUT_INDX_CHAR = {v: k for k, v in INPUT_CHAR_INDX.items()}\n",
    "\n",
    "df_train = df_train.set_axis(['X', 'Y'], axis=1)\n",
    "df_valid = df_valid.set_axis(['X', 'Y'], axis=1)\n",
    "df_test = df_test.set_axis(['X', 'Y'], axis=1)\n",
    "\n",
    "print(INPUT_CHAR_INDX)\n",
    "\n",
    "ouput_words = df_train['Y'].tolist() + df_test['Y'].tolist() + df_valid['Y'].tolist()\n",
    "output_char_set = set()\n",
    "for word in ouput_words:\n",
    "    for char in word:\n",
    "        output_char_set.add(char)\n",
    "OUT_ALPHA = list(output_char_set)\n",
    "# OUT_ALPHA = [chr(alpha) for alpha in range(2304, 2432)]\n",
    "OUT_ALPHA_SIZE = len(OUT_ALPHA)\n",
    "OUTPUT_CHAR_INDEX = {PAD_CHAR: 0, EOW_CHAR: 1, SOW_CHAR: 2}\n",
    "for index, alpha in enumerate(OUT_ALPHA):\n",
    "    OUTPUT_CHAR_INDEX[alpha] = index + 3\n",
    "# %%\n",
    "\n",
    "OUTPUT_INDEX_CHAR = {v: k for k, v in OUTPUT_CHAR_INDEX.items()}\n",
    "\n",
    "print(\"ouput char set \",output_char_set)\n",
    "print(\"ouput char set size\",len(output_char_set))\n",
    "\n",
    "OUTPUT_INDEX_CHAR = {v: k for k, v in OUTPUT_CHAR_INDEX.items()}\n",
    "\n",
    "# print(OUTPUT_CHAR_INDEX)\n",
    "# print(len(OUTPUT_CHAR_INDEX))\n",
    "\n",
    "df_train = df_train.set_axis(['X', 'Y'], axis=1)\n",
    "df_valid = df_valid.set_axis(['X', 'Y'], axis=1)\n",
    "df_test = df_test.set_axis(['X', 'Y'], axis=1)\n",
    "# %%\n",
    "# print(df_train)\n",
    "# print(df_test)\n",
    "# print(df_valid)\n",
    "\n",
    "if 'kaggle' not in sys.path:\n",
    "    df_train = df_train.iloc[:2000,:]\n",
    "    df_test = df_test.iloc[:200,:]\n",
    "    df_valid = df_valid.iloc[:200,:]\n",
    "\n",
    "# %%\n",
    "max_input_length = max(df_train.iloc[:, 0].apply(lambda x: len(x)).max(),\n",
    "                       df_test.iloc[:, 0].apply(lambda x: len(x)).max(),\n",
    "                       df_valid.iloc[:, 0].apply(lambda x: len(x)).max())\n",
    "\n",
    "max_output_length = max(df_train.iloc[:, 1].apply(lambda x: len(x)).max(),\n",
    "                        df_test.iloc[:, 1].apply(lambda x: len(x)).max(),\n",
    "                        df_valid.iloc[:, 1].apply(lambda x: len(x)).max())\n",
    "\n",
    "print(\"max input length\", max_input_length)\n",
    "print(\"max output length\", max_output_length)\n",
    "MAX_LENGTH = max(max_input_length, max_output_length)\n",
    "print(\"max_length\", MAX_LENGTH)\n",
    "# %%\n",
    "input_vocab_size = len(INPUT_CHAR_INDX)\n",
    "output_vocab_size = len(OUTPUT_CHAR_INDEX)\n",
    "print(\"Input Character max\", input_vocab_size)\n",
    "print(\"output Character size\", output_vocab_size)\n",
    "\n",
    "train_list = df_train.values.tolist()\n",
    "valid_list = df_valid.values.tolist()\n",
    "test_list = df_test.values.tolist()\n",
    "\n",
    "# %%\n",
    "input_vocab_size = len(INPUT_CHAR_INDX)\n",
    "output_vocab_size = len(OUTPUT_CHAR_INDEX)\n",
    "print(\"Input Character max\", input_vocab_size)\n",
    "print(\"output Character size\", output_vocab_size)\n",
    "\n",
    "train_list = df_train.values.tolist()\n",
    "valid_list = df_valid.values.tolist()\n",
    "test_list = df_test.values.tolist()\n",
    "\n",
    "\n",
    "# %% md\n",
    "class Transliterate(Dataset):\n",
    "    def __init__(self, df_data, in_dict, out_dict):\n",
    "        super().__init__()\n",
    "        self.df_data_word = df_data.copy()\n",
    "        self.in_dict = in_dict\n",
    "        self.out_dict = out_dict\n",
    "        self.df_data = df_data.iloc[:, ].apply(lambda x: SOW_CHAR + x + EOW_CHAR)\n",
    "\n",
    "\n",
    "    def __get_random_word__(self):\n",
    "        idx = random.randint(0, len(self.df_data))\n",
    "        input_word = self.df_data_word.iloc[idx][0]\n",
    "        output_word = self.df_data_word.iloc[idx][1]\n",
    "        return input_word, output_word\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df_data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        input_word = self.df_data.iloc[idx][0]\n",
    "        output_word = self.df_data.iloc[idx][1]\n",
    "        input_tensor = inputToTensor(input_word)\n",
    "        output_tensor = outToTensor(output_word)\n",
    "        return input_tensor, output_tensor\n",
    "\n",
    "    def __getrandom__(self):\n",
    "        idx = random.randint(0,len(self.data_list))\n",
    "        input_word = self.df_data[idx][0]\n",
    "        output_word = self.df_data[idx][1]\n",
    "        input_tensor = inputToTensor(input_word)\n",
    "        output_tensor = outToTensor(output_word)\n",
    "        return input_tensor, output_tensor\n",
    "\n",
    "    def preprocess(self, word):\n",
    "        return SOW_CHAR + word + EOW_CHAR\n",
    "\n",
    "\n",
    "train_data = Transliterate(df_train, INPUT_CHAR_INDX, OUTPUT_CHAR_INDEX)\n",
    "valid_data = Transliterate(df_valid, INPUT_CHAR_INDX, OUTPUT_CHAR_INDEX)\n",
    "test_data = Transliterate(df_test, INPUT_CHAR_INDX, OUTPUT_CHAR_INDEX)\n",
    "# %%\n",
    "def inputToTensor(line):\n",
    "    tensor = torch.tensor(data=([INPUT_CHAR_INDX[x] for x in line]), dtype=torch.long)\n",
    "    return tensor\n",
    "\n",
    "\n",
    "def charToTensor(char, dic=INPUT_CHAR_INDX):\n",
    "    tensor = torch.zeros(len(dic))\n",
    "    tensor[dic[char]] = 1\n",
    "    return tensor\n",
    "\n",
    "\n",
    "def outToTensor(word):\n",
    "    tensor = torch.tensor([OUTPUT_CHAR_INDEX[x] for x in word])\n",
    "    return tensor\n",
    "\n",
    "\n",
    "# %%\n",
    "print(inputToTensor(train_list[0][0]))\n",
    "# %%\n",
    "print(train_list[1][1])\n",
    "\n",
    "# %%\n",
    "inputToTensor(\"$bindhya|\")\n",
    "# %%\n",
    "print(INPUT_CHAR_INDX)\n",
    "# %%\n",
    "print(inputToTensor(\"hello\"))\n",
    "\n",
    "\n",
    "# %%\n",
    "def generate_batch(data_batch):\n",
    "    train_batch = [x[0] for x in data_batch]\n",
    "    target_batch = [x[1] for x in data_batch]\n",
    "    train_pad = torch.nn.utils.rnn.pad_sequence(train_batch, batch_first=True, padding_value=0)\n",
    "    train_pad = train_pad[:, :MAX_LENGTH]\n",
    "    train_pad = torch.nn.functional.pad(train_pad, (0, MAX_LENGTH - train_pad.size(1)), value=0)\n",
    "    target_pad = torch.nn.utils.rnn.pad_sequence(target_batch, batch_first=True, padding_value=0)\n",
    "    target_pad = target_pad[:, :MAX_LENGTH]\n",
    "    target_pad = torch.nn.functional.pad(target_pad, (0, MAX_LENGTH - target_pad.size(1)), value=0)\n",
    "    padded_input_batch = train_pad.T.to(device)\n",
    "    padded_output_batch = target_pad.T.to(device)\n",
    "    return padded_input_batch, padded_output_batch\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# for data, target in train_dataloader:\n",
    "#     print(data.shape)\n",
    "#     print(target.shape)\n",
    "#     if True:\n",
    "#         break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\gaura\\AppData\\Roaming\\Python\\Python311\\site-packages\\torch\\nn\\modules\\rnn.py:71: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.5 and num_layers=1\n",
      "  warnings.warn(\"dropout option adds dropout after all but last \"\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a9d8fbe58e05483d9586dba351113f28",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epochs:   0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f6a20936934547dfa947f47da838d705",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training:   0%|          | 0/2000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "attention applied shape torch.Size([1, 256])\n",
      "attention_weights tensor([[0.0433, 0.0380, 0.0378, 0.0415, 0.0406, 0.0393, 0.0375, 0.0425, 0.0426,\n",
      "         0.0400, 0.0400, 0.0365, 0.0384, 0.0387, 0.0410, 0.0422, 0.0404, 0.0373,\n",
      "         0.0408, 0.0428, 0.0361, 0.0391, 0.0421, 0.0405, 0.0409]],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "attention applied shape torch.Size([1, 256])\n",
      "attention_weights tensor([[0.0436, 0.0401, 0.0370, 0.0419, 0.0416, 0.0430, 0.0409, 0.0408, 0.0389,\n",
      "         0.0387, 0.0427, 0.0350, 0.0377, 0.0354, 0.0402, 0.0411, 0.0394, 0.0372,\n",
      "         0.0371, 0.0420, 0.0397, 0.0415, 0.0404, 0.0425, 0.0415]],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "attention applied shape torch.Size([1, 256])\n",
      "attention_weights tensor([[0.0439, 0.0384, 0.0359, 0.0402, 0.0441, 0.0396, 0.0403, 0.0403, 0.0378,\n",
      "         0.0396, 0.0418, 0.0343, 0.0396, 0.0364, 0.0417, 0.0399, 0.0406, 0.0375,\n",
      "         0.0387, 0.0446, 0.0377, 0.0420, 0.0402, 0.0423, 0.0427]],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "attention applied shape torch.Size([1, 256])\n",
      "attention_weights tensor([[0.0437, 0.0388, 0.0366, 0.0390, 0.0429, 0.0421, 0.0411, 0.0412, 0.0377,\n",
      "         0.0379, 0.0419, 0.0341, 0.0411, 0.0372, 0.0423, 0.0431, 0.0416, 0.0360,\n",
      "         0.0370, 0.0410, 0.0374, 0.0420, 0.0399, 0.0424, 0.0420]],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "attention applied shape torch.Size([1, 256])\n",
      "attention_weights tensor([[0.0432, 0.0376, 0.0368, 0.0393, 0.0409, 0.0402, 0.0389, 0.0428, 0.0387,\n",
      "         0.0392, 0.0412, 0.0375, 0.0388, 0.0366, 0.0404, 0.0411, 0.0409, 0.0395,\n",
      "         0.0409, 0.0414, 0.0361, 0.0423, 0.0425, 0.0407, 0.0427]],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "attention applied shape torch.Size([1, 256])\n",
      "attention_weights tensor([[0.0412, 0.0385, 0.0378, 0.0357, 0.0441, 0.0399, 0.0424, 0.0402, 0.0413,\n",
      "         0.0367, 0.0431, 0.0357, 0.0385, 0.0388, 0.0404, 0.0426, 0.0423, 0.0358,\n",
      "         0.0406, 0.0412, 0.0374, 0.0374, 0.0402, 0.0431, 0.0450]],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "attention applied shape torch.Size([1, 256])\n",
      "attention_weights tensor([[0.0426, 0.0397, 0.0363, 0.0368, 0.0424, 0.0397, 0.0386, 0.0421, 0.0388,\n",
      "         0.0390, 0.0415, 0.0377, 0.0399, 0.0400, 0.0397, 0.0410, 0.0397, 0.0375,\n",
      "         0.0391, 0.0407, 0.0384, 0.0418, 0.0417, 0.0418, 0.0434]],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "attention applied shape torch.Size([1, 256])\n",
      "attention_weights tensor([[0.0442, 0.0386, 0.0361, 0.0377, 0.0423, 0.0426, 0.0403, 0.0408, 0.0369,\n",
      "         0.0392, 0.0418, 0.0364, 0.0386, 0.0384, 0.0415, 0.0406, 0.0416, 0.0375,\n",
      "         0.0374, 0.0436, 0.0363, 0.0422, 0.0399, 0.0417, 0.0437]],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "attention applied shape torch.Size([1, 256])\n",
      "attention_weights tensor([[0.0410, 0.0370, 0.0371, 0.0389, 0.0421, 0.0403, 0.0398, 0.0430, 0.0387,\n",
      "         0.0374, 0.0422, 0.0385, 0.0402, 0.0370, 0.0404, 0.0396, 0.0395, 0.0385,\n",
      "         0.0406, 0.0458, 0.0375, 0.0431, 0.0408, 0.0399, 0.0411]],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "attention applied shape torch.Size([1, 256])\n",
      "attention_weights tensor([[0.0428, 0.0383, 0.0368, 0.0392, 0.0421, 0.0408, 0.0404, 0.0412, 0.0366,\n",
      "         0.0389, 0.0436, 0.0393, 0.0381, 0.0384, 0.0376, 0.0418, 0.0400, 0.0394,\n",
      "         0.0375, 0.0422, 0.0380, 0.0419, 0.0397, 0.0418, 0.0434]],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "attention applied shape torch.Size([1, 256])\n",
      "attention_weights tensor([[0.0417, 0.0390, 0.0372, 0.0369, 0.0440, 0.0396, 0.0422, 0.0403, 0.0407,\n",
      "         0.0379, 0.0414, 0.0369, 0.0393, 0.0395, 0.0397, 0.0409, 0.0402, 0.0359,\n",
      "         0.0400, 0.0420, 0.0360, 0.0388, 0.0431, 0.0432, 0.0434]],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "attention applied shape torch.Size([1, 256])\n",
      "attention_weights tensor([[0.0418, 0.0393, 0.0389, 0.0357, 0.0429, 0.0413, 0.0396, 0.0419, 0.0400,\n",
      "         0.0376, 0.0391, 0.0360, 0.0389, 0.0394, 0.0384, 0.0401, 0.0410, 0.0368,\n",
      "         0.0414, 0.0427, 0.0375, 0.0399, 0.0439, 0.0414, 0.0443]],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "attention applied shape torch.Size([1, 256])\n",
      "attention_weights tensor([[0.0401, 0.0386, 0.0374, 0.0370, 0.0439, 0.0414, 0.0425, 0.0428, 0.0405,\n",
      "         0.0363, 0.0428, 0.0358, 0.0379, 0.0392, 0.0391, 0.0435, 0.0400, 0.0356,\n",
      "         0.0405, 0.0432, 0.0371, 0.0391, 0.0409, 0.0426, 0.0422]],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "attention applied shape torch.Size([1, 256])\n",
      "attention_weights tensor([[0.0426, 0.0386, 0.0372, 0.0377, 0.0437, 0.0453, 0.0397, 0.0406, 0.0364,\n",
      "         0.0387, 0.0421, 0.0365, 0.0372, 0.0396, 0.0373, 0.0421, 0.0401, 0.0379,\n",
      "         0.0400, 0.0425, 0.0384, 0.0407, 0.0425, 0.0388, 0.0438]],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "attention applied shape torch.Size([1, 256])\n",
      "attention_weights tensor([[0.0425, 0.0385, 0.0364, 0.0362, 0.0460, 0.0441, 0.0398, 0.0419, 0.0379,\n",
      "         0.0372, 0.0393, 0.0348, 0.0388, 0.0396, 0.0391, 0.0410, 0.0395, 0.0393,\n",
      "         0.0406, 0.0433, 0.0381, 0.0401, 0.0421, 0.0409, 0.0430]],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "attention applied shape torch.Size([1, 256])\n",
      "attention_weights tensor([[0.0429, 0.0408, 0.0374, 0.0374, 0.0433, 0.0440, 0.0406, 0.0406, 0.0368,\n",
      "         0.0358, 0.0412, 0.0346, 0.0376, 0.0396, 0.0404, 0.0421, 0.0391, 0.0387,\n",
      "         0.0392, 0.0432, 0.0372, 0.0389, 0.0424, 0.0424, 0.0438]],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "attention applied shape torch.Size([1, 256])\n",
      "attention_weights tensor([[0.0434, 0.0387, 0.0365, 0.0370, 0.0451, 0.0435, 0.0395, 0.0413, 0.0369,\n",
      "         0.0382, 0.0406, 0.0356, 0.0400, 0.0385, 0.0412, 0.0396, 0.0397, 0.0394,\n",
      "         0.0384, 0.0422, 0.0386, 0.0409, 0.0427, 0.0410, 0.0415]],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "attention applied shape torch.Size([1, 256])\n",
      "attention_weights tensor([[0.0444, 0.0389, 0.0352, 0.0378, 0.0438, 0.0471, 0.0396, 0.0403, 0.0375,\n",
      "         0.0384, 0.0409, 0.0344, 0.0381, 0.0390, 0.0388, 0.0404, 0.0413, 0.0365,\n",
      "         0.0399, 0.0424, 0.0390, 0.0388, 0.0426, 0.0401, 0.0448]],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "attention applied shape torch.Size([1, 256])\n",
      "attention_weights tensor([[0.0431, 0.0389, 0.0351, 0.0372, 0.0445, 0.0452, 0.0420, 0.0414, 0.0361,\n",
      "         0.0387, 0.0399, 0.0347, 0.0395, 0.0390, 0.0380, 0.0408, 0.0405, 0.0391,\n",
      "         0.0395, 0.0439, 0.0374, 0.0410, 0.0410, 0.0386, 0.0448]],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "attention applied shape torch.Size([1, 256])\n",
      "attention_weights tensor([[0.0422, 0.0406, 0.0363, 0.0378, 0.0452, 0.0435, 0.0405, 0.0412, 0.0381,\n",
      "         0.0389, 0.0391, 0.0359, 0.0396, 0.0391, 0.0379, 0.0406, 0.0393, 0.0382,\n",
      "         0.0378, 0.0438, 0.0360, 0.0412, 0.0419, 0.0403, 0.0449]],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "attention applied shape torch.Size([1, 256])\n",
      "attention_weights tensor([[0.0437, 0.0395, 0.0363, 0.0375, 0.0446, 0.0412, 0.0401, 0.0416, 0.0374,\n",
      "         0.0369, 0.0398, 0.0358, 0.0369, 0.0384, 0.0399, 0.0434, 0.0389, 0.0389,\n",
      "         0.0396, 0.0433, 0.0378, 0.0403, 0.0429, 0.0418, 0.0436]],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "attention applied shape torch.Size([1, 256])\n",
      "attention_weights tensor([[0.0403, 0.0399, 0.0381, 0.0357, 0.0434, 0.0404, 0.0409, 0.0409, 0.0394,\n",
      "         0.0375, 0.0415, 0.0358, 0.0387, 0.0405, 0.0395, 0.0416, 0.0427, 0.0378,\n",
      "         0.0411, 0.0424, 0.0371, 0.0388, 0.0418, 0.0408, 0.0433]],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "attention applied shape torch.Size([1, 256])\n",
      "attention_weights tensor([[0.0411, 0.0386, 0.0374, 0.0360, 0.0423, 0.0393, 0.0400, 0.0406, 0.0399,\n",
      "         0.0372, 0.0436, 0.0360, 0.0390, 0.0405, 0.0379, 0.0415, 0.0438, 0.0383,\n",
      "         0.0404, 0.0428, 0.0378, 0.0392, 0.0427, 0.0397, 0.0443]],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "attention applied shape torch.Size([1, 256])\n",
      "attention_weights tensor([[0.0418, 0.0389, 0.0374, 0.0366, 0.0436, 0.0410, 0.0406, 0.0411, 0.0391,\n",
      "         0.0369, 0.0414, 0.0364, 0.0402, 0.0390, 0.0396, 0.0416, 0.0430, 0.0354,\n",
      "         0.0412, 0.0411, 0.0369, 0.0383, 0.0424, 0.0429, 0.0434]],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "attention weights tensor([[0.0418, 0.0389, 0.0374, 0.0366, 0.0436, 0.0410, 0.0406, 0.0411, 0.0391,\n",
      "         0.0369, 0.0414, 0.0364, 0.0402, 0.0390, 0.0396, 0.0416, 0.0430, 0.0354,\n",
      "         0.0412, 0.0411, 0.0369, 0.0383, 0.0424, 0.0429, 0.0434]],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "attention weights shape torch.Size([1, 25])\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "attention applied shape torch.Size([1, 256])\n",
      "attention_weights tensor([[0.0429, 0.0395, 0.0388, 0.0404, 0.0404, 0.0398, 0.0367, 0.0427, 0.0414,\n",
      "         0.0394, 0.0411, 0.0360, 0.0397, 0.0380, 0.0403, 0.0421, 0.0396, 0.0369,\n",
      "         0.0389, 0.0430, 0.0372, 0.0407, 0.0413, 0.0429, 0.0401]],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "attention applied shape torch.Size([1, 256])\n",
      "attention_weights tensor([[0.0416, 0.0383, 0.0363, 0.0399, 0.0419, 0.0401, 0.0403, 0.0404, 0.0384,\n",
      "         0.0379, 0.0398, 0.0353, 0.0401, 0.0382, 0.0418, 0.0424, 0.0401, 0.0383,\n",
      "         0.0400, 0.0445, 0.0368, 0.0407, 0.0416, 0.0416, 0.0436]],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "attention applied shape torch.Size([1, 256])\n",
      "attention_weights tensor([[0.0413, 0.0379, 0.0386, 0.0390, 0.0407, 0.0404, 0.0390, 0.0426, 0.0392,\n",
      "         0.0390, 0.0393, 0.0359, 0.0392, 0.0377, 0.0385, 0.0425, 0.0407, 0.0388,\n",
      "         0.0393, 0.0430, 0.0363, 0.0440, 0.0411, 0.0427, 0.0433]],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "attention applied shape torch.Size([1, 256])\n",
      "attention_weights tensor([[0.0425, 0.0371, 0.0366, 0.0383, 0.0423, 0.0402, 0.0388, 0.0422, 0.0374,\n",
      "         0.0401, 0.0393, 0.0363, 0.0401, 0.0402, 0.0383, 0.0415, 0.0417, 0.0397,\n",
      "         0.0396, 0.0439, 0.0378, 0.0433, 0.0413, 0.0403, 0.0412]],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "attention applied shape torch.Size([1, 256])\n",
      "attention_weights tensor([[0.0423, 0.0383, 0.0368, 0.0374, 0.0428, 0.0402, 0.0413, 0.0413, 0.0378,\n",
      "         0.0393, 0.0406, 0.0366, 0.0392, 0.0378, 0.0370, 0.0416, 0.0409, 0.0383,\n",
      "         0.0411, 0.0447, 0.0379, 0.0414, 0.0421, 0.0425, 0.0409]],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "attention applied shape torch.Size([1, 256])\n",
      "attention_weights tensor([[0.0435, 0.0384, 0.0363, 0.0381, 0.0434, 0.0434, 0.0404, 0.0406, 0.0373,\n",
      "         0.0391, 0.0398, 0.0349, 0.0380, 0.0386, 0.0388, 0.0420, 0.0396, 0.0389,\n",
      "         0.0390, 0.0433, 0.0381, 0.0411, 0.0424, 0.0405, 0.0443]],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "attention applied shape torch.Size([1, 256])\n",
      "attention_weights tensor([[0.0416, 0.0381, 0.0380, 0.0367, 0.0424, 0.0396, 0.0409, 0.0405, 0.0399,\n",
      "         0.0384, 0.0404, 0.0356, 0.0390, 0.0389, 0.0387, 0.0427, 0.0419, 0.0381,\n",
      "         0.0401, 0.0431, 0.0371, 0.0400, 0.0423, 0.0419, 0.0441]],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "attention applied shape torch.Size([1, 256])\n",
      "attention_weights tensor([[0.0430, 0.0375, 0.0358, 0.0381, 0.0418, 0.0396, 0.0400, 0.0403, 0.0377,\n",
      "         0.0411, 0.0404, 0.0357, 0.0402, 0.0386, 0.0393, 0.0416, 0.0409, 0.0383,\n",
      "         0.0392, 0.0434, 0.0375, 0.0431, 0.0416, 0.0419, 0.0433]],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "attention applied shape torch.Size([1, 256])\n",
      "attention_weights tensor([[0.0435, 0.0386, 0.0363, 0.0381, 0.0432, 0.0432, 0.0402, 0.0406, 0.0373,\n",
      "         0.0392, 0.0397, 0.0351, 0.0379, 0.0387, 0.0387, 0.0417, 0.0399, 0.0388,\n",
      "         0.0391, 0.0434, 0.0380, 0.0411, 0.0426, 0.0404, 0.0445]],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "attention applied shape torch.Size([1, 256])\n",
      "attention_weights tensor([[0.0437, 0.0388, 0.0363, 0.0380, 0.0432, 0.0433, 0.0403, 0.0406, 0.0373,\n",
      "         0.0391, 0.0395, 0.0349, 0.0380, 0.0388, 0.0387, 0.0417, 0.0399, 0.0390,\n",
      "         0.0390, 0.0435, 0.0379, 0.0410, 0.0427, 0.0405, 0.0443]],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "attention applied shape torch.Size([1, 256])\n",
      "attention_weights tensor([[0.0438, 0.0388, 0.0363, 0.0379, 0.0432, 0.0433, 0.0403, 0.0406, 0.0373,\n",
      "         0.0390, 0.0394, 0.0349, 0.0381, 0.0388, 0.0387, 0.0416, 0.0399, 0.0390,\n",
      "         0.0389, 0.0436, 0.0378, 0.0410, 0.0427, 0.0406, 0.0442]],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "attention applied shape torch.Size([1, 256])\n",
      "attention_weights tensor([[0.0438, 0.0389, 0.0363, 0.0379, 0.0432, 0.0433, 0.0403, 0.0406, 0.0373,\n",
      "         0.0390, 0.0394, 0.0348, 0.0382, 0.0388, 0.0388, 0.0416, 0.0399, 0.0391,\n",
      "         0.0389, 0.0436, 0.0378, 0.0410, 0.0427, 0.0406, 0.0442]],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "attention applied shape torch.Size([1, 256])\n",
      "attention_weights tensor([[0.0438, 0.0389, 0.0363, 0.0379, 0.0432, 0.0433, 0.0403, 0.0406, 0.0373,\n",
      "         0.0390, 0.0394, 0.0348, 0.0382, 0.0388, 0.0388, 0.0416, 0.0399, 0.0391,\n",
      "         0.0389, 0.0436, 0.0378, 0.0410, 0.0427, 0.0406, 0.0442]],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "attention applied shape torch.Size([1, 256])\n",
      "attention_weights tensor([[0.0438, 0.0389, 0.0363, 0.0379, 0.0432, 0.0433, 0.0403, 0.0406, 0.0373,\n",
      "         0.0390, 0.0394, 0.0348, 0.0382, 0.0388, 0.0388, 0.0416, 0.0399, 0.0391,\n",
      "         0.0389, 0.0436, 0.0378, 0.0410, 0.0427, 0.0407, 0.0441]],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "attention applied shape torch.Size([1, 256])\n",
      "attention_weights tensor([[0.0438, 0.0389, 0.0363, 0.0379, 0.0432, 0.0433, 0.0404, 0.0406, 0.0373,\n",
      "         0.0390, 0.0394, 0.0348, 0.0382, 0.0388, 0.0388, 0.0416, 0.0399, 0.0391,\n",
      "         0.0389, 0.0436, 0.0378, 0.0410, 0.0427, 0.0407, 0.0441]],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "attention applied shape torch.Size([1, 256])\n",
      "attention_weights tensor([[0.0438, 0.0388, 0.0363, 0.0379, 0.0432, 0.0433, 0.0404, 0.0406, 0.0373,\n",
      "         0.0390, 0.0394, 0.0348, 0.0382, 0.0388, 0.0388, 0.0416, 0.0399, 0.0391,\n",
      "         0.0389, 0.0436, 0.0377, 0.0410, 0.0427, 0.0407, 0.0441]],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "attention applied shape torch.Size([1, 256])\n",
      "attention_weights tensor([[0.0438, 0.0388, 0.0363, 0.0379, 0.0432, 0.0433, 0.0404, 0.0406, 0.0373,\n",
      "         0.0390, 0.0394, 0.0348, 0.0382, 0.0388, 0.0388, 0.0415, 0.0399, 0.0391,\n",
      "         0.0389, 0.0436, 0.0377, 0.0410, 0.0427, 0.0407, 0.0441]],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "attention applied shape torch.Size([1, 256])\n",
      "attention_weights tensor([[0.0438, 0.0388, 0.0363, 0.0379, 0.0432, 0.0433, 0.0404, 0.0406, 0.0373,\n",
      "         0.0390, 0.0394, 0.0348, 0.0382, 0.0388, 0.0388, 0.0415, 0.0399, 0.0391,\n",
      "         0.0389, 0.0436, 0.0377, 0.0410, 0.0427, 0.0407, 0.0441]],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "attention applied shape torch.Size([1, 256])\n",
      "attention_weights tensor([[0.0438, 0.0388, 0.0363, 0.0379, 0.0432, 0.0433, 0.0404, 0.0406, 0.0373,\n",
      "         0.0390, 0.0394, 0.0348, 0.0382, 0.0388, 0.0388, 0.0415, 0.0399, 0.0391,\n",
      "         0.0389, 0.0436, 0.0377, 0.0410, 0.0427, 0.0407, 0.0441]],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "attention applied shape torch.Size([1, 256])\n",
      "attention_weights tensor([[0.0438, 0.0388, 0.0363, 0.0379, 0.0432, 0.0433, 0.0404, 0.0406, 0.0373,\n",
      "         0.0390, 0.0394, 0.0348, 0.0382, 0.0388, 0.0388, 0.0415, 0.0399, 0.0391,\n",
      "         0.0389, 0.0436, 0.0377, 0.0410, 0.0427, 0.0407, 0.0441]],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "attention applied shape torch.Size([1, 256])\n",
      "attention_weights tensor([[0.0438, 0.0388, 0.0363, 0.0379, 0.0432, 0.0433, 0.0404, 0.0406, 0.0373,\n",
      "         0.0390, 0.0394, 0.0348, 0.0382, 0.0388, 0.0388, 0.0415, 0.0399, 0.0391,\n",
      "         0.0389, 0.0436, 0.0377, 0.0410, 0.0427, 0.0407, 0.0441]],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "attention applied shape torch.Size([1, 256])\n",
      "attention_weights tensor([[0.0438, 0.0388, 0.0363, 0.0379, 0.0432, 0.0433, 0.0404, 0.0406, 0.0373,\n",
      "         0.0390, 0.0394, 0.0348, 0.0382, 0.0388, 0.0388, 0.0415, 0.0399, 0.0391,\n",
      "         0.0389, 0.0436, 0.0377, 0.0410, 0.0427, 0.0407, 0.0441]],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "attention applied shape torch.Size([1, 256])\n",
      "attention_weights tensor([[0.0438, 0.0388, 0.0363, 0.0379, 0.0432, 0.0433, 0.0404, 0.0406, 0.0373,\n",
      "         0.0390, 0.0394, 0.0348, 0.0382, 0.0388, 0.0388, 0.0415, 0.0399, 0.0391,\n",
      "         0.0389, 0.0436, 0.0377, 0.0410, 0.0427, 0.0407, 0.0441]],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "attention applied shape torch.Size([1, 256])\n",
      "attention_weights tensor([[0.0438, 0.0388, 0.0363, 0.0379, 0.0432, 0.0433, 0.0404, 0.0406, 0.0373,\n",
      "         0.0390, 0.0394, 0.0348, 0.0382, 0.0388, 0.0388, 0.0415, 0.0399, 0.0391,\n",
      "         0.0389, 0.0436, 0.0377, 0.0410, 0.0427, 0.0407, 0.0441]],\n",
      "       grad_fn=<SoftmaxBackward0>)\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'tuple' object has no attribute 'shape'",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mAttributeError\u001B[0m                            Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[34], line 273\u001B[0m\n\u001B[0;32m    271\u001B[0m \u001B[39mfor\u001B[39;00m epoch \u001B[39min\u001B[39;00m gbar:\n\u001B[0;32m    272\u001B[0m     train_loss, train_accuracy \u001B[39m=\u001B[39m train(model, train_dataloader, optimizer, criterion, CLIP)\n\u001B[1;32m--> 273\u001B[0m     valid_loss, valid_accuracy \u001B[39m=\u001B[39m evaluate(model, valid_dataloader, criterion)\n\u001B[0;32m    274\u001B[0m     gbar\u001B[39m.\u001B[39mset_postfix(train_loss\u001B[39m=\u001B[39mtrain_loss, train_acc\u001B[39m=\u001B[39mtrain_accuracy, val_loss\u001B[39m=\u001B[39mvalid_loss, val_acc\u001B[39m=\u001B[39mvalid_accuracy)\n\u001B[0;32m    276\u001B[0m predict(model, pred_src, pred_trg)\n",
      "Cell \u001B[1;32mIn[34], line 201\u001B[0m, in \u001B[0;36mevaluate\u001B[1;34m(model, iterator, criterion)\u001B[0m\n\u001B[0;32m    199\u001B[0m trg \u001B[39m=\u001B[39m target\u001B[39m.\u001B[39mto(device)\n\u001B[0;32m    200\u001B[0m output \u001B[39m=\u001B[39m model(src, trg)\n\u001B[1;32m--> 201\u001B[0m output_dim \u001B[39m=\u001B[39m output\u001B[39m.\u001B[39;49mshape[\u001B[39m-\u001B[39m\u001B[39m1\u001B[39m]\n\u001B[0;32m    202\u001B[0m output_reshaped \u001B[39m=\u001B[39m output[\u001B[39m1\u001B[39m:]\u001B[39m.\u001B[39mreshape(\u001B[39m-\u001B[39m\u001B[39m1\u001B[39m, output_dim)\n\u001B[0;32m    203\u001B[0m trg_reshaped \u001B[39m=\u001B[39m trg[\u001B[39m1\u001B[39m:]\u001B[39m.\u001B[39mreshape(\u001B[39m-\u001B[39m\u001B[39m1\u001B[39m)\n",
      "\u001B[1;31mAttributeError\u001B[0m: 'tuple' object has no attribute 'shape'"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "\n",
    "class Encoder(nn.Module):\n",
    "    def __init__(self, input_size, embedding_size, hidden_size, num_layers, dropout, cell_type, bidirectional=True, batch_size=BATCH_SIZE):\n",
    "        super().__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_layers = num_layers\n",
    "        self.embedding = nn.Embedding(input_size, embedding_size)\n",
    "        self.cell_type = cell_type\n",
    "        self.batch_size = batch_size\n",
    "        self.bidirectional = bidirectional\n",
    "        if cell_type == 'RNN':\n",
    "            self.rnn = nn.RNN(embedding_size, hidden_size, num_layers, dropout=dropout, bidirectional=bidirectional)\n",
    "        elif cell_type == 'LSTM':\n",
    "            self.rnn = nn.LSTM(embedding_size, hidden_size, num_layers, dropout=dropout, bidirectional=bidirectional)\n",
    "        elif cell_type == 'GRU':\n",
    "            self.rnn = nn.GRU(embedding_size, hidden_size, num_layers, dropout=dropout, bidirectional=bidirectional)\n",
    "        # self.rnn = nn.LSTM(embedding_size, hidden_size, n_layers, dropout=dropout)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self, src, hidden=None):\n",
    "        embedded = self.dropout(self.embedding(src))\n",
    "        if self.cell_type == 'LSTM':\n",
    "            output, (hidden, cell) = self.rnn(embedded)\n",
    "        else:\n",
    "            output, hidden = self.rnn(embedded,hidden)\n",
    "        if self.bidirectional:\n",
    "    # Split hidden and cell into two halves along the first dimension\n",
    "            hidden_chunks = torch.chunk(hidden, 2, dim=0)\n",
    "            hidden = 0.5 * (hidden_chunks[0] + hidden_chunks[1])\n",
    "\n",
    "            if self.cell_type == \"LSTM\":\n",
    "                cell_chunks = torch.chunk(cell, 2, dim=0)\n",
    "                cell = 0.5 * (cell_chunks[0] + cell_chunks[1])\n",
    "\n",
    "    # Compute the average of forward and backward outputs\n",
    "            output = output.permute(2, 1, 0)\n",
    "            output_chunks = torch.chunk(output, 2, dim=0)\n",
    "            output = 0.5 * (output_chunks[0] + output_chunks[1])\n",
    "            output = output.permute(2, 1, 0)\n",
    "\n",
    "        if (self.cell_type == \"LSTM\"):\n",
    "            return output, hidden, cell\n",
    "        else:\n",
    "            return output, hidden\n",
    "\n",
    "    def initHidden(self):\n",
    "        if self.bidirectional == True:\n",
    "            return torch.zeros(2*self.num_layers, self.batch_size, self.hidden_size, device=device)\n",
    "        else:\n",
    "            return torch.zeros(self.num_layers, self.batch_size, self.hidden_size, device=device)\n",
    "\n",
    "# write decoder with attention\n",
    "\n",
    "\n",
    "class Decoder_with_attention(nn.Module):\n",
    "    def __init__(self,hidden_size,output_size,num_layers,dropout,embedding_size, cell_type =\"LSTM\",batch_size=BATCH_SIZE):\n",
    "        super(Decoder_with_attention,self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.output_size = output_size\n",
    "        self.num_layers = num_layers\n",
    "        self.batch_size = batch_size\n",
    "        self.embedding_size = embedding_size\n",
    "        self.cell_type = cell_type\n",
    "        self.embedding = nn.Embedding(output_size,embedding_size)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.attn = nn.Linear(self.hidden_size+self.embedding_size,MAX_LENGTH)\n",
    "        self.attn_combine = nn.Linear(self.hidden_size+self.embedding_size,self.hidden_size)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        if cell_type == 'RNN':\n",
    "            self.rnn = nn.RNN(self.hidden_size,self.hidden_size,num_layers,dropout=dropout)\n",
    "        elif cell_type == 'LSTM':\n",
    "            self.rnn = nn.LSTM(self.hidden_size,self.hidden_size,num_layers,dropout=dropout)\n",
    "        elif cell_type == 'GRU':\n",
    "            self.rnn = nn.GRU(self.hidden_size,self.hidden_size,num_layers,dropout=dropout)\n",
    "\n",
    "        self.out = nn.Linear(self.hidden_size,self.output_size)\n",
    "        self.softmax = nn.LogSoftmax(dim=1)\n",
    "\n",
    "    def forward(self,input,hidden,encoder_outputs):\n",
    "        input = input.unsqueeze(0)\n",
    "        self.batch_size = input.size(1)\n",
    "        output = self.embedding(input).view(-1,self.batch_size,self.embedding_size)\n",
    "        output = self.dropout(output)\n",
    "        if self.cell_type == \"LSTM\":\n",
    "            attn_weights = F.softmax(self.attn(torch.cat((output[0],hidden[0][0]),1)),dim=1)\n",
    "        else:\n",
    "            attn_weights = F.softmax(self.attn(torch.cat((output[0],hidden[0]),1)),dim=1)\n",
    "\n",
    "        attn_applied = torch.bmm(attn_weights.unsqueeze(1),encoder_outputs.permute(1,0,2))\n",
    "        attn_applied = attn_applied.squeeze(1)\n",
    "        print(\"attention applied shape\",attn_applied.shape)\n",
    "        output = torch.cat((output[0],attn_applied),1)\n",
    "        output = self.attn_combine(output).unsqueeze(0)\n",
    "        output = F.relu(output)\n",
    "        if self.cell_type == \"LSTM\":\n",
    "            output,(hidden,cell) = self.rnn(output,(hidden[0],hidden[1]))\n",
    "            return self.out(output[0]),hidden,cell,attn_weights\n",
    "        else:\n",
    "            output,hidden = self.rnn(output,hidden)\n",
    "            return self.out(output[0]),hidden,attn_weights  \n",
    "        \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "class Seq2Seq(nn.Module):\n",
    "    def __init__(self, encoder, decoder, device, teacher_forcing_ratio=0.5):\n",
    "        super().__init__()\n",
    "        self.encoder = encoder\n",
    "        self.decoder = decoder\n",
    "        self.device = device\n",
    "        self.teacher_forcing_ratio = teacher_forcing_ratio\n",
    "\n",
    "    def forward(self, src, trg):\n",
    "        batch_size = trg.shape[1]\n",
    "        trg_len = trg.shape[0]\n",
    "        trg_vocab_size = self.decoder.output_size\n",
    "        outputs = torch.zeros(trg_len, batch_size, trg_vocab_size).to(self.device)\n",
    "        encoder_hidden = self.encoder.initHidden()\n",
    "        # encoder_hidden = self.encoder.initHidden()\n",
    "        if self.encoder.cell_type == 'LSTM':\n",
    "            encoder_output, encoder_hidden, encoder_cell = self.encoder(src,encoder_hidden)\n",
    "        else:\n",
    "            encoder_output, encoder_hidden = self.encoder(src,encoder_hidden)\n",
    "        input_decoder = trg[0, :]\n",
    "        decoder_hidden = encoder_hidden\n",
    "\n",
    "        if self.decoder.cell_type == 'LSTM':\n",
    "            decoder_cell = encoder_cell\n",
    "\n",
    "        \n",
    "        for t in range(1, trg_len):\n",
    "            if self.decoder.cell_type == 'LSTM':\n",
    "                decoder_output, decoder_hidden, decoder_cell,attn_weights = self.decoder(input_decoder,( decoder_hidden, decoder_cell),encoder_output)\n",
    "\n",
    "            else:\n",
    "                decoder_output, decoder_hidden, attn_weights = self.decoder(input_decoder, decoder_hidden,encoder_output)\n",
    "            print(\"attention_weights\",attn_weights)\n",
    "            outputs[t] = decoder_output\n",
    "            teacher_force = random.random() < self.teacher_forcing_ratio\n",
    "            top1 = decoder_output.argmax(1)\n",
    "            input_decoder = trg[t] if teacher_force else top1\n",
    "        \n",
    "        return outputs,attn_weights\n",
    "\n",
    "\n",
    "def get_accuracy(preds, target):\n",
    "    \"\"\"\n",
    "    Returns accuracy per batch, i.e. if you get 8/10 right, this returns 0.8, NOT 8\n",
    "    \"\"\"\n",
    "    preds = preds.argmax(dim=2)\n",
    "    preds = preds[1:]\n",
    "    target = target[1:]\n",
    "    matches = torch.eq(preds, target)\n",
    "    columns_matches = torch.sum(matches, dim=0)\n",
    "    num_matching_columns = torch.sum(columns_matches == target.shape[0])\n",
    "    acc = num_matching_columns / target.shape[1]\n",
    "    return acc.item()\n",
    "\n",
    "\n",
    "def train(model, iterator, optimizer, criterion, clip):\n",
    "    model.train()\n",
    "    epoch_loss = 0\n",
    "    epoch_acc = 0\n",
    "    pbar = tqdm(iterator, desc=\"Training\", position=0, leave=True)\n",
    "    \n",
    "    for i, (data, target) in enumerate(pbar):\n",
    "        src = data.to(device)\n",
    "        trg = target.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        output,attn_weights = model(src, trg)\n",
    "        print(\"attention weights\", attn_weights)\n",
    "        print(\"attention weights shape\", attn_weights.shape)\n",
    "        attn_weightscpu = attn_weights.cpu().detach().numpy()\n",
    "        sns.heatmap(attn_weightscpu, cmap=\"YlGnBu\", annot=False,fmt='.2f')\n",
    "        plt.show()\n",
    "        output_dim = output.shape[-1]\n",
    "        output_reshaped = output[1:].reshape(-1, output_dim)\n",
    "        trg_reshaped = trg[1:].reshape(-1)\n",
    "        loss = criterion(output_reshaped, trg_reshaped)\n",
    "        loss.backward()\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), clip)\n",
    "        optimizer.step()\n",
    "        acc = get_accuracy(output, trg)\n",
    "        epoch_acc += acc\n",
    "        epoch_loss += loss.item()\n",
    "        pbar.set_postfix(train_loss=epoch_loss / (i + 1), train_acc=epoch_acc / (i + 1))\n",
    "        if True:\n",
    "            break\n",
    "    return epoch_loss / len(iterator), epoch_acc / len(iterator)\n",
    "\n",
    "\n",
    "def evaluate(model, iterator, criterion):\n",
    "    model.eval()\n",
    "    epoch_loss = 0\n",
    "    epoch_acc = 0\n",
    "    # with torch.no_grad():\n",
    "    for i, (data, target) in enumerate(iterator):\n",
    "        src = data.to(device)\n",
    "        trg = target.to(device)\n",
    "        output = model(src, trg)\n",
    "        output_dim = output.shape[-1]\n",
    "        output_reshaped = output[1:].reshape(-1, output_dim)\n",
    "        trg_reshaped = trg[1:].reshape(-1)\n",
    "        loss = criterion(output_reshaped, trg_reshaped)\n",
    "        acc = get_accuracy(output, trg)\n",
    "        epoch_acc += acc\n",
    "        epoch_loss += loss.item()\n",
    "    return epoch_loss / len(iterator), epoch_acc / len(iterator)\n",
    "\n",
    "\n",
    "def predict(model, input_word, actual_output):\n",
    "    data_pred = [[input_word, actual_output]]\n",
    "    data_batch = DataLoader(data_pred, batch_size=BATCH_SIZE, shuffle=False, collate_fn=generate_batch)\n",
    "    iterator = data_batch\n",
    "\n",
    "    src = data\n",
    "    trg = target\n",
    "    output = model(src, trg, 0)\n",
    "    output_dim = output.shape[-1]\n",
    "    # output_reshaped = output[1:].reshape(-1, output_dim)\n",
    "    # trg_reshaped = trg[1:].reshape(-1)\n",
    "    preds = output.argmax(dim=2)\n",
    "    print(\"input word\", input_word)\n",
    "    print(\"actual word\", actual_output)\n",
    "    predicted_word = \"\"\n",
    "    for i in preds:\n",
    "        if i.item() in [0, 1, 2]:\n",
    "            continue\n",
    "        predicted_word += predicted_word + OUTPUT_INDEX_CHAR[i.item()]\n",
    "    print(\"predicted word\", predicted_word)\n",
    "    return preds\n",
    "\n",
    "\n",
    "N_EPOCHS = 10\n",
    "CLIP = 1\n",
    "INPUT_DIM = input_vocab_size\n",
    "OUTPUT_DIM = output_vocab_size\n",
    "ENC_EMB_DIM = 128\n",
    "DEC_EMB_DIM = 128\n",
    "HIDDEN_SIZE = 256\n",
    "num_layers = 1\n",
    "ENC_DROPOUT = 0.5\n",
    "DEC_DROPOUT = 0.5\n",
    "TEACHER_FORCING = 0.5\n",
    "BI_DIRECTION = True\n",
    "CELL_TYPE = 'LSTM'\n",
    "pred_src = \"$bindya|\"\n",
    "pred_trg = '$बिन्द्या|'\n",
    "BATCH_SIZE = 1\n",
    "enc = Encoder(input_size=INPUT_DIM, embedding_size=ENC_EMB_DIM, hidden_size=HIDDEN_SIZE, num_layers=num_layers,\n",
    "              dropout=ENC_DROPOUT, cell_type=CELL_TYPE, bidirectional=BI_DIRECTION)\n",
    "dec = Decoder_with_attention(output_size=OUTPUT_DIM, embedding_size=DEC_EMB_DIM, hidden_size=HIDDEN_SIZE, num_layers=num_layers,\n",
    "              dropout=DEC_DROPOUT, cell_type=CELL_TYPE,batch_size=BATCH_SIZE)\n",
    "\n",
    "model = Seq2Seq(enc, dec, device, teacher_forcing_ratio=TEACHER_FORCING).to(device)\n",
    "\n",
    "\n",
    "def init_weights(m):\n",
    "    for name, param in m.named_parameters():\n",
    "        nn.init.uniform_(param.data, -0.08, 0.08)\n",
    "\n",
    "\n",
    "model.apply(init_weights)\n",
    "optimizer = optim.Adam(model.parameters())\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "train_dataloader = DataLoader(train_data, batch_size=BATCH_SIZE, shuffle=True, collate_fn=generate_batch)\n",
    "valid_dataloader = DataLoader(valid_data, batch_size=BATCH_SIZE, shuffle=True, collate_fn=generate_batch)\n",
    "best_valid_loss = float('inf')\n",
    "gbar = tqdm(range(1, N_EPOCHS + 1), position=1, leave=True, desc='Epochs', total=N_EPOCHS)\n",
    "for epoch in gbar:\n",
    "    train_loss, train_accuracy = train(model, train_dataloader, optimizer, criterion, CLIP)\n",
    "    valid_loss, valid_accuracy = evaluate(model, valid_dataloader, criterion)\n",
    "    gbar.set_postfix(train_loss=train_loss, train_acc=train_accuracy, val_loss=valid_loss, val_acc=valid_accuracy)\n",
    "\n",
    "predict(model, pred_src, pred_trg)\n",
    "# predict(model,\"$बिन्द्या|\",\"$bindya|\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25\n"
     ]
    }
   ],
   "source": [
    "print(MAX_LENGTH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "sweep_config = {\n",
    "  \"name\": \"CS6910 Assignment 3\",\n",
    "  \"metric\": {\n",
    "      \"name\":\"validation_accuracy\",\n",
    "      \"goal\": \"maximize\"\n",
    "  },\n",
    "  \"method\": \"bayes\",\n",
    "  \"parameters\": {\n",
    "        \n",
    "        \"cell_type\": {\n",
    "            \"values\": [\"LSTM\",\"GRU\"]\n",
    "        },\n",
    "        \"bidirectional\": {\n",
    "            \"values\": [True, False]\n",
    "        },\n",
    "        \"num_epochs\": {\n",
    "            \"values\": [20,25]\n",
    "        },\n",
    "        \"num_layers\": {\n",
    "            \"values\": [1, 2, 3]\n",
    "        },\n",
    "        \"batch_size\": {\n",
    "            \"values\": [32,64,128]\n",
    "        },\n",
    "        \"embedding_size\": {\n",
    "            \"values\": [128, 256, 512]\n",
    "        },\n",
    "        \"hidden_size\": {\n",
    "            \"values\": [128, 256, 512]\n",
    "        },\n",
    "        \"learning_rate\": {\n",
    "            \"values\": [0.001,0.0001]\n",
    "        },\n",
    "        \"enc_dropout\": {\n",
    "            \"values\": [0.2,0.3,0.5]\n",
    "        },\n",
    "        \"dec_dropout\": {\n",
    "            \"values\": [0.2,0.3,0.5]\n",
    "        }\n",
    "    }\n",
    "}\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_train(INPUT_DIM, OUTPUT_DIM, EMBEDDING_SIZE, HIDDEN_SIZE, NUM_LAYERS, ENC_DROPOUT, DEC_DROPOUT,  BIDIRECTIONAL, CELL_TYPE, LEARNING_RATE, N_EPOCHS, CLIP,BATCH_SIZE):\n",
    "    train_dataloader = DataLoader(train_data, batch_size=BATCH_SIZE, shuffle=True, collate_fn=generate_batch)\n",
    "    valid_dataloader = DataLoader(valid_data, batch_size=BATCH_SIZE, shuffle=True, collate_fn=generate_batch)\n",
    "    encoder = Encoder(input_size=INPUT_DIM, embedding_size=EMBEDDING_SIZE, hidden_size=HIDDEN_SIZE, num_layers=NUM_LAYERS, dropout=ENC_DROPOUT, bidirectional=BIDIRECTIONAL, cell_type=CELL_TYPE)\n",
    "    decoder = Decoder(output_dim=OUTPUT_DIM, emb_dim=EMBEDDING_SIZE, hidden_size=HIDDEN_SIZE, num_layers=NUM_LAYERS, dropout=DEC_DROPOUT, cell_type=CELL_TYPE)\n",
    "    model = Seq2Seq(encoder, decoder, device).to(device)\n",
    "    optimizer = optim.Adam(model.parameters(), lr=LEARNING_RATE)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    # pbar = tqdm(range(N_EPOCHS), desc=\"Epochs\",position=0, leave=True)\n",
    "    gbar = tqdm(range(1, N_EPOCHS + 1),position=1,leave=True, desc='Epochs', total=N_EPOCHS)\n",
    "#     gbar = N_EPOCHS\n",
    "    for epoch in gbar:\n",
    "\n",
    "        train_loss, train_acc = train(model, train_dataloader, optimizer, criterion, clip=CLIP)\n",
    "        # print(run_name)\n",
    "        valid_loss, valid_acc = evaluate(model,valid_dataloader, criterion)\n",
    "        print(\"Epoch: \",epoch)\n",
    "        print(f'\\tTrain Loss: {train_loss:.3f} | Train Acc: {train_acc * 100:.2f}%')\n",
    "        print(f'\\t Val. Loss: {valid_loss:.3f} |  Val. Acc: {valid_acc * 100:.2f}%')\n",
    "        wandb.log({\"train_loss\": train_loss, \"train_acc\": train_acc, \"valid_loss\": valid_loss, \"valid_acc\": valid_acc})\n",
    "        gbar.set_postfix(train_loss=train_loss, train_acc=train_acc, valid_loss=valid_loss, valid_acc=valid_acc)\n",
    "    return valid_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_wandb():\n",
    "    wandb.init()\n",
    "    config = wandb.config\n",
    "    LEARNING_RATE = config.learning_rate\n",
    "    BATCH_SIZE = config.batch_size\n",
    "    EMBEDDING_SIZE = config.embedding_size\n",
    "    HIDDEN_SIZE = config.hidden_size\n",
    "    ENC_DROPOUT = config.enc_dropout\n",
    "    DEC_DROPOUT = config.dec_dropout\n",
    "    NUM_LAYERS = config.num_layers\n",
    "    BIDIRECTIONAL = config.bidirectional\n",
    "    CELL_TYPE = config.cell_type\n",
    "    N_EPOCHS = config.num_epochs\n",
    "    CLIP = 1\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    INPUT_DIM = len(INPUT_CHAR_INDX)\n",
    "    OUTPUT_DIM = len(OUTPUT_CHAR_INDEX)\n",
    "    model_train(INPUT_DIM=INPUT_DIM, OUTPUT_DIM=OUTPUT_DIM, EMBEDDING_SIZE=EMBEDDING_SIZE, HIDDEN_SIZE=HIDDEN_SIZE, NUM_LAYERS=NUM_LAYERS, ENC_DROPOUT=ENC_DROPOUT,DEC_DROPOUT=DEC_DROPOUT, BIDIRECTIONAL=BIDIRECTIONAL, CELL_TYPE=CELL_TYPE, LEARNING_RATE=LEARNING_RATE, N_EPOCHS=N_EPOCHS, CLIP=CLIP,BATCH_SIZE=BATCH_SIZE)\n",
    "    # best_valid_loss = float('inf')\n",
    "    print(\"cell_type\",CELL_TYPE,\"bidirectional\",BIDIRECTIONAL,\"num_layers\",NUM_LAYERS,\"batch_size\",BATCH_SIZE,\"embedding_size\",EMBEDDING_SIZE,\"hidden_size\",HIDDEN_SIZE,\"enc_dropout\",ENC_DROPOUT,\"dec_dropout\",DEC_DROPOUT,\"num_epochs\",N_EPOCHS)\n",
    "    run_name = \"ct_{}_bi_{}_nl_{}_bs_{}_es_{}_hs_{}_endo_{}_decdo_{}_ne_{}\".format(CELL_TYPE,BIDIRECTIONAL,NUM_LAYERS,BATCH_SIZE,EMBEDDING_SIZE,HIDDEN_SIZE,ENC_DROPOUT,DEC_DROPOUT,N_EPOCHS)\n",
    "    print(run_name)\n",
    "    wandb.run.name = run_name\n",
    "    wandb.run.save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # wandb.init()\n",
    "# config=wandb.config\n",
    "# LEARNING_RATE = 0.001\n",
    "# BATCH_SIZE = 32\n",
    "# EMBEDDING_SIZE = 128\n",
    "# HIDDEN_SIZE = 512\n",
    "# ENC_DROPOUT = 0.2\n",
    "# DEC_DROPOUT = 0.2\n",
    "# NUM_LAYERS = 2\n",
    "# BIDIRECTIONAL = True\n",
    "# CELL_TYPE = 'LSTM'\n",
    "# N_EPOCHS = 1\n",
    "# CLIP = 1\n",
    "# device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "# train_dataloader = DataLoader(train_data, batch_size=BATCH_SIZE, shuffle=True, collate_fn=generate_batch)\n",
    "# valid_dataloader = DataLoader(valid_data, batch_size=BATCH_SIZE, shuffle=False,     collate_fn=generate_batch)\n",
    "# INPUT_DIM = len(INPUT_CHAR_INDX)\n",
    "# OUTPUT_DIM = len(OUTPUT_CHAR_INDEX)\n",
    "# model_train(INPUT_DIM=INPUT_DIM, OUTPUT_DIM=OUTPUT_DIM, EMBEDDING_SIZE=EMBEDDING_SIZE, HIDDEN_SIZE=HIDDEN_SIZE, NUM_LAYERS=NUM_LAYERS, ENC_DROPOUT=ENC_DROPOUT,DEC_DROPOUT=DEC_DROPOUT, BIDIRECTIONAL=BIDIRECTIONAL, CELL_TYPE=CELL_TYPE, LEARNING_RATE=LEARNING_RATE, N_EPOCHS=N_EPOCHS, CLIP=CLIP,BATCH_SIZE=BATCH_SIZE)\n",
    "# # best_valid_loss = float('inf')\n",
    "# # run_name = \"ct_{}_bi_{}_nl_{}_bs_{}_es_{}_hs_{}_do_{}_ne{}\".format(CELL_TYPE,BIDIRECTIONAL,NUM_LAYERS,BATCH_SIZE,EMBEDDING_SIZE,HIDDEN_SIZE,DROPOUT,N_EPOCHS)\n",
    "# # print(run_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[34m\u001B[1mwandb\u001B[0m: \u001B[33mWARNING\u001B[0m Calling wandb.login() after wandb.init() has no effect.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Create sweep with ID: x2ojhehe\n",
      "Sweep URL: https://wandb.ai/cs22m045/DL_ASSIGNMENT_3/sweeps/x2ojhehe\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "wandb: Waiting for W&B process to finish... (success).\n",
      "wandb: 🚀 View run graceful-meadow-11 at: https://wandb.ai/cs22m045/DL_ASSIGNMENT_3/runs/n92g2j3z\n",
      "wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\n",
      "wandb: Find logs at: ./wandb/run-20230516_071553-n92g2j3z/logs\n",
      "\u001B[34m\u001B[1mwandb\u001B[0m: Agent Starting Run: as4hm8y3 with config:\n",
      "\u001B[34m\u001B[1mwandb\u001B[0m: \tbatch_size: 64\n",
      "\u001B[34m\u001B[1mwandb\u001B[0m: \tbidirectional: False\n",
      "\u001B[34m\u001B[1mwandb\u001B[0m: \tcell_type: LSTM\n",
      "\u001B[34m\u001B[1mwandb\u001B[0m: \tdec_dropout: 0.5\n",
      "\u001B[34m\u001B[1mwandb\u001B[0m: \tembedding_size: 128\n",
      "\u001B[34m\u001B[1mwandb\u001B[0m: \tenc_dropout: 0.5\n",
      "\u001B[34m\u001B[1mwandb\u001B[0m: \thidden_size: 128\n",
      "\u001B[34m\u001B[1mwandb\u001B[0m: \tlearning_rate: 0.001\n",
      "\u001B[34m\u001B[1mwandb\u001B[0m: \tnum_epochs: 15\n",
      "\u001B[34m\u001B[1mwandb\u001B[0m: \tnum_layers: 1\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.15.2 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.15.0"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/kaggle/working/wandb/run-20230516_071700-as4hm8y3</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/cs22m045/DL_ASSIGNMENT_3/runs/as4hm8y3' target=\"_blank\">ancient-sweep-1</a></strong> to <a href='https://wandb.ai/cs22m045/DL_ASSIGNMENT_3' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/cs22m045/DL_ASSIGNMENT_3/sweeps/x2ojhehe' target=\"_blank\">https://wandb.ai/cs22m045/DL_ASSIGNMENT_3/sweeps/x2ojhehe</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/cs22m045/DL_ASSIGNMENT_3' target=\"_blank\">https://wandb.ai/cs22m045/DL_ASSIGNMENT_3</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/cs22m045/DL_ASSIGNMENT_3/sweeps/x2ojhehe' target=\"_blank\">https://wandb.ai/cs22m045/DL_ASSIGNMENT_3/sweeps/x2ojhehe</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/cs22m045/DL_ASSIGNMENT_3/runs/as4hm8y3' target=\"_blank\">https://wandb.ai/cs22m045/DL_ASSIGNMENT_3/runs/as4hm8y3</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/torch/nn/modules/rnn.py:71: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.5 and num_layers=1\n",
      "  warnings.warn(\"dropout option adds dropout after all but last \"\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b6a1fbe9a205471389e359110fd20e24",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epochs:   0%|          | 0/15 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d96f4a7a3f624af8a825d2e9c6153c55",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training:   0%|          | 0/800 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tTrain Loss: 1.267 | Train Acc: 0.00%\n",
      "\t Val. Loss: 0.873 |  Val. Acc: 0.02%\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ca39fbafe6e74335b53a23abcc5d3cf8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training:   0%|          | 0/800 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tTrain Loss: 1.013 | Train Acc: 0.03%\n",
      "\t Val. Loss: 0.723 |  Val. Acc: 0.59%\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d3ab165077704e11a38edd04295b835b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training:   0%|          | 0/800 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tTrain Loss: 0.849 | Train Acc: 0.22%\n",
      "\t Val. Loss: 0.576 |  Val. Acc: 1.98%\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "562c24c7b15249448a6fd0aa18ba4289",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training:   0%|          | 0/800 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tTrain Loss: 0.715 | Train Acc: 1.16%\n",
      "\t Val. Loss: 0.475 |  Val. Acc: 5.27%\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "505ea329bb524997a908ae0dcc0c8028",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training:   0%|          | 0/800 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tTrain Loss: 0.613 | Train Acc: 2.88%\n",
      "\t Val. Loss: 0.412 |  Val. Acc: 8.96%\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4a56d067e7d84ad9ada21e788644e3b9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training:   0%|          | 0/800 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tTrain Loss: 0.550 | Train Acc: 4.52%\n",
      "\t Val. Loss: 0.381 |  Val. Acc: 11.43%\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "67c2613fc7e5498e8783ad34f1f0b1d4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training:   0%|          | 0/800 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tTrain Loss: 0.503 | Train Acc: 6.20%\n",
      "\t Val. Loss: 0.361 |  Val. Acc: 14.29%\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0c39ed978a05414787bd6bccfbcfa19d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training:   0%|          | 0/800 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tTrain Loss: 0.470 | Train Acc: 7.91%\n",
      "\t Val. Loss: 0.349 |  Val. Acc: 15.04%\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "93b0c550caf244febf98c24a15e85ec7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training:   0%|          | 0/800 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tTrain Loss: 0.445 | Train Acc: 9.28%\n",
      "\t Val. Loss: 0.328 |  Val. Acc: 17.04%\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5f8b84438c8e464a8befdae8b9befe85",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training:   0%|          | 0/800 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tTrain Loss: 0.424 | Train Acc: 10.36%\n",
      "\t Val. Loss: 0.314 |  Val. Acc: 17.68%\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "500ba7fd891d4a99ae35f81662540603",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training:   0%|          | 0/800 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tTrain Loss: 0.406 | Train Acc: 11.70%\n",
      "\t Val. Loss: 0.306 |  Val. Acc: 18.61%\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e2ce3ad49b0d493abfd468609722c0d8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training:   0%|          | 0/800 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tTrain Loss: 0.392 | Train Acc: 12.78%\n",
      "\t Val. Loss: 0.292 |  Val. Acc: 20.49%\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "830e813b336f48d08211fac6f5140ce0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training:   0%|          | 0/800 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tTrain Loss: 0.379 | Train Acc: 13.79%\n",
      "\t Val. Loss: 0.288 |  Val. Acc: 20.17%\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e2728e1e89044370b0e24ff46155563d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training:   0%|          | 0/800 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tTrain Loss: 0.369 | Train Acc: 14.61%\n",
      "\t Val. Loss: 0.282 |  Val. Acc: 20.98%\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7c36eff75eb34974aecb4efc875c2b61",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training:   0%|          | 0/800 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[34m\u001B[1mwandb\u001B[0m: \u001B[33mWARNING\u001B[0m Calling wandb.run.save without any arguments is deprecated.Changes to attributes are automatically persisted.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tTrain Loss: 0.361 | Train Acc: 15.59%\n",
      "\t Val. Loss: 0.277 |  Val. Acc: 21.90%\n",
      "ct_LSTM_bi_False_nl_1_bs_64_es_128_hs_128_endo_0.5_decdo_0.5_ne_15\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>train_acc</td><td>▁▁▁▂▂▃▄▅▅▆▆▇▇██</td></tr><tr><td>train_loss</td><td>█▆▅▄▃▂▂▂▂▁▁▁▁▁▁</td></tr><tr><td>valid_acc</td><td>▁▁▂▃▄▅▆▆▆▇▇█▇██</td></tr><tr><td>valid_loss</td><td>█▆▅▃▃▂▂▂▂▁▁▁▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>train_acc</td><td>0.15588</td></tr><tr><td>train_loss</td><td>0.36053</td></tr><tr><td>valid_acc</td><td>0.21904</td></tr><tr><td>valid_loss</td><td>0.27669</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">ancient-sweep-1</strong> at: <a href='https://wandb.ai/cs22m045/DL_ASSIGNMENT_3/runs/as4hm8y3' target=\"_blank\">https://wandb.ai/cs22m045/DL_ASSIGNMENT_3/runs/as4hm8y3</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20230516_071700-as4hm8y3/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error in callback <function _WandbInit._pause_backend at 0x786e3559fe20> (for post_run_cell):\n"
     ]
    },
    {
     "ename": "BrokenPipeError",
     "evalue": "[Errno 32] Broken pipe",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m\n",
      "\u001B[0;31mBrokenPipeError\u001B[0m                           Traceback (most recent call last)\n",
      "File \u001B[0;32m/opt/conda/lib/python3.10/site-packages/backcall/backcall.py:104\u001B[0m, in \u001B[0;36mcallback_prototype.<locals>.adapt.<locals>.adapted\u001B[0;34m(*args, **kwargs)\u001B[0m\n",
      "\u001B[1;32m    102\u001B[0m                 kwargs\u001B[38;5;241m.\u001B[39mpop(name)\n",
      "\u001B[1;32m    103\u001B[0m \u001B[38;5;66;03m#            print(args, kwargs, unmatched_pos, cut_positional, unmatched_kw)\u001B[39;00m\n",
      "\u001B[0;32m--> 104\u001B[0m             \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mcallback\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "\n",
      "File \u001B[0;32m/opt/conda/lib/python3.10/site-packages/wandb/sdk/wandb_init.py:419\u001B[0m, in \u001B[0;36m_WandbInit._pause_backend\u001B[0;34m(self)\u001B[0m\n",
      "\u001B[1;32m    417\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mbackend\u001B[38;5;241m.\u001B[39minterface \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n",
      "\u001B[1;32m    418\u001B[0m     logger\u001B[38;5;241m.\u001B[39minfo(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mpausing backend\u001B[39m\u001B[38;5;124m\"\u001B[39m)  \u001B[38;5;66;03m# type: ignore\u001B[39;00m\n",
      "\u001B[0;32m--> 419\u001B[0m     \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mbackend\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43minterface\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mpublish_pause\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n",
      "\n",
      "File \u001B[0;32m/opt/conda/lib/python3.10/site-packages/wandb/sdk/interface/interface.py:665\u001B[0m, in \u001B[0;36mInterfaceBase.publish_pause\u001B[0;34m(self)\u001B[0m\n",
      "\u001B[1;32m    663\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mpublish_pause\u001B[39m(\u001B[38;5;28mself\u001B[39m) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m:\n",
      "\u001B[1;32m    664\u001B[0m     pause \u001B[38;5;241m=\u001B[39m pb\u001B[38;5;241m.\u001B[39mPauseRequest()\n",
      "\u001B[0;32m--> 665\u001B[0m     \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_publish_pause\u001B[49m\u001B[43m(\u001B[49m\u001B[43mpause\u001B[49m\u001B[43m)\u001B[49m\n",
      "\n",
      "File \u001B[0;32m/opt/conda/lib/python3.10/site-packages/wandb/sdk/interface/interface_shared.py:340\u001B[0m, in \u001B[0;36mInterfaceShared._publish_pause\u001B[0;34m(self, pause)\u001B[0m\n",
      "\u001B[1;32m    338\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m_publish_pause\u001B[39m(\u001B[38;5;28mself\u001B[39m, pause: pb\u001B[38;5;241m.\u001B[39mPauseRequest) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m:\n",
      "\u001B[1;32m    339\u001B[0m     rec \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_make_request(pause\u001B[38;5;241m=\u001B[39mpause)\n",
      "\u001B[0;32m--> 340\u001B[0m     \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_publish\u001B[49m\u001B[43m(\u001B[49m\u001B[43mrec\u001B[49m\u001B[43m)\u001B[49m\n",
      "\n",
      "File \u001B[0;32m/opt/conda/lib/python3.10/site-packages/wandb/sdk/interface/interface_sock.py:51\u001B[0m, in \u001B[0;36mInterfaceSock._publish\u001B[0;34m(self, record, local)\u001B[0m\n",
      "\u001B[1;32m     49\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m_publish\u001B[39m(\u001B[38;5;28mself\u001B[39m, record: \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mpb.Record\u001B[39m\u001B[38;5;124m\"\u001B[39m, local: Optional[\u001B[38;5;28mbool\u001B[39m] \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m:\n",
      "\u001B[1;32m     50\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_assign(record)\n",
      "\u001B[0;32m---> 51\u001B[0m     \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_sock_client\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43msend_record_publish\u001B[49m\u001B[43m(\u001B[49m\u001B[43mrecord\u001B[49m\u001B[43m)\u001B[49m\n",
      "\n",
      "File \u001B[0;32m/opt/conda/lib/python3.10/site-packages/wandb/sdk/lib/sock_client.py:221\u001B[0m, in \u001B[0;36mSockClient.send_record_publish\u001B[0;34m(self, record)\u001B[0m\n",
      "\u001B[1;32m    219\u001B[0m server_req \u001B[38;5;241m=\u001B[39m spb\u001B[38;5;241m.\u001B[39mServerRequest()\n",
      "\u001B[1;32m    220\u001B[0m server_req\u001B[38;5;241m.\u001B[39mrecord_publish\u001B[38;5;241m.\u001B[39mCopyFrom(record)\n",
      "\u001B[0;32m--> 221\u001B[0m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43msend_server_request\u001B[49m\u001B[43m(\u001B[49m\u001B[43mserver_req\u001B[49m\u001B[43m)\u001B[49m\n",
      "\n",
      "File \u001B[0;32m/opt/conda/lib/python3.10/site-packages/wandb/sdk/lib/sock_client.py:155\u001B[0m, in \u001B[0;36mSockClient.send_server_request\u001B[0;34m(self, msg)\u001B[0m\n",
      "\u001B[1;32m    154\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21msend_server_request\u001B[39m(\u001B[38;5;28mself\u001B[39m, msg: Any) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m:\n",
      "\u001B[0;32m--> 155\u001B[0m     \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_send_message\u001B[49m\u001B[43m(\u001B[49m\u001B[43mmsg\u001B[49m\u001B[43m)\u001B[49m\n",
      "\n",
      "File \u001B[0;32m/opt/conda/lib/python3.10/site-packages/wandb/sdk/lib/sock_client.py:152\u001B[0m, in \u001B[0;36mSockClient._send_message\u001B[0;34m(self, msg)\u001B[0m\n",
      "\u001B[1;32m    150\u001B[0m header \u001B[38;5;241m=\u001B[39m struct\u001B[38;5;241m.\u001B[39mpack(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m<BI\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;28mord\u001B[39m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mW\u001B[39m\u001B[38;5;124m\"\u001B[39m), raw_size)\n",
      "\u001B[1;32m    151\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_lock:\n",
      "\u001B[0;32m--> 152\u001B[0m     \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_sendall_with_error_handle\u001B[49m\u001B[43m(\u001B[49m\u001B[43mheader\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m+\u001B[39;49m\u001B[43m \u001B[49m\u001B[43mdata\u001B[49m\u001B[43m)\u001B[49m\n",
      "\n",
      "File \u001B[0;32m/opt/conda/lib/python3.10/site-packages/wandb/sdk/lib/sock_client.py:130\u001B[0m, in \u001B[0;36mSockClient._sendall_with_error_handle\u001B[0;34m(self, data)\u001B[0m\n",
      "\u001B[1;32m    128\u001B[0m start_time \u001B[38;5;241m=\u001B[39m time\u001B[38;5;241m.\u001B[39mmonotonic()\n",
      "\u001B[1;32m    129\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n",
      "\u001B[0;32m--> 130\u001B[0m     sent \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_sock\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43msend\u001B[49m\u001B[43m(\u001B[49m\u001B[43mdata\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[1;32m    131\u001B[0m     \u001B[38;5;66;03m# sent equal to 0 indicates a closed socket\u001B[39;00m\n",
      "\u001B[1;32m    132\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m sent \u001B[38;5;241m==\u001B[39m \u001B[38;5;241m0\u001B[39m:\n",
      "\n",
      "\u001B[0;31mBrokenPipeError\u001B[0m: [Errno 32] Broken pipe"
     ]
    }
   ],
   "source": [
    "sweep_id = wandb.sweep(sweep_config, entity=\"cs22m045\", project=\"DL_ASSIGNMENT_3\")\n",
    "wandb.agent(sweep_id,run_wandb, count=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error in callback <function _WandbInit._resume_backend at 0x786e3559fd90> (for pre_run_cell):\n"
     ]
    },
    {
     "ename": "BrokenPipeError",
     "evalue": "[Errno 32] Broken pipe",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m\n",
      "\u001B[0;31mBrokenPipeError\u001B[0m                           Traceback (most recent call last)\n",
      "File \u001B[0;32m/opt/conda/lib/python3.10/site-packages/backcall/backcall.py:104\u001B[0m, in \u001B[0;36mcallback_prototype.<locals>.adapt.<locals>.adapted\u001B[0;34m(*args, **kwargs)\u001B[0m\n",
      "\u001B[1;32m    102\u001B[0m                 kwargs\u001B[38;5;241m.\u001B[39mpop(name)\n",
      "\u001B[1;32m    103\u001B[0m \u001B[38;5;66;03m#            print(args, kwargs, unmatched_pos, cut_positional, unmatched_kw)\u001B[39;00m\n",
      "\u001B[0;32m--> 104\u001B[0m             \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mcallback\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "\n",
      "File \u001B[0;32m/opt/conda/lib/python3.10/site-packages/wandb/sdk/wandb_init.py:424\u001B[0m, in \u001B[0;36m_WandbInit._resume_backend\u001B[0;34m(self)\u001B[0m\n",
      "\u001B[1;32m    422\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mbackend \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mbackend\u001B[38;5;241m.\u001B[39minterface \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n",
      "\u001B[1;32m    423\u001B[0m     logger\u001B[38;5;241m.\u001B[39minfo(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mresuming backend\u001B[39m\u001B[38;5;124m\"\u001B[39m)  \u001B[38;5;66;03m# type: ignore\u001B[39;00m\n",
      "\u001B[0;32m--> 424\u001B[0m     \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mbackend\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43minterface\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mpublish_resume\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n",
      "\n",
      "File \u001B[0;32m/opt/conda/lib/python3.10/site-packages/wandb/sdk/interface/interface.py:673\u001B[0m, in \u001B[0;36mInterfaceBase.publish_resume\u001B[0;34m(self)\u001B[0m\n",
      "\u001B[1;32m    671\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mpublish_resume\u001B[39m(\u001B[38;5;28mself\u001B[39m) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m:\n",
      "\u001B[1;32m    672\u001B[0m     resume \u001B[38;5;241m=\u001B[39m pb\u001B[38;5;241m.\u001B[39mResumeRequest()\n",
      "\u001B[0;32m--> 673\u001B[0m     \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_publish_resume\u001B[49m\u001B[43m(\u001B[49m\u001B[43mresume\u001B[49m\u001B[43m)\u001B[49m\n",
      "\n",
      "File \u001B[0;32m/opt/conda/lib/python3.10/site-packages/wandb/sdk/interface/interface_shared.py:344\u001B[0m, in \u001B[0;36mInterfaceShared._publish_resume\u001B[0;34m(self, resume)\u001B[0m\n",
      "\u001B[1;32m    342\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m_publish_resume\u001B[39m(\u001B[38;5;28mself\u001B[39m, resume: pb\u001B[38;5;241m.\u001B[39mResumeRequest) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m:\n",
      "\u001B[1;32m    343\u001B[0m     rec \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_make_request(resume\u001B[38;5;241m=\u001B[39mresume)\n",
      "\u001B[0;32m--> 344\u001B[0m     \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_publish\u001B[49m\u001B[43m(\u001B[49m\u001B[43mrec\u001B[49m\u001B[43m)\u001B[49m\n",
      "\n",
      "File \u001B[0;32m/opt/conda/lib/python3.10/site-packages/wandb/sdk/interface/interface_sock.py:51\u001B[0m, in \u001B[0;36mInterfaceSock._publish\u001B[0;34m(self, record, local)\u001B[0m\n",
      "\u001B[1;32m     49\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m_publish\u001B[39m(\u001B[38;5;28mself\u001B[39m, record: \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mpb.Record\u001B[39m\u001B[38;5;124m\"\u001B[39m, local: Optional[\u001B[38;5;28mbool\u001B[39m] \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m:\n",
      "\u001B[1;32m     50\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_assign(record)\n",
      "\u001B[0;32m---> 51\u001B[0m     \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_sock_client\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43msend_record_publish\u001B[49m\u001B[43m(\u001B[49m\u001B[43mrecord\u001B[49m\u001B[43m)\u001B[49m\n",
      "\n",
      "File \u001B[0;32m/opt/conda/lib/python3.10/site-packages/wandb/sdk/lib/sock_client.py:221\u001B[0m, in \u001B[0;36mSockClient.send_record_publish\u001B[0;34m(self, record)\u001B[0m\n",
      "\u001B[1;32m    219\u001B[0m server_req \u001B[38;5;241m=\u001B[39m spb\u001B[38;5;241m.\u001B[39mServerRequest()\n",
      "\u001B[1;32m    220\u001B[0m server_req\u001B[38;5;241m.\u001B[39mrecord_publish\u001B[38;5;241m.\u001B[39mCopyFrom(record)\n",
      "\u001B[0;32m--> 221\u001B[0m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43msend_server_request\u001B[49m\u001B[43m(\u001B[49m\u001B[43mserver_req\u001B[49m\u001B[43m)\u001B[49m\n",
      "\n",
      "File \u001B[0;32m/opt/conda/lib/python3.10/site-packages/wandb/sdk/lib/sock_client.py:155\u001B[0m, in \u001B[0;36mSockClient.send_server_request\u001B[0;34m(self, msg)\u001B[0m\n",
      "\u001B[1;32m    154\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21msend_server_request\u001B[39m(\u001B[38;5;28mself\u001B[39m, msg: Any) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m:\n",
      "\u001B[0;32m--> 155\u001B[0m     \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_send_message\u001B[49m\u001B[43m(\u001B[49m\u001B[43mmsg\u001B[49m\u001B[43m)\u001B[49m\n",
      "\n",
      "File \u001B[0;32m/opt/conda/lib/python3.10/site-packages/wandb/sdk/lib/sock_client.py:152\u001B[0m, in \u001B[0;36mSockClient._send_message\u001B[0;34m(self, msg)\u001B[0m\n",
      "\u001B[1;32m    150\u001B[0m header \u001B[38;5;241m=\u001B[39m struct\u001B[38;5;241m.\u001B[39mpack(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m<BI\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;28mord\u001B[39m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mW\u001B[39m\u001B[38;5;124m\"\u001B[39m), raw_size)\n",
      "\u001B[1;32m    151\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_lock:\n",
      "\u001B[0;32m--> 152\u001B[0m     \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_sendall_with_error_handle\u001B[49m\u001B[43m(\u001B[49m\u001B[43mheader\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m+\u001B[39;49m\u001B[43m \u001B[49m\u001B[43mdata\u001B[49m\u001B[43m)\u001B[49m\n",
      "\n",
      "File \u001B[0;32m/opt/conda/lib/python3.10/site-packages/wandb/sdk/lib/sock_client.py:130\u001B[0m, in \u001B[0;36mSockClient._sendall_with_error_handle\u001B[0;34m(self, data)\u001B[0m\n",
      "\u001B[1;32m    128\u001B[0m start_time \u001B[38;5;241m=\u001B[39m time\u001B[38;5;241m.\u001B[39mmonotonic()\n",
      "\u001B[1;32m    129\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n",
      "\u001B[0;32m--> 130\u001B[0m     sent \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_sock\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43msend\u001B[49m\u001B[43m(\u001B[49m\u001B[43mdata\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[1;32m    131\u001B[0m     \u001B[38;5;66;03m# sent equal to 0 indicates a closed socket\u001B[39;00m\n",
      "\u001B[1;32m    132\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m sent \u001B[38;5;241m==\u001B[39m \u001B[38;5;241m0\u001B[39m:\n",
      "\n",
      "\u001B[0;31mBrokenPipeError\u001B[0m: [Errno 32] Broken pipe"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error in callback <function _WandbInit._pause_backend at 0x786e3559fe20> (for post_run_cell):\n"
     ]
    },
    {
     "ename": "BrokenPipeError",
     "evalue": "[Errno 32] Broken pipe",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m\n",
      "\u001B[0;31mBrokenPipeError\u001B[0m                           Traceback (most recent call last)\n",
      "File \u001B[0;32m/opt/conda/lib/python3.10/site-packages/backcall/backcall.py:104\u001B[0m, in \u001B[0;36mcallback_prototype.<locals>.adapt.<locals>.adapted\u001B[0;34m(*args, **kwargs)\u001B[0m\n",
      "\u001B[1;32m    102\u001B[0m                 kwargs\u001B[38;5;241m.\u001B[39mpop(name)\n",
      "\u001B[1;32m    103\u001B[0m \u001B[38;5;66;03m#            print(args, kwargs, unmatched_pos, cut_positional, unmatched_kw)\u001B[39;00m\n",
      "\u001B[0;32m--> 104\u001B[0m             \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mcallback\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "\n",
      "File \u001B[0;32m/opt/conda/lib/python3.10/site-packages/wandb/sdk/wandb_init.py:419\u001B[0m, in \u001B[0;36m_WandbInit._pause_backend\u001B[0;34m(self)\u001B[0m\n",
      "\u001B[1;32m    417\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mbackend\u001B[38;5;241m.\u001B[39minterface \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n",
      "\u001B[1;32m    418\u001B[0m     logger\u001B[38;5;241m.\u001B[39minfo(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mpausing backend\u001B[39m\u001B[38;5;124m\"\u001B[39m)  \u001B[38;5;66;03m# type: ignore\u001B[39;00m\n",
      "\u001B[0;32m--> 419\u001B[0m     \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mbackend\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43minterface\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mpublish_pause\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n",
      "\n",
      "File \u001B[0;32m/opt/conda/lib/python3.10/site-packages/wandb/sdk/interface/interface.py:665\u001B[0m, in \u001B[0;36mInterfaceBase.publish_pause\u001B[0;34m(self)\u001B[0m\n",
      "\u001B[1;32m    663\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mpublish_pause\u001B[39m(\u001B[38;5;28mself\u001B[39m) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m:\n",
      "\u001B[1;32m    664\u001B[0m     pause \u001B[38;5;241m=\u001B[39m pb\u001B[38;5;241m.\u001B[39mPauseRequest()\n",
      "\u001B[0;32m--> 665\u001B[0m     \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_publish_pause\u001B[49m\u001B[43m(\u001B[49m\u001B[43mpause\u001B[49m\u001B[43m)\u001B[49m\n",
      "\n",
      "File \u001B[0;32m/opt/conda/lib/python3.10/site-packages/wandb/sdk/interface/interface_shared.py:340\u001B[0m, in \u001B[0;36mInterfaceShared._publish_pause\u001B[0;34m(self, pause)\u001B[0m\n",
      "\u001B[1;32m    338\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m_publish_pause\u001B[39m(\u001B[38;5;28mself\u001B[39m, pause: pb\u001B[38;5;241m.\u001B[39mPauseRequest) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m:\n",
      "\u001B[1;32m    339\u001B[0m     rec \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_make_request(pause\u001B[38;5;241m=\u001B[39mpause)\n",
      "\u001B[0;32m--> 340\u001B[0m     \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_publish\u001B[49m\u001B[43m(\u001B[49m\u001B[43mrec\u001B[49m\u001B[43m)\u001B[49m\n",
      "\n",
      "File \u001B[0;32m/opt/conda/lib/python3.10/site-packages/wandb/sdk/interface/interface_sock.py:51\u001B[0m, in \u001B[0;36mInterfaceSock._publish\u001B[0;34m(self, record, local)\u001B[0m\n",
      "\u001B[1;32m     49\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m_publish\u001B[39m(\u001B[38;5;28mself\u001B[39m, record: \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mpb.Record\u001B[39m\u001B[38;5;124m\"\u001B[39m, local: Optional[\u001B[38;5;28mbool\u001B[39m] \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m:\n",
      "\u001B[1;32m     50\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_assign(record)\n",
      "\u001B[0;32m---> 51\u001B[0m     \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_sock_client\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43msend_record_publish\u001B[49m\u001B[43m(\u001B[49m\u001B[43mrecord\u001B[49m\u001B[43m)\u001B[49m\n",
      "\n",
      "File \u001B[0;32m/opt/conda/lib/python3.10/site-packages/wandb/sdk/lib/sock_client.py:221\u001B[0m, in \u001B[0;36mSockClient.send_record_publish\u001B[0;34m(self, record)\u001B[0m\n",
      "\u001B[1;32m    219\u001B[0m server_req \u001B[38;5;241m=\u001B[39m spb\u001B[38;5;241m.\u001B[39mServerRequest()\n",
      "\u001B[1;32m    220\u001B[0m server_req\u001B[38;5;241m.\u001B[39mrecord_publish\u001B[38;5;241m.\u001B[39mCopyFrom(record)\n",
      "\u001B[0;32m--> 221\u001B[0m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43msend_server_request\u001B[49m\u001B[43m(\u001B[49m\u001B[43mserver_req\u001B[49m\u001B[43m)\u001B[49m\n",
      "\n",
      "File \u001B[0;32m/opt/conda/lib/python3.10/site-packages/wandb/sdk/lib/sock_client.py:155\u001B[0m, in \u001B[0;36mSockClient.send_server_request\u001B[0;34m(self, msg)\u001B[0m\n",
      "\u001B[1;32m    154\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21msend_server_request\u001B[39m(\u001B[38;5;28mself\u001B[39m, msg: Any) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m:\n",
      "\u001B[0;32m--> 155\u001B[0m     \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_send_message\u001B[49m\u001B[43m(\u001B[49m\u001B[43mmsg\u001B[49m\u001B[43m)\u001B[49m\n",
      "\n",
      "File \u001B[0;32m/opt/conda/lib/python3.10/site-packages/wandb/sdk/lib/sock_client.py:152\u001B[0m, in \u001B[0;36mSockClient._send_message\u001B[0;34m(self, msg)\u001B[0m\n",
      "\u001B[1;32m    150\u001B[0m header \u001B[38;5;241m=\u001B[39m struct\u001B[38;5;241m.\u001B[39mpack(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m<BI\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;28mord\u001B[39m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mW\u001B[39m\u001B[38;5;124m\"\u001B[39m), raw_size)\n",
      "\u001B[1;32m    151\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_lock:\n",
      "\u001B[0;32m--> 152\u001B[0m     \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_sendall_with_error_handle\u001B[49m\u001B[43m(\u001B[49m\u001B[43mheader\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m+\u001B[39;49m\u001B[43m \u001B[49m\u001B[43mdata\u001B[49m\u001B[43m)\u001B[49m\n",
      "\n",
      "File \u001B[0;32m/opt/conda/lib/python3.10/site-packages/wandb/sdk/lib/sock_client.py:130\u001B[0m, in \u001B[0;36mSockClient._sendall_with_error_handle\u001B[0;34m(self, data)\u001B[0m\n",
      "\u001B[1;32m    128\u001B[0m start_time \u001B[38;5;241m=\u001B[39m time\u001B[38;5;241m.\u001B[39mmonotonic()\n",
      "\u001B[1;32m    129\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n",
      "\u001B[0;32m--> 130\u001B[0m     sent \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_sock\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43msend\u001B[49m\u001B[43m(\u001B[49m\u001B[43mdata\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[1;32m    131\u001B[0m     \u001B[38;5;66;03m# sent equal to 0 indicates a closed socket\u001B[39;00m\n",
      "\u001B[1;32m    132\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m sent \u001B[38;5;241m==\u001B[39m \u001B[38;5;241m0\u001B[39m:\n",
      "\n",
      "\u001B[0;31mBrokenPipeError\u001B[0m: [Errno 32] Broken pipe"
     ]
    }
   ],
   "source": [
    "\n",
    "# N_EPOCHS = 1\n",
    "# CLIP = 1\n",
    "# INPUT_DIM = input_vocab_size\n",
    "# OUTPUT_DIM = output_vocab_size\n",
    "# ENC_EMB_DIM = 128\n",
    "# DEC_EMB_DIM = 128\n",
    "# HIDDEN_SIZE = 256\n",
    "# num_layers = 1\n",
    "# ENC_DROPOUT = 0.5\n",
    "# DEC_DROPOUT = 0.5\n",
    "# TEACHER_FORCING = 0.5\n",
    "# BI_DIRECTION = True\n",
    "# CELL_TYPE = 'LSTM'\n",
    "# pred_src = \"$bindya|\"\n",
    "# pred_trg = '$बिन्द्या|'\n",
    "\n",
    "# enc = Encoder(input_size=INPUT_DIM, embedding_size=ENC_EMB_DIM, hidden_size=HIDDEN_SIZE, num_layers=num_layers, dropout=ENC_DROPOUT, cell_type=CELL_TYPE, bidirectional=BI_DIRECTION)\n",
    "# dec = Decoder(output_dim=OUTPUT_DIM, emb_dim=DEC_EMB_DIM, hidden_size=HIDDEN_SIZE, num_layers=num_layers, dropout=DEC_DROPOUT, cell_type=CELL_TYPE, bidirectional=BI_DIRECTION)\n",
    "\n",
    "# model = Seq2Seq(enc, dec, device, teacher_forcing_ratio=TEACHER_FORCING).to(device)\n",
    "# def init_weights(m):\n",
    "#     for name, param in m.named_parameters():\n",
    "#         nn.init.uniform_(param.data, -0.08, 0.08)\n",
    "\n",
    "\n",
    "# model.apply(init_weights)\n",
    "# optimizer = optim.Adam(model.parameters())\n",
    "# criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# best_valid_loss = float('inf')\n",
    "# gbar = tqdm(range(1, N_EPOCHS + 1),position=1,leave=True, desc='Epochs', total=N_EPOCHS)\n",
    "# for epoch in gbar:\n",
    "#     train_loss, train_accuracy = train(model, train_dataloader, optimizer, criterion, CLIP)\n",
    "#     valid_loss, valid_accuracy = evaluate(model, valid_dataloader, criterion)\n",
    "#     gbar.set_postfix(train_loss=train_loss, train_acc=train_accuracy, val_loss=valid_loss, val_acc=valid_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
