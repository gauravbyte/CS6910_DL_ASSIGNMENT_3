{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2a6483c4",
   "metadata": {
    "_cell_guid": "968fde9b-cc8a-4f15-b43f-425c0407d454",
    "_uuid": "58f02d03-d719-42a8-b2e1-f43562d8a6b4",
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2023-05-02T16:13:09.313107Z",
     "iopub.status.busy": "2023-05-02T16:13:09.312520Z",
     "iopub.status.idle": "2023-05-02T16:13:09.318692Z",
     "shell.execute_reply": "2023-05-02T16:13:09.317695Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "papermill": {
     "duration": 0.017244,
     "end_time": "2023-05-02T16:13:09.321929",
     "exception": false,
     "start_time": "2023-05-02T16:13:09.304685",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#  [code] {\"jupyter\":{\"outputs_hidden\":false}}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1ca6d4c2",
   "metadata": {
    "_cell_guid": "a8a21111-7c1f-45ca-a80a-7ed914cba813",
    "_uuid": "06c0242b-893a-4476-9192-ff5a5992226b",
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2023-05-02T16:13:09.334839Z",
     "iopub.status.busy": "2023-05-02T16:13:09.333327Z",
     "iopub.status.idle": "2023-05-02T16:13:09.454938Z",
     "shell.execute_reply": "2023-05-02T16:13:09.453906Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "papermill": {
     "duration": 0.130627,
     "end_time": "2023-05-02T16:13:09.457623",
     "exception": false,
     "start_time": "2023-05-02T16:13:09.326996",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import random\n",
    "# Input data files are available in the read-only \"../input/\" directory\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        os.path.join(dirname, filename)\n",
    "\n",
    "        \n",
    "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n",
    "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df4b96ec",
   "metadata": {
    "_cell_guid": "da776bf1-b361-446d-9192-c8790e69dc5b",
    "_uuid": "e6981786-f1ec-4f86-aaee-8eeb70f39e33",
    "papermill": {
     "duration": 0.004742,
     "end_time": "2023-05-02T16:13:09.467512",
     "exception": false,
     "start_time": "2023-05-02T16:13:09.462770",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Import data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "12d4cca0",
   "metadata": {
    "_cell_guid": "8a976178-48d5-4975-8a09-1e8d388c1d1f",
    "_uuid": "816ea9a5-d66e-4184-bd06-63565a5c877b",
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2023-05-02T16:13:09.478799Z",
     "iopub.status.busy": "2023-05-02T16:13:09.478477Z",
     "iopub.status.idle": "2023-05-02T16:13:11.898470Z",
     "shell.execute_reply": "2023-05-02T16:13:11.897465Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "papermill": {
     "duration": 2.428909,
     "end_time": "2023-05-02T16:13:11.901319",
     "exception": false,
     "start_time": "2023-05-02T16:13:09.472410",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.autograd import Variable\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "import pickle\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b7240188",
   "metadata": {
    "_cell_guid": "bee05b18-19a1-4b97-8d8d-c11c1d4a650e",
    "_uuid": "fa99b038-35bb-4c6b-b687-e35025ef433b",
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2023-05-02T16:13:11.920398Z",
     "iopub.status.busy": "2023-05-02T16:13:11.919484Z",
     "iopub.status.idle": "2023-05-02T16:13:11.992471Z",
     "shell.execute_reply": "2023-05-02T16:13:11.991477Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "papermill": {
     "duration": 0.084633,
     "end_time": "2023-05-02T16:13:11.995216",
     "exception": false,
     "start_time": "2023-05-02T16:13:11.910583",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Executing on cuda:0\n"
     ]
    }
   ],
   "source": [
    "# Instantiates the device to be used as GPU/CPU based on availability\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Executing on \" + (\"cuda:0\" if torch.cuda.is_available() else \"cpu\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "653b124a",
   "metadata": {
    "_cell_guid": "c599adf9-b70a-4c20-896a-9e21a7d27833",
    "_uuid": "84df22fc-9f4a-4efb-9772-b293cbd7dff9",
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2023-05-02T16:13:12.012040Z",
     "iopub.status.busy": "2023-05-02T16:13:12.011655Z",
     "iopub.status.idle": "2023-05-02T16:13:12.177714Z",
     "shell.execute_reply": "2023-05-02T16:13:12.176758Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "papermill": {
     "duration": 0.177275,
     "end_time": "2023-05-02T16:13:12.180539",
     "exception": false,
     "start_time": "2023-05-02T16:13:12.003264",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(51199, 2)\n",
      "(4095, 2)\n",
      "(4095, 2)\n"
     ]
    }
   ],
   "source": [
    "df_train = pd.read_csv(\"/kaggle/input/aksharantar/aksharantar_sampled/mai/mai_train.csv\")\n",
    "df_test = pd.read_csv('/kaggle/input/aksharantar/aksharantar_sampled/mai/mai_test.csv')\n",
    "df_valid = pd.read_csv('/kaggle/input/aksharantar/aksharantar_sampled/mar/mar_valid.csv')\n",
    "print(df_train.shape)\n",
    "print(df_test.shape)\n",
    "print(df_valid.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e4a6ea26",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-02T16:13:12.198341Z",
     "iopub.status.busy": "2023-05-02T16:13:12.197975Z",
     "iopub.status.idle": "2023-05-02T16:13:12.203287Z",
     "shell.execute_reply": "2023-05-02T16:13:12.202376Z"
    },
    "papermill": {
     "duration": 0.018485,
     "end_time": "2023-05-02T16:13:12.207441",
     "exception": false,
     "start_time": "2023-05-02T16:13:12.188956",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_train = df_train.iloc[:2000]\n",
    "df_test = df_test.iloc[:200]\n",
    "df_valid = df_valid.iloc[:200]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "02b3af74",
   "metadata": {
    "_cell_guid": "c599adf9-b70a-4c20-896a-9e21a7d27833",
    "_uuid": "84df22fc-9f4a-4efb-9772-b293cbd7dff9",
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2023-05-02T16:13:12.226148Z",
     "iopub.status.busy": "2023-05-02T16:13:12.225854Z",
     "iopub.status.idle": "2023-05-02T16:13:14.922905Z",
     "shell.execute_reply": "2023-05-02T16:13:14.920748Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "papermill": {
     "duration": 2.710165,
     "end_time": "2023-05-02T16:13:14.925143",
     "exception": false,
     "start_time": "2023-05-02T16:13:12.214978",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'_': 0, '|': 1, '$': 2, 'a': 3, 'b': 4, 'c': 5, 'd': 6, 'e': 7, 'f': 8, 'g': 9, 'h': 10, 'i': 11, 'j': 12, 'k': 13, 'l': 14, 'm': 15, 'n': 16, 'o': 17, 'p': 18, 'q': 19, 'r': 20, 's': 21, 't': 22, 'u': 23, 'v': 24, 'w': 25, 'x': 26, 'y': 27, 'z': 28}\n",
      "{'_': 0, '|': 1, '$': 2, 'ऀ': 3, 'ँ': 4, 'ं': 5, 'ः': 6, 'ऄ': 7, 'अ': 8, 'आ': 9, 'इ': 10, 'ई': 11, 'उ': 12, 'ऊ': 13, 'ऋ': 14, 'ऌ': 15, 'ऍ': 16, 'ऎ': 17, 'ए': 18, 'ऐ': 19, 'ऑ': 20, 'ऒ': 21, 'ओ': 22, 'औ': 23, 'क': 24, 'ख': 25, 'ग': 26, 'घ': 27, 'ङ': 28, 'च': 29, 'छ': 30, 'ज': 31, 'झ': 32, 'ञ': 33, 'ट': 34, 'ठ': 35, 'ड': 36, 'ढ': 37, 'ण': 38, 'त': 39, 'थ': 40, 'द': 41, 'ध': 42, 'न': 43, 'ऩ': 44, 'प': 45, 'फ': 46, 'ब': 47, 'भ': 48, 'म': 49, 'य': 50, 'र': 51, 'ऱ': 52, 'ल': 53, 'ळ': 54, 'ऴ': 55, 'व': 56, 'श': 57, 'ष': 58, 'स': 59, 'ह': 60, 'ऺ': 61, 'ऻ': 62, '़': 63, 'ऽ': 64, 'ा': 65, 'ि': 66, 'ी': 67, 'ु': 68, 'ू': 69, 'ृ': 70, 'ॄ': 71, 'ॅ': 72, 'ॆ': 73, 'े': 74, 'ै': 75, 'ॉ': 76, 'ॊ': 77, 'ो': 78, 'ौ': 79, '्': 80, 'ॎ': 81, 'ॏ': 82, 'ॐ': 83, '॑': 84, '॒': 85, '॓': 86, '॔': 87, 'ॕ': 88, 'ॖ': 89, 'ॗ': 90, 'क़': 91, 'ख़': 92, 'ग़': 93, 'ज़': 94, 'ड़': 95, 'ढ़': 96, 'फ़': 97, 'य़': 98, 'ॠ': 99, 'ॡ': 100, 'ॢ': 101, 'ॣ': 102, '।': 103, '॥': 104, '०': 105, '१': 106, '२': 107, '३': 108, '४': 109, '५': 110, '६': 111, '७': 112, '८': 113, '९': 114, '॰': 115, 'ॱ': 116, 'ॲ': 117, 'ॳ': 118, 'ॴ': 119, 'ॵ': 120, 'ॶ': 121, 'ॷ': 122, 'ॸ': 123, 'ॹ': 124, 'ॺ': 125, 'ॻ': 126, 'ॼ': 127, 'ॽ': 128, 'ॾ': 129, 'ॿ': 130}\n",
      "131\n",
      "                  X             Y\n",
      "0       $deyuralee|     $देउराली|\n",
      "1        $dekhaint|      $देखैंत|\n",
      "2     $tarkariwali|  $तरकारीवाली|\n",
      "3     $kathapathme|    $कथापाठमे|\n",
      "4        $dehalvee|      $देहलवी|\n",
      "...             ...           ...\n",
      "1995     $khalipha|       $खलिफा|\n",
      "1996    $balcharit|     $बालचरित|\n",
      "1997     $kshemkar|     $क्षेमकर|\n",
      "1998       $thaaka|         $थाक|\n",
      "1999    $rayadamda|    $रायडाँडा|\n",
      "\n",
      "[2000 rows x 2 columns]\n",
      "                      X               Y\n",
      "0              $odisha|         $ओडिशा|\n",
      "1            $pembroke|      $पेमब्रोक|\n",
      "2              $baxter|       $बैक्सटर|\n",
      "3           $nizamabad|     $निजामाबाद|\n",
      "4            $umedwaar|       $उमेदवार|\n",
      "..                  ...             ...\n",
      "195              $naat|           $नात|\n",
      "196  $sampannmadhubani|  $संपन्नमधुबनी|\n",
      "197         $shreemati|       $श्रीमती|\n",
      "198     $jeewwaigyanik|  $जीववैज्ञानिक|\n",
      "199        $wibhooshit|       $विभूषित|\n",
      "\n",
      "[200 rows x 2 columns]\n",
      "                     X               Y\n",
      "0                $reo|          $रियो|\n",
      "1       $sangrahalaye|    $संग्रहालये|\n",
      "2              $sidni|         $सिडनी|\n",
      "3           $dastavej|      $दस्तावेज|\n",
      "4         $guntaliyet|     $गुंतलीयेत|\n",
      "..                 ...             ...\n",
      "195      $fulpakharoo|      $फुलपाखरू|\n",
      "196      $sansaarachi|      $संसाराची|\n",
      "197  $khalashyanpaiki|  $खलाश्यांपैकी|\n",
      "198           $shakoo|           $शकू|\n",
      "199   $nilangekaranna|  $निलंगेकरांना|\n",
      "\n",
      "[200 rows x 2 columns]\n",
      "max input length 29\n",
      "max output length 21\n",
      "max_length 29\n",
      "Input Character max 29\n",
      "output Character size 131\n",
      "Input Character max 29\n",
      "output Character size 131\n",
      "tensor([ 2,  6,  7, 27, 23, 20,  3, 14,  7,  7,  1])\n",
      "$देखैंत|\n",
      "{'_': 0, '|': 1, '$': 2, 'a': 3, 'b': 4, 'c': 5, 'd': 6, 'e': 7, 'f': 8, 'g': 9, 'h': 10, 'i': 11, 'j': 12, 'k': 13, 'l': 14, 'm': 15, 'n': 16, 'o': 17, 'p': 18, 'q': 19, 'r': 20, 's': 21, 't': 22, 'u': 23, 'v': 24, 'w': 25, 'x': 26, 'y': 27, 'z': 28}\n",
      "tensor([10,  7, 14, 14, 17])\n",
      "torch.Size([29, 3])\n",
      "torch.Size([21, 3])\n"
     ]
    }
   ],
   "source": [
    "#%%\n",
    "PAD_CHAR = '_'\n",
    "EOW_CHAR = '|'\n",
    "SOW_CHAR = '$'\n",
    "BATCH_SIZE = 3\n",
    "#%%\n",
    "eng_alphabets = [chr(alpha) for alpha in range(ord('a'), ord('z') + 1)]\n",
    "# eng_alpha2index = {pad_char:0}\n",
    "in_dict = {PAD_CHAR: 0, EOW_CHAR: 1, SOW_CHAR: 2}\n",
    "for index, alpha in enumerate(eng_alphabets):\n",
    "\tin_dict[alpha] = index + 3\n",
    "print(in_dict)\n",
    "\n",
    "#%%\n",
    "hindi_alphabets = [chr(alpha) for alpha in range(2304, 2432)]\n",
    "hindi_alphabet_size = len(hindi_alphabets)\n",
    "out_dict = {PAD_CHAR: 0, EOW_CHAR: 1, SOW_CHAR: 2}\n",
    "for index, alpha in enumerate(hindi_alphabets):\n",
    "\tout_dict[alpha] = index + 3\n",
    "#%%\n",
    "print(out_dict)\n",
    "print(len(out_dict))\n",
    "#%%\n",
    "if df_train.iloc[0][0][0] != SOW_CHAR:\n",
    "\tdf_train = df_train.iloc[:, ].apply(lambda x: SOW_CHAR + x + EOW_CHAR)\n",
    "\tdf_test = df_test.iloc[:, ].apply(lambda x: SOW_CHAR + x + EOW_CHAR)\n",
    "\tdf_valid = df_valid.iloc[:, ].apply(lambda x: SOW_CHAR + x + EOW_CHAR)\n",
    "\n",
    "#%%\n",
    "df_train = df_train.set_axis(['X', 'Y'], axis=1)\n",
    "df_valid = df_valid.set_axis(['X', 'Y'], axis=1)\n",
    "df_test = df_test.set_axis(['X', 'Y'], axis=1)\n",
    "#%%\n",
    "print(df_train)\n",
    "print(df_test)\n",
    "print(df_valid)\n",
    "\n",
    "#%%\n",
    "max_input_length = max(df_train.iloc[:, 0].apply(lambda x: len(x)).max(),\n",
    "\t\t\t\t\t   df_test.iloc[:, 0].apply(lambda x: len(x)).max(),\n",
    "\t\t\t\t\t   df_valid.iloc[:, 0].apply(lambda x: len(x)).max())\n",
    "\n",
    "max_output_length = max(df_train.iloc[:, 1].apply(lambda x: len(x)).max(),\n",
    "\t\t\t\t\t\tdf_test.iloc[:, 1].apply(lambda x: len(x)).max(),\n",
    "\t\t\t\t\t\tdf_valid.iloc[:, 1].apply(lambda x: len(x)).max())\n",
    "\n",
    "print(\"max input length\", max_input_length)\n",
    "print(\"max output length\", max_output_length)\n",
    "MAX_LENGTH = max(max_input_length, max_output_length)\n",
    "print(\"max_length\", MAX_LENGTH)\n",
    "#%%\n",
    "input_vocab_size = len(in_dict)\n",
    "output_vocab_size = len(out_dict)\n",
    "print(\"Input Character max\", input_vocab_size)\n",
    "print(\"output Character size\", output_vocab_size)\n",
    "\n",
    "train = df_train.values.tolist()\n",
    "valid = df_valid.values.tolist()\n",
    "test = df_test.values.tolist()\n",
    "\n",
    "#%%\n",
    "input_vocab_size = len(in_dict)\n",
    "output_vocab_size = len(out_dict)\n",
    "print(\"Input Character max\", input_vocab_size)\n",
    "print(\"output Character size\", output_vocab_size)\n",
    "\n",
    "train = df_train.values.tolist()\n",
    "valid = df_valid.values.tolist()\n",
    "test = df_test.values.tolist()\n",
    "#%% md\n",
    "\n",
    "#%%\n",
    "def inputToTensor(line):\n",
    "\t# print([in_dict[x] for x in line])\n",
    "\ttensor = torch.tensor(data=([in_dict[x] for x in line]), dtype=torch.long)\n",
    "\treturn tensor\n",
    "\n",
    "\n",
    "def charToTensor(char, dic=in_dict):\n",
    "\ttensor = torch.zeros(len(dic))\n",
    "\ttensor[dic[char]] = 1\n",
    "\treturn tensor\n",
    "\n",
    "\n",
    "def outToTensor(word):\n",
    "\ttensor = torch.tensor([out_dict[x] for x in word])\n",
    "\treturn tensor\n",
    "\n",
    "#%%\n",
    "print(inputToTensor(train[0][0]))\n",
    "#%%\n",
    "print(train[1][1])\n",
    "\n",
    "#%%\n",
    "inputToTensor(\"$bindhya|\")\n",
    "#%%\n",
    "print(in_dict)\n",
    "#%%\n",
    "print(inputToTensor(\"hello\"))\n",
    "\n",
    "#%%\n",
    "def generate_batch(data_batch):\n",
    "\t#     print(data_batch)\n",
    "\ttensor_data = [inputToTensor(x[0].ljust(max_input_length, PAD_CHAR)) for x in data_batch]\n",
    "\ttensor_target = [outToTensor(x[1].ljust(max_output_length, PAD_CHAR)) for x in data_batch]\n",
    "\tpadded_input_batch = (torch.nn.utils.rnn.pad_sequence(tensor_data, batch_first=True, padding_value=1).T).to(device)\n",
    "\tpadded_output_batch = (torch.nn.utils.rnn.pad_sequence(tensor_target, batch_first=True, padding_value=1).T).to(device)\n",
    "\t#     print(tensor_data)\n",
    "\t#     print(padded_input_batch.shape)\n",
    "\t#     print(padded_output_batch.shape)\n",
    "\treturn padded_input_batch, padded_output_batch\n",
    "#%%\n",
    "train_dataloader = DataLoader(train, batch_size=BATCH_SIZE, shuffle=True, collate_fn=generate_batch)\n",
    "test_dataloader = DataLoader(test, batch_size=BATCH_SIZE, shuffle=False, collate_fn=generate_batch)\n",
    "valid_dataloader = DataLoader(test, batch_size=BATCH_SIZE, shuffle=False, collate_fn=generate_batch)\n",
    "\n",
    "#%%\n",
    "\n",
    "for data,target in train_dataloader:\n",
    "    # print(data)\n",
    "    # print(target)\n",
    "    print(data.shape)\n",
    "    print(target.shape)\n",
    "    if True:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "28140984",
   "metadata": {
    "_cell_guid": "c599adf9-b70a-4c20-896a-9e21a7d27833",
    "_uuid": "84df22fc-9f4a-4efb-9772-b293cbd7dff9",
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2023-05-02T16:13:14.938144Z",
     "iopub.status.busy": "2023-05-02T16:13:14.937737Z",
     "iopub.status.idle": "2023-05-02T16:13:14.945028Z",
     "shell.execute_reply": "2023-05-02T16:13:14.943981Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "papermill": {
     "duration": 0.01626,
     "end_time": "2023-05-02T16:13:14.947194",
     "exception": false,
     "start_time": "2023-05-02T16:13:14.930934",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#%%\n",
    "class Encoder(nn.Module):\n",
    "    def __init__(self, input_dim, emb_dim, hid_dim, n_layers, dropout):\n",
    "        super().__init__()\n",
    "\n",
    "        self.hid_dim = hid_dim\n",
    "        self.n_layers = n_layers\n",
    "\n",
    "        self.embedding = nn.Embedding(input_dim, emb_dim)\n",
    "\n",
    "        self.rnn = nn.LSTM(emb_dim, hid_dim, n_layers, dropout = dropout)\n",
    "\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self, src):\n",
    "        #src = [src len, batch size]\n",
    "        # print(\"encoder forward prop\")\n",
    "\n",
    "        embedded = self.dropout(self.embedding(src))\n",
    "        # embedded = embedded.permute(1,0,2)\n",
    "        # print(\"encoder embedded shape\", embedded.shape)\n",
    "        #embedded = [src len, batch size, emb dim]\n",
    "        outputs, (hidden, cell) = self.rnn(embedded)\n",
    "        # print(\"encoder hidden dimension\", hidden.shape)\n",
    "        # print(\"encoder output dimension\", outputs.shape)\n",
    "        # print(\"encoder cell dimension\", cell.shape)\n",
    "        #outputs = [src len, batch size, hid dim * n directions]\n",
    "        #hidden = [n layers * n directions, batch size, hid dim]\n",
    "        #cell = [n layers * n directions, batch size, hid dim]\n",
    "        #outputs are always from the top hidden layer\n",
    "        return hidden, cell\n",
    "#%%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ba615c5c",
   "metadata": {
    "_cell_guid": "c599adf9-b70a-4c20-896a-9e21a7d27833",
    "_uuid": "84df22fc-9f4a-4efb-9772-b293cbd7dff9",
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2023-05-02T16:13:14.959247Z",
     "iopub.status.busy": "2023-05-02T16:13:14.958959Z",
     "iopub.status.idle": "2023-05-02T16:13:14.967241Z",
     "shell.execute_reply": "2023-05-02T16:13:14.966195Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "papermill": {
     "duration": 0.016876,
     "end_time": "2023-05-02T16:13:14.969425",
     "exception": false,
     "start_time": "2023-05-02T16:13:14.952549",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class Decoder(nn.Module):\n",
    "    def __init__(self, output_dim, emb_dim, hid_dim, n_layers, dropout):\n",
    "        super().__init__()\n",
    "\n",
    "        self.output_dim = output_dim\n",
    "        self.hid_dim = hid_dim\n",
    "        self.n_layers = n_layers\n",
    "\n",
    "        self.embedding = nn.Embedding(output_dim, emb_dim)\n",
    "\n",
    "        self.rnn = nn.LSTM(emb_dim, hid_dim, n_layers, dropout = dropout)\n",
    "\n",
    "        self.fc_out = nn.Linear(hid_dim, output_dim)\n",
    "\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self, input, hidden, cell):\n",
    "\n",
    "        #input = [batch size]\n",
    "        #hidden = [n layers * n directions, batch size, hid dim]\n",
    "        #cell = [n layers * n directions, batch size, hid dim]\n",
    "\n",
    "        #n directions in the decoder will both always be 1, therefore:\n",
    "        #hidden = [n layers, batch size, hid dim]\n",
    "        #context = [n layers, batch size, hid dim]\n",
    "        # print(\"decoder hidden shape\", hidden.shape)\n",
    "        # print(\"decoder context shape\", cell.shape)\n",
    "        input = input.unsqueeze(0)\n",
    "\n",
    "        #input = [1, batch size]\n",
    "\n",
    "        embedded = self.dropout(self.embedding(input))\n",
    "        # print(\"decoder embedded shape\", embedded.shape)\n",
    "        #embedded = [1, batch size, emb dim]\n",
    "\n",
    "        output, (hidden, cell) = self.rnn(embedded, (hidden, cell))\n",
    "        # print(\"decoder output shape\", output.shape)\n",
    "        # print(\"decoder hidden shape\", hidden.shape)\n",
    "        # print(\"decoder context shape\", cell.shape)\n",
    "        #output = [seq len, batch size, hid dim * n directions]\n",
    "        #hidden = [n layers * n directions, batch size, hid dim]\n",
    "        #cell = [n layers * n directions, batch size, hid dim]\n",
    "\n",
    "        #seq len and n directions will always be 1 in the decoder, therefore:\n",
    "        #output = [1, batch size, hid dim]\n",
    "        #hidden = [n layers, batch size, hid dim]\n",
    "        #cell = [n layers, batch size, hid dim]\n",
    "\n",
    "        prediction = self.fc_out(output.squeeze(0))\n",
    "\n",
    "        #prediction = [batch size, output dim]\n",
    "        # print(\"decoder prediction shape\", prediction.shape)\n",
    "        return prediction, hidden, cell\n",
    "#%%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "04a5b2e2",
   "metadata": {
    "_cell_guid": "c599adf9-b70a-4c20-896a-9e21a7d27833",
    "_uuid": "84df22fc-9f4a-4efb-9772-b293cbd7dff9",
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2023-05-02T16:13:14.981449Z",
     "iopub.status.busy": "2023-05-02T16:13:14.981172Z",
     "iopub.status.idle": "2023-05-02T16:13:14.990135Z",
     "shell.execute_reply": "2023-05-02T16:13:14.989117Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "papermill": {
     "duration": 0.017413,
     "end_time": "2023-05-02T16:13:14.992236",
     "exception": false,
     "start_time": "2023-05-02T16:13:14.974823",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class Seq2Seq(nn.Module):\n",
    "    def __init__(self, encoder, decoder, device):\n",
    "        super().__init__()\n",
    "\n",
    "        self.encoder = encoder\n",
    "        self.decoder = decoder\n",
    "        self.device = device\n",
    "\n",
    "        assert encoder.hid_dim == decoder.hid_dim, \\\n",
    "            \"Hidden dimensions of encoder and decoder must be equal!\"\n",
    "        assert encoder.n_layers == decoder.n_layers, \\\n",
    "            \"Encoder and decoder must have equal number of layers!\"\n",
    "\n",
    "    def forward(self, src, trg, teacher_forcing_ratio = 0.5):\n",
    "        # src = src.permute(1,0)\n",
    "        # trg = trg.permute(1,0)\n",
    "        #src = [src len, batch size]\n",
    "        #trg = [trg len, batch size]\n",
    "        #teacher_forcing_ratio is probability to use teacher forcing\n",
    "        #e.g. if teacher_forcing_ratio is 0.75 we use ground-truth inputs 75% of the time\n",
    "        # print(\"seq2seq forward prop src shape\", src.shape)\n",
    "        # print(\"seq2seq forward prop trg shape\", trg.shape)\n",
    "        batch_size = trg.shape[1]\n",
    "        trg_len = trg.shape[0]\n",
    "\n",
    "        trg_vocab_size = self.decoder.output_dim\n",
    "        # print(\"seq2seq trg vocab size\", trg_vocab_size)\n",
    "        # print(\"seq2seq batch size\", batch_size)\n",
    "        # print(\"seq2seq trg len\", trg_len)\n",
    "        #tensor to store decoder outputs\n",
    "        outputs = torch.zeros(trg_len, batch_size, trg_vocab_size).to(self.device)\n",
    "\n",
    "        #last hidden state of the encoder is used as the initial hidden state of the decoder\n",
    "        hidden, cell = self.encoder(src)\n",
    "        # print(\"seq2seq hidden shape\", hidden.shape)\n",
    "        # print(\"seq2seq cell shape\", cell.shape)\n",
    "        #first input to the decoder is the <sos> tokens\n",
    "        input = trg[0,:]\n",
    "        # print(\"first input to decoder\", input)\n",
    "        for t in range(1, trg_len):\n",
    "\t\t\t            #insert input token embedding, previous hidden and previous cell states\n",
    "            #receive output tensor (predictions) and new hidden and cell states\n",
    "            output, hidden, cell = self.decoder(input, hidden, cell)\n",
    "\n",
    "            #place predictions in a tensor holding predictions for each token\n",
    "            outputs[t] = output\n",
    "\n",
    "            #decide if we are going to use teacher forcing or not\n",
    "            teacher_force = random.random() < teacher_forcing_ratio\n",
    "\n",
    "            #get the highest predicted token from our predictions\n",
    "            top1 = output.argmax(1)\n",
    "\n",
    "            #if teacher forcing, use actual next token as next input\n",
    "            #if not, use predicted token\n",
    "            input = trg[t] if teacher_force else top1\n",
    "\n",
    "        return outputs\n",
    "#%%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "af0e4071",
   "metadata": {
    "_cell_guid": "c599adf9-b70a-4c20-896a-9e21a7d27833",
    "_uuid": "84df22fc-9f4a-4efb-9772-b293cbd7dff9",
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2023-05-02T16:13:15.005215Z",
     "iopub.status.busy": "2023-05-02T16:13:15.004382Z",
     "iopub.status.idle": "2023-05-02T16:13:15.009425Z",
     "shell.execute_reply": "2023-05-02T16:13:15.008398Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "papermill": {
     "duration": 0.013188,
     "end_time": "2023-05-02T16:13:15.011481",
     "exception": false,
     "start_time": "2023-05-02T16:13:14.998293",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "INPUT_DIM = input_vocab_size\n",
    "OUTPUT_DIM = output_vocab_size\n",
    "ENC_EMB_DIM = 256\n",
    "DEC_EMB_DIM = 256\n",
    "HID_DIM = 512\n",
    "N_LAYERS = 2\n",
    "ENC_DROPOUT = 0.5\n",
    "DEC_DROPOUT = 0.5\n",
    "#%%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "09e2573b",
   "metadata": {
    "_cell_guid": "c599adf9-b70a-4c20-896a-9e21a7d27833",
    "_uuid": "84df22fc-9f4a-4efb-9772-b293cbd7dff9",
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2023-05-02T16:13:15.023549Z",
     "iopub.status.busy": "2023-05-02T16:13:15.022630Z",
     "iopub.status.idle": "2023-05-02T16:13:16.147203Z",
     "shell.execute_reply": "2023-05-02T16:13:16.146129Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "papermill": {
     "duration": 1.133422,
     "end_time": "2023-05-02T16:13:16.150008",
     "exception": false,
     "start_time": "2023-05-02T16:13:15.016586",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "enc = Encoder(INPUT_DIM, ENC_EMB_DIM, HID_DIM, N_LAYERS, ENC_DROPOUT)\n",
    "dec = Decoder(OUTPUT_DIM, DEC_EMB_DIM, HID_DIM, N_LAYERS, DEC_DROPOUT)\n",
    "#%%\n",
    "model = Seq2Seq(enc, dec, device).to(device)\n",
    "#%%\n",
    "def init_weights(m):\n",
    "    for name, param in m.named_parameters():\n",
    "        nn.init.uniform_(param.data, -0.08, 0.08)\n",
    "\n",
    "model.apply(init_weights)\n",
    "#%%\n",
    "optimizer = optim.Adam(model.parameters())\n",
    "#%%\n",
    "# TRG_PAD_IDX = TRG.vocab.stoi[TRG.pad_token]\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "#%%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d2c8b136",
   "metadata": {
    "_cell_guid": "c599adf9-b70a-4c20-896a-9e21a7d27833",
    "_uuid": "84df22fc-9f4a-4efb-9772-b293cbd7dff9",
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2023-05-02T16:13:16.163181Z",
     "iopub.status.busy": "2023-05-02T16:13:16.162201Z",
     "iopub.status.idle": "2023-05-02T16:13:16.170100Z",
     "shell.execute_reply": "2023-05-02T16:13:16.169084Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "papermill": {
     "duration": 0.016706,
     "end_time": "2023-05-02T16:13:16.172325",
     "exception": false,
     "start_time": "2023-05-02T16:13:16.155619",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def train(model, iterator, optimizer, criterion, clip):\n",
    "\n",
    "    model.train()\n",
    "\n",
    "    epoch_loss = 0\n",
    "\n",
    "    for i, (data, target) in enumerate(iterator):\n",
    "        # if(i == 2):\n",
    "        #     break\n",
    "        src = data\n",
    "        trg = target\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        # print(\"train target shape\", trg.shape)\n",
    "        output = model(src, trg)\n",
    "\n",
    "        #trg = [trg len, batch size]\n",
    "        #output = [trg len, batch size, output dim]\n",
    "        # trg = trg.permute(1,0)\n",
    "        # output = output.permute(1,0, 2)\n",
    "        # print(\"train target shape\", trg.shape)\n",
    "        # print(\"train output shape\", output.shape)\n",
    "        output_dim = output.shape[-1]\n",
    "        output = output[1:].reshape(-1, output_dim)\n",
    "        trg = trg[1:].reshape(-1)\n",
    "        # print(\"target shape\", trg.shape)\n",
    "        # print(\"output shape\", output.shape)\n",
    "        #trg = [(trg len - 1) * batch size]\n",
    "        #output = [(trg len - 1) * batch size, output dim]\n",
    "\n",
    "        loss = criterion(output, trg)\n",
    "\n",
    "        loss.backward()\n",
    "\n",
    "        # torch.nn.utils.clip_grad_norm_(model.parameters(), clip)\n",
    "        #\n",
    "        optimizer.step()\n",
    "        #\n",
    "        ls = loss.item()\n",
    "        epoch_loss += ls\n",
    "#         print(ls)\n",
    "    return epoch_loss / len(iterator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2e477b4a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-02T16:13:16.184207Z",
     "iopub.status.busy": "2023-05-02T16:13:16.183913Z",
     "iopub.status.idle": "2023-05-02T16:13:16.190502Z",
     "shell.execute_reply": "2023-05-02T16:13:16.189466Z"
    },
    "papermill": {
     "duration": 0.014767,
     "end_time": "2023-05-02T16:13:16.192595",
     "exception": false,
     "start_time": "2023-05-02T16:13:16.177828",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def evaluate(model, iterator, criterion):\n",
    "    \n",
    "    model.eval()\n",
    "    \n",
    "    epoch_loss = 0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "    \n",
    "        for i,(data,target) in enumerate(iterator):\n",
    "\n",
    "            src = data\n",
    "            trg = target\n",
    "\n",
    "            output = model(src, trg, 0) #turn off teacher forcing\n",
    "\n",
    "            #trg = [trg len, batch size]\n",
    "            #output = [trg len, batch size, output dim]\n",
    "\n",
    "            output_dim = output.shape[-1]\n",
    "            \n",
    "            output = output[1:].reshape(-1, output_dim)\n",
    "            trg = trg[1:].reshape(-1)\n",
    "\n",
    "            #trg = [(trg len - 1) * batch size]\n",
    "            #output = [(trg len - 1) * batch size, output dim]\n",
    "\n",
    "            loss = criterion(output, trg)\n",
    "            \n",
    "            epoch_loss += loss.item()\n",
    "        \n",
    "    return epoch_loss / len(iterator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "de6a803b",
   "metadata": {
    "_cell_guid": "c599adf9-b70a-4c20-896a-9e21a7d27833",
    "_uuid": "84df22fc-9f4a-4efb-9772-b293cbd7dff9",
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2023-05-02T16:13:16.204081Z",
     "iopub.status.busy": "2023-05-02T16:13:16.203805Z",
     "iopub.status.idle": "2023-05-02T16:16:04.397863Z",
     "shell.execute_reply": "2023-05-02T16:16:04.396612Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "papermill": {
     "duration": 168.202571,
     "end_time": "2023-05-02T16:16:04.400349",
     "exception": false,
     "start_time": "2023-05-02T16:13:16.197778",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.5833338904773993\n",
      "1.4955152842535901\n",
      "1.3970622117372824\n",
      "1.3597482398374756\n",
      "1.3338366491326328\n",
      "1.2932602905515413\n",
      "1.2964136218917424\n",
      "1.2672723158081967\n",
      "1.2532442385467633\n",
      "1.2528506873258904\n",
      "1.2111332703387363\n",
      "1.206494181013819\n",
      "1.1561186115244875\n",
      "1.2138021659495226\n",
      "1.0952509325304847\n",
      "1.19814600695425\n",
      "1.0492746942583053\n",
      "1.067351236272214\n",
      "1.0001597880334154\n",
      "1.0321044165696671\n"
     ]
    }
   ],
   "source": [
    "N_EPOCHS = 10\n",
    "CLIP = 1\n",
    "\n",
    "best_valid_loss = float('inf')\n",
    "\n",
    "for epoch in range(N_EPOCHS):\n",
    "\n",
    "    # start_time = time.time()\n",
    "    train_loss = train(model, train_dataloader, optimizer, criterion, CLIP)\n",
    "    print(train_loss)\n",
    "    valid_loss = evaluate(model, valid_dataloader, criterion)\n",
    "    print(valid_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cf6ff42",
   "metadata": {
    "papermill": {
     "duration": 0.006094,
     "end_time": "2023-05-02T16:16:04.412866",
     "exception": false,
     "start_time": "2023-05-02T16:16:04.406772",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20c582d8",
   "metadata": {
    "papermill": {
     "duration": 0.005955,
     "end_time": "2023-05-02T16:16:04.425070",
     "exception": false,
     "start_time": "2023-05-02T16:16:04.419115",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c14b472e",
   "metadata": {
    "papermill": {
     "duration": 0.0059,
     "end_time": "2023-05-02T16:16:04.437151",
     "exception": false,
     "start_time": "2023-05-02T16:16:04.431251",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d9dd149",
   "metadata": {
    "papermill": {
     "duration": 0.005916,
     "end_time": "2023-05-02T16:16:04.449553",
     "exception": false,
     "start_time": "2023-05-02T16:16:04.443637",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "188a5153",
   "metadata": {
    "papermill": {
     "duration": 0.005934,
     "end_time": "2023-05-02T16:16:04.461670",
     "exception": false,
     "start_time": "2023-05-02T16:16:04.455736",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 185.598336,
   "end_time": "2023-05-02T16:16:05.893498",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2023-05-02T16:13:00.295162",
   "version": "2.4.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
